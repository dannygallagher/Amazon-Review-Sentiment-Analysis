{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN + hyperparameter tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzGv3xKvfsoR"
      },
      "source": [
        "!pip install madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vJs5Piuib3L"
      },
      "source": [
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mNPpf6IfM9n"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnZbMqLUepUJ"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import nltk\n",
        "import torch\n",
        "import random\n",
        "import string\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import brown\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.autograd import Variable\n",
        "from torchtext import data, datasets\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "from IPython.display import Image, YouTubeVideo\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from madgrad import MADGRAD\n",
        "\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIkyo5ZVd6zA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFoJ_1Eizz0L"
      },
      "source": [
        "batch_size = 32 \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# max size of our vocab vector\n",
        "max_vocab = 40000\n",
        "\n",
        "def load_dataset():\n",
        "    TEXT = data.Field(tokenize = nltk.word_tokenize,\n",
        "                      include_lengths = True, batch_first = True)\n",
        "    LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "    fields = {'title_plus_review': ('text', TEXT), 'neutrality': ('label', LABEL)}\n",
        "    train_data, test_data = data.TabularDataset.splits(\n",
        "        path = '',\n",
        "        train = '/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/neutrality_binary_train.json',\n",
        "        test = '/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/neutrality_binary_test.json',\n",
        "        format = 'json',\n",
        "        fields = fields\n",
        "    )\n",
        "    \n",
        "\n",
        "    #We use \"glove.6B.100d\" for 6 billion 100-dimensional glove embeddings and set the non-glove words via Gaussian distribution\n",
        "    TEXT.build_vocab(train_data, max_size = max_vocab, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
        "    LABEL.build_vocab(train_data)\n",
        "\n",
        "    train_data, valid_data = train_data.split(split_ratio=0.75, random_state = random.seed(42))\n",
        "    \n",
        "    #Use BucketIterator sort_within_batch = True, sort_key=lambda x: len(x.text), and shuffle=True\n",
        "    #to split batches into reviews of similar length and pad each batch accordingly.\n",
        "    #This will greatly speed up our processing by making us have to process way fewer non-useful pad tokens.\n",
        "    train_batches, valid_batches, test_batches = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                   batch_size= batch_size, sort_key=lambda x: len(x.text),\n",
        "                                                                   repeat=False, shuffle=True, sort_within_batch = True)\n",
        "    vocab_size = len(TEXT.vocab)\n",
        "\n",
        "    return TEXT, vocab_size, train_batches, valid_batches, test_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgdPMbagXdY"
      },
      "source": [
        "%%time\n",
        "TEXT, vocab_size, train_batches, valid_batches, test_batches = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le-grBv7iebA"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtKYPkF3tFtR"
      },
      "source": [
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKUsYCAYUDhI"
      },
      "source": [
        "Train, Test, Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY6hwxRtA7j1"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "\n",
        "def train(model, device, train_batches, valid_batches, epochs, learning_rate, weight_decay = 0, criterion = nn.CrossEntropyLoss(), optim = 'Adam'):\n",
        "      if optim == 'Adam':\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
        "      elif optim == 'Madgrad':\n",
        "          optimizer =  MADGRAD(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
        "\n",
        "      #We'll set up a best validation loss (set to infinity at first) so we can save the best epoch\n",
        "      best_validation_loss = float('inf')\n",
        "      train_loss, validation_loss = [], []\n",
        "      train_acc, validation_acc = [], []\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "          # train\n",
        "          model.train()\n",
        "          running_loss = 0.\n",
        "          correct, total = 0, 0 \n",
        "          steps = 0\n",
        "\n",
        "          for idx, batch in enumerate(train_batches):\n",
        "              text = batch.text[0]\n",
        "            \n",
        "              target = batch.label\n",
        "              target = torch.autograd.Variable(target).long()\n",
        "              text, target = text.to(device), target.to(device)\n",
        "\n",
        "              \n",
        "              optimizer.zero_grad()\n",
        "              output = model(text)\n",
        "\n",
        "              loss = criterion(output, target)\n",
        "              loss.backward()\n",
        "\n",
        "              #gradient clipping to help with vanishing gradients\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "\n",
        "              optimizer.step()\n",
        "              steps += 1\n",
        "              running_loss += loss.item()\n",
        "\n",
        "              # get accuracy \n",
        "              _, predicted = torch.max(output, 1)\n",
        "              total += target.size(0)\n",
        "              correct += (predicted == target).sum().item()\n",
        "\n",
        "\n",
        "          t_loss = running_loss/len(train_batches)\n",
        "          t_acc = correct/total\n",
        "\n",
        "          train_loss.append(t_loss)\n",
        "          train_acc.append(t_acc)\n",
        "\n",
        "          print(f'Epoch: {epoch + 1},  Training Loss: {t_loss: .4f}, Training Accuracy: {100*t_acc: .2f}%')\n",
        "\n",
        "          # validate\n",
        "          model.eval()\n",
        "          running_loss = 0.\n",
        "          correct, total = 0, 0 \n",
        "\n",
        "          with torch.no_grad():\n",
        "              for idx, batch in enumerate(valid_batches):\n",
        "                  text = batch.text[0]\n",
        "                  target = batch.label\n",
        "                  target = torch.autograd.Variable(target).long()\n",
        "                  text, target = text.to(device), target.to(device)\n",
        "\n",
        "                  optimizer.zero_grad()\n",
        "                  output = model(text)\n",
        "\n",
        "                  loss = criterion(output, target)\n",
        "                  running_loss += loss.item()\n",
        "\n",
        "                  # accuracy \n",
        "                  _, predicted = torch.max(output, 1)\n",
        "                  total += target.size(0)\n",
        "                  correct += (predicted == target).sum().item()\n",
        "\n",
        "          v_loss = running_loss/len(valid_batches)\n",
        "          v_acc = correct/total\n",
        "\n",
        "          validation_loss.append(v_loss)\n",
        "          validation_acc.append(v_acc)\n",
        "\n",
        "          print (f'Validation Loss: {v_loss:.4f}, Validation Accuracy: {100*v_acc: .2f}%')\n",
        "          \n",
        "          # If the current epoch has the lowest validation loss, save the model state and use that state for testing\n",
        "          if v_loss < best_validation_loss:\n",
        "              best_validation_loss = v_loss\n",
        "              chosen_train_loss = t_loss\n",
        "              chosen_validation_acc = v_acc\n",
        "              chosen_train_acc = t_acc\n",
        "              #save model to load in testing\n",
        "              torch.save(model.state_dict(), '/content/sample_data/RNN-train.pt')\n",
        "\n",
        "\n",
        "      return train_loss, train_acc, validation_loss, validation_acc, best_validation_loss, chosen_train_loss, chosen_validation_acc, chosen_train_acc\n",
        "\n",
        "# return f1, accuracy, prec, recall\n",
        "def get_metrics(true_labels, pred_labels):\n",
        "    #set average to 'macro' for multiclass problems\n",
        "    f1 = f1_score(true_labels, pred_labels, average= 'macro')\n",
        "    acc = accuracy_score(true_labels, pred_labels)\n",
        "    rec = recall_score(true_labels, pred_labels, average= 'macro')\n",
        "    prec = precision_score(true_labels, pred_labels, average= 'macro')\n",
        "    return f1, acc, rec, prec\n",
        "\n",
        "def metric_test(model,  device, test_batches, choose_best_epoch = True):\n",
        "    \n",
        "    #Load from best epoch\n",
        "    if choose_best_epoch:\n",
        "        model.load_state_dict(torch.load('/content/sample_data/RNN-train.pt'))\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(test_batches):\n",
        "            text = batch.text[0]\n",
        "            target = batch.label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            text, target = text.to(device), target.to(device)\n",
        "\n",
        "            #detatch and convert labels to numpy, then add each to labels array\n",
        "            target_arr = target.detach().cpu().numpy()\n",
        "            for label in target_arr:\n",
        "              labels.append(label)\n",
        "\n",
        "            outputs = model(text)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            preds_arr = predicted.detach().cpu().numpy()\n",
        "            for pred in preds_arr:\n",
        "              predictions.append(pred)\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    labels = np.asarray(labels)\n",
        "    predictions = np.asarray(predictions)\n",
        "    #pdb.set_trace()\n",
        "    f1, acc, rec, prec = get_metrics(labels, predictions)\n",
        "    return f1, acc, rec, prec, model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqDcAiBYVyq6"
      },
      "source": [
        "Notes on RNN notes: These are the final models, though there were many configurations and settings I fiddled with before landing here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAT5tVnDbf_H"
      },
      "source": [
        "GRU RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p17NHD5ll4ZB"
      },
      "source": [
        "#num_layers changes also require corresponding architecture changes\n",
        "class GRURNN(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, vocab_size, embed_size,  num_layers = 2, dropout_prob= 0):\n",
        "        super(GRURNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        #Unidirectional model seemed to perform better than bidirectional\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, num_layers=num_layers, dropout=dropout_prob)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        input = self.embedding(inputs)\n",
        "        input = input.permute(1, 0, 2)\n",
        "        x =  Variable(torch.zeros(self.num_layers, input.size()[1], self.hidden_size).to(device)) \n",
        "        output, x = self.gru(input, x)\n",
        "        x = x.permute(1, 0, 2) \n",
        "        x = x.contiguous().view(x.size()[0], x.size()[1]*x.size()[2])\n",
        "        #Model actually seems to perform better without an additional dropout layer called\n",
        "        #x = self.dropout(x)\n",
        "        outs = self.fc(x)\n",
        "        return outs\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9h9pk9nbjdK"
      },
      "source": [
        "RNN with Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arGoC5RMbYjI"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, vocab_size, embed_size,  num_layers = 2, dropout_prob = 0):\n",
        "        super(BiLSTM, self).__init__(**kwargs)\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
        "                               bidirectional=True, dropout = dropout_prob)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc = nn.Linear(4 * hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        input = self.embedding(inputs.T)\n",
        "    \n",
        "        # (no. of words, batch size, 2 * no. of hidden units).\n",
        "        self.lstm.flatten_parameters()\n",
        "        outputs, _ = self.lstm(input)\n",
        "\n",
        "        # (batch size, 4 * no. of hidden units)\n",
        "        x = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
        "        x = self.dropout(x)\n",
        "        outs = self.fc(x)\n",
        "\n",
        "        return outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr3D_nM2Wd2D"
      },
      "source": [
        "Used same method for hyperparameter tuning on small samples and full samples, as well as for final training/testing (with single values in all arrays but optimizer, which was a planned comparison)\n",
        "\n",
        "Test accuracy only used for final test. Max validation accuracy used for hyperparam tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RnrIwEtFX84"
      },
      "source": [
        "%%time\n",
        "\n",
        "'''\n",
        "lr = [.0002, .0005, .001, .005]\n",
        "optimizers = ['Adam', 'Madgrad']\n",
        "\n",
        "output_size = 5\n",
        "hidden_size = [200, 300] \n",
        "embedding_length = 200\n",
        "epochs = 10\n",
        "dropout = [0, .3, .5]\n",
        "\n",
        "num_layers = 2\n",
        "'''\n",
        "\n",
        "lr = [.001]\n",
        "optimizers = ['Madgrad']\n",
        "\n",
        "output_size = 2\n",
        "hidden_size = [300] \n",
        "embedding_length = 200\n",
        "epochs = 20\n",
        "num_layers = 2\n",
        "dropout = [.5]\n",
        "\n",
        "All_Final_GRU_neut_Results = pd.DataFrame(columns = ['loss_rate', 'dropout', 'hidden_size', 'optimizer',  'test_acc', 'test_f1', 'test_recall', 'test_precision', 'train_acc', 'train_loss', 'validation_acc', 'validation_loss', 'training_time'])\n",
        "\n",
        "for rate in lr:\n",
        "  for d in dropout:\n",
        "    for hid in hidden_size:\n",
        "      for optim_name in optimizers:\n",
        "        start_time = time.time()\n",
        "        rnn_model = GRURNN(output_size, hid, vocab_size, embedding_length, num_layers, d)\n",
        "        rnn_model.to(device)\n",
        "        train_loss, train_acc, validation_loss, validation_acc, best_validation_loss, chosen_train_loss, chosen_validation_acc, chosen_train_acc = train(rnn_model, device, train_batches, valid_batches, epochs, learning_rate = rate, optim = optim_name)\n",
        "        train_time = time.time() - start_time\n",
        "        f1, test_acc, rec, prec, model = metric_test(rnn_model, device, test_batches)\n",
        "\n",
        "        model_file = '/content/drive/Shareddrives/519 Project/Data/Final Results/' + optim_name + '_All_GRU_neut_model.pt'\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        \n",
        "        print('\\n---------------------------------------------')\n",
        "        print('%s, LR OF %.4f, DROPOUT OF %.2f RESULTS' % (optim_name, rate, d))\n",
        "        print(\"--- Time taken to train = %s seconds ---\" % (train_time))\n",
        "        print('TRAIN ACC: %.4f, TRAIN LOSS: %.4f' % (chosen_train_acc, chosen_train_loss))\n",
        "        print('VALIDATION ACC: %.4f, VALIDATION LOSS: %.4f' % (chosen_validation_acc, best_validation_loss))\n",
        "        print('TEST ACC: %.4f, F1: %.4f, RECALL: %.4f, PRECISION: %.4f' % (test_acc, f1, rec, prec))\n",
        "        print('---------------------------------------------\\n')\n",
        "        \n",
        "        All_Final_GRU_neut_Results = All_Final_GRU_neut_Results.append({'loss_rate': rate,\n",
        "                                                'dropout': d,\n",
        "                                                'hidden_size': hid,\n",
        "                                                'optimizer': optim_name,\n",
        "                                                'train_acc' : chosen_train_acc,\n",
        "                                                'train_loss': chosen_train_loss,\n",
        "                                                'validation_acc': chosen_validation_acc,\n",
        "                                                'validation_loss': best_validation_loss,\n",
        "                                                'test_acc': test_acc,\n",
        "                                                'test_f1': f1,\n",
        "                                                'test_recall': rec,\n",
        "                                                'test_precision': prec,\n",
        "                                                'training_time': train_time}, ignore_index = True)\n",
        "      \n",
        "print('\\n-----Best Model-----\\n')\n",
        "display(All_Final_GRU_neut_Results.sort_values('validation_acc', ascending=False).iloc[0])\n",
        "All_Final_GRU_neut_Results.to_csv('/content/drive/Shareddrives/519 Project/Data/Final Results/All_Final_GRU_neut_Results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWzoTu_LFMlg"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "lr = [.0002]\n",
        "optimizers = ['Adam']\n",
        "num_layers = 2\n",
        "output_size = 2\n",
        "hidden_size = [300] \n",
        "embedding_length = 200\n",
        "epochs = 20\n",
        "dropout = [0]\n",
        "\n",
        "All_Final_BiLSTM_neut_Results = pd.DataFrame(columns = ['loss_rate', 'dropout', 'hidden_size', 'optimizer',  'test_acc', 'test_f1', 'test_recall', 'test_precision', 'train_acc', 'train_loss', 'validation_acc', 'validation_loss', 'training_time'])\n",
        "\n",
        "for rate in lr:\n",
        "  for d in dropout:\n",
        "    for hid in hidden_size:\n",
        "      for optim_name in optimizers:\n",
        "        start_time = time.time()\n",
        "        rnn_model = BiLSTM(output_size, hid, vocab_size, embedding_length, num_layers, d)\n",
        "        rnn_model.to(device)\n",
        "        train_loss, train_acc, validation_loss, validation_acc, best_validation_loss, chosen_train_loss, chosen_validation_acc, chosen_train_acc = train(rnn_model, device, train_batches, valid_batches, epochs, learning_rate = rate, optim = optim_name)\n",
        "        train_time = time.time() - start_time\n",
        "        f1, test_acc, rec, prec, model = metric_test(rnn_model, device, test_batches)\n",
        "\n",
        "        model_file = '/content/drive/Shareddrives/519 Project/Data/Final Results/' + optim_name + '_All_BiLSTM_neut_model.pt'\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        \n",
        "        print('\\n---------------------------------------------')\n",
        "        print('%s, LR OF %.4f, DROPOUT OF %.2f RESULTS' % (optim_name, rate, d))\n",
        "        print(\"--- Time taken to train = %s seconds ---\" % (train_time))\n",
        "        print('TRAIN ACC: %.4f, TRAIN LOSS: %.4f' % (chosen_train_acc, chosen_train_loss))\n",
        "        print('VALIDATION ACC: %.4f, VALIDATION LOSS: %.4f' % (chosen_validation_acc, best_validation_loss))\n",
        "        print('TEST ACC: %.4f, F1: %.4f, RECALL: %.4f, PRECISION: %.4f' % (test_acc, f1, rec, prec))\n",
        "        print('---------------------------------------------\\n')\n",
        "        \n",
        "        All_Final_BiLSTM_neut_Results = All_Final_BiLSTM_neut_Results.append({'loss_rate': rate,\n",
        "                                                'dropout': d,\n",
        "                                                'hidden_size': hid,\n",
        "                                                'optimizer': optim_name,\n",
        "                                                'train_acc' : chosen_train_acc,\n",
        "                                                'train_loss': chosen_train_loss,\n",
        "                                                'validation_acc': chosen_validation_acc,\n",
        "                                                'validation_loss': best_validation_loss,\n",
        "                                                'test_acc': test_acc,\n",
        "                                                'test_f1': f1,\n",
        "                                                'test_recall': rec,\n",
        "                                                'test_precision': prec,\n",
        "                                                'training_time': train_time}, ignore_index = True)\n",
        "      \n",
        "print('\\n-----Best Model-----\\n')\n",
        "display(All_Final_BiLSTM_neut_Results.sort_values('validation_acc', ascending=False).iloc[0])\n",
        "All_Final_BiLSTM_neut_Results.to_csv('/content/drive/Shareddrives/519 Project/Data/Final Results/All_Final_BiLSTM_neut_Results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2nB0E34amzn"
      },
      "source": [
        "Load/display downsampled hyperparam training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWQ7CYdBs6al"
      },
      "source": [
        "All_Final_GRU_neut_Results_small = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/Subsample Results/all_small_GRU_neutrality_results.csv')\n",
        "All_Final_BiLSTM_neut_Results_small = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/Subsample Results/all_small_BiLSTM_neutrality_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcQiKI8uE2C"
      },
      "source": [
        "display(All_Final_BiLSTM_neut_Results_small[All_Final_BiLSTM_neut_Results_small['optimizer'] == 'Madgrad'].sort_values('validation_acc', ascending=False).iloc[0])\n",
        "display(All_Final_BiLSTM_neut_Results_small[All_Final_BiLSTM_neut_Results_small['optimizer'] == 'Adam'].sort_values('validation_acc', ascending=False).iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnNQkBAz1Ev7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}