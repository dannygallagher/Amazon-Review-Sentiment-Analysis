{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYtb4z0LzVl"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjOajYcXsl_N",
        "outputId": "159f77c3-3d88-4e72-dd26-bfd54021b4d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/Shareddrives/519 Project/Data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h8fE9mfMOkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ec214f-81e5-4bc3-cf40-e632c2e7b281"
      },
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "#gift_card_path = os.path.join(path, 'Gift_Cards_5.json.gz')\n",
        "#df = getDF(electronics_path)\n",
        "\n",
        "electronics_path = os.path.join(path, 'electronics_downsampled_pos_neg_binary.csv')\n",
        "df = pd.read_csv(electronics_path)\n",
        "#df = df[['reviewText', 'overall']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2xjnwNBFgiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e372cd7d-8bad-4ada-b1eb-a5eeed83646c"
      },
      "source": [
        "#preprocessing\n",
        "\n",
        "#TODO: add in Dan's preprocessing code\n",
        "df = df[['reviewText', 'pos_neg']]\n",
        "df = df.rename(columns = {'pos_neg': 'overall'})\n",
        "\n",
        "df = df[df['reviewText'].notna()]\n",
        "print(df.columns)\n",
        "\n",
        "#from spell_check import fixSentence\n",
        "#df['reviewText'] = df['reviewText'].apply(lambda x: fixSentence(x))\n",
        "\n",
        "#print('CHECKPOINT: Spell Check Complete')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['reviewText', 'overall'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1jt03k-c9_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40df62d9-0a39-4104-da4c-cea088a3adcf"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "def tokenize(sentence):\n",
        "  tokens = token.tokenize(sentence)\n",
        "  filtered = [x for x in tokens if not x in stop_words]\n",
        "  return filtered\n",
        "\n",
        "df['tokenized'] = df['reviewText'].apply(tokenize)\n",
        "df = df[['tokenized', 'overall']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHEsEPBqMc8"
      },
      "source": [
        "#df['overall_adj'] = df['overall'].apply(lambda x: 1 if x > 3 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "iG_2LD7LTv9x",
        "outputId": "71ee2adb-a2d4-4df6-ec94-7da83ceac7b7"
      },
      "source": [
        "len_tokens = [len(i) for i in df['tokenized']]\n",
        "pd.Series(len_tokens).hist()\n",
        "plt.title('Tokenized Review Length')\n",
        "plt.show()\n",
        "pd.Series(len_tokens).describe()\n",
        "\n",
        "df['len'] = df['tokenized'].apply(lambda x: len(x))\n",
        "df = df.loc[df['len'] >= 4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VcuT5xJ9Lj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size = .2, random_state = 42)\n",
        "\n",
        "train_json = train_df.to_json(orient = 'records')\n",
        "train_json_result = json.loads(train_json)\n",
        "print(train_json)\n",
        "with open('sample_data/train_gift_cards.json', 'w') as f:\n",
        "  for entry in train_json_result:\n",
        "    json.dump(entry, f)\n",
        "    f.write('\\n')\n",
        "\n",
        "test_json = test_df.to_json(orient = 'records')\n",
        "test_json_result = json.loads(test_json)\n",
        "with open('sample_data/test_gift_cards.json', 'w') as f:\n",
        "  for entry in test_json_result:\n",
        "    json.dump(entry, f)\n",
        "    f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDxun1vxMgZ6"
      },
      "source": [
        "MAX_LEN = 277"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psAvAvJuMz4-",
        "outputId": "f1cc55d9-30ca-4006-c639-02fe4306068e"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "\n",
        "TOKENS = data.Field(lower = True, batch_first = True)\n",
        "SCORE = data.LabelField(dtype = torch.float)\n",
        "\n",
        "fields = {'tokenized': ('tokens', TOKENS), 'overall': ('score', SCORE)}\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = 'sample_data',\n",
        "    train = 'train_gift_cards.json',\n",
        "    test = 'test_gift_cards.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")\n",
        "print(vars(train_data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tokens': ['a', 'great', 'way', 'get', 'want'], 'score': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL09fdZMPyL"
      },
      "source": [
        "TOKENS.build_vocab(train_data, \n",
        "                   max_size = 10000,\n",
        "                   vectors = \"glove.6B.100d\", \n",
        "                   unk_init = torch.Tensor.normal_)\n",
        "SCORE.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64V9jCNeMIGt"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator = data.BucketIterator(train_data, sort_key = lambda x: x.tokens, batch_size= 32, device = device)\n",
        "test_iterator = data.BucketIterator(test_data, sort_key = lambda x: x.tokens, batch_size= 1, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdWzbgXZTqZi"
      },
      "source": [
        "'''\n",
        "model architecture taken from: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
        "'''\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Text(nn.Module):\n",
        "    ''' Define network architecture and forward path. '''\n",
        "    def __init__(self, vocab_size, \n",
        "                 vector_size, n_filters, \n",
        "                 filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        # Create word embeddings from the input words     \n",
        "        self.embedding = nn.Embedding(vocab_size, vector_size, \n",
        "                                      padding_idx = pad_idx)\n",
        "        \n",
        "        # Specify convolutions with filters of different sizes (fs)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, vector_size)) \n",
        "                                    for fs in filter_sizes])\n",
        "        \n",
        "        # Add a fully connected layer for final predicitons\n",
        "        self.linear = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        # Drop some of the nodes to increase robustness in training\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, text):\n",
        "        '''Forward path of the network.'''       \n",
        "        # Get word embeddings and formt them for convolutions\n",
        "        embedded = self.embedding(text).unsqueeze(1)\n",
        "        \n",
        "        # Perform convolutions and apply activation functions\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        # Pooling layer to reduce dimensionality    \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        # Dropout layer\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        return self.linear(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPLw0QxmVoWc"
      },
      "source": [
        "input_dim = len(TOKENS.vocab)\n",
        "embedding_dim = 100\n",
        "n_filters = 100\n",
        "filter_sizes = [1,2,3,4]\n",
        "output_dim = 1\n",
        "dropout = .5\n",
        "pad_idx = TOKENS.vocab.stoi[TOKENS.pad_token]\n",
        "\n",
        "model = CNN_Text(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wufh0kuJWari"
      },
      "source": [
        "pretrained_embeddings = TOKENS.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "unk_idx = TOKENS.vocab.stoi[TOKENS.unk_token]\n",
        "\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17G86lZFbEBc"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCzbsXRDK7iM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "76b61228-4020-48ec-dc85-144b419835c3"
      },
      "source": [
        "\"\"\"\n",
        "Basic train loop for cnn\n",
        "\"\"\"\n",
        "def train_cnn(model, iterator, optimizer, criterion, epochs=10):\n",
        "    for child in model.children():\n",
        "      if hasattr(child, 'reset_parameters'):\n",
        "        child.reset_parameters()\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    for epoch in range(epochs):\n",
        "      epoch_acc = 0\n",
        "      epoch_loss = 0\n",
        "      for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        print(len)\n",
        "        outputs = model(batch.tokens).squeeze(1)\n",
        "        loss = criterion(outputs, batch.score)\n",
        "        epoch_acc += binary_accuracy(outputs, batch.score).item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "      epoch_acc = epoch_acc / len(iterator)\n",
        "      epoch_loss = epoch_loss / len(iterator)\n",
        "      accuracy_list.append(epoch_acc)\n",
        "      loss_list.append(epoch_loss)\n",
        "      print('Epoch Num: %d, Accuracy: %.4f, Loss: %.4f' % (epoch + 1, epoch_acc, epoch_loss))\n",
        "\n",
        "    final_training_accuracy = accuracy_list[-1]     \n",
        "    final_training_loss = loss_list[-1]\n",
        "    return final_training_loss, final_training_accuracy\n",
        "\n",
        "train_cnn(model, train_iterator, optimizer, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6b11f17591f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_training_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_training_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-6b11f17591f9>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model, iterator, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hX1n_IFZero"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}