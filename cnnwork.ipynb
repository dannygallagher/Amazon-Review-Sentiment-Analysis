{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHXfPL3cEZUB"
      },
      "source": [
        "%pip install autocorrect\n",
        "%pip install madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYtb4z0LzVl"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjOajYcXsl_N",
        "outputId": "6c6a5a0f-28e4-4b7a-cb3c-a5a28a76a9a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h8fE9mfMOkj"
      },
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "#path = '/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/'\n",
        "\n",
        "#electronics_train_path = os.path.join(path, 'electronics_train.csv')\n",
        "#electronics_test_path = os.path.join(path, 'electronics_test.csv')\n",
        "\n",
        "#allcats_train_path = os.path.join(path, 'all_train.csv')\n",
        "#allcats_test_path = os.path.join(path, 'all_test.csv')\n",
        "\n",
        "#train_df = pd.read_csv(electronics_train_path)\n",
        "#test_df = pd.read_csv(electronics_test_path)'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq9RAO1p7Usz"
      },
      "source": [
        "def cleanup(df, binary):\n",
        "    df = df[['title_plus_review', 'overall']]\n",
        "    df['overall'] = df['overall'].apply(lambda x: x if isinstance(x, float) else None)\n",
        "    if binary:\n",
        "        df['overall_adj'] = df['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
        "        df = df[['overall_adj', 'title_plus_review']]\n",
        "        df = df.rename(columns = {'overall_adj': 'overall', 'title_plus_review': 'reviewText'})\n",
        "    df = df.dropna()\n",
        "    df = df.rename(columns = {'title_plus_review': 'reviewText'})\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1jt03k-c9_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fba84f-c74a-4072-b98a-89a06ccf277e"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "def tokenize(sentence):\n",
        "  tokens = token.tokenize(sentence)\n",
        "  filtered = [x for x in tokens if not x in stop_words]\n",
        "  return filtered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiQfjL8SpqLR"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train_df, test_df = train_test_split(train_df, test_size = .2, random_state = 42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VcuT5xJ9Lj"
      },
      "source": [
        "def output_to_json(train_df, test_df):\n",
        "    train_json = train_df.to_json(orient = 'records')\n",
        "    train_json_result = json.loads(train_json)\n",
        "    with open('sample_data/train.json', 'w') as f:\n",
        "      for entry in train_json_result:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')\n",
        "\n",
        "    test_json = test_df.to_json(orient = 'records')\n",
        "    test_json_result = json.loads(test_json)\n",
        "    with open('sample_data/test.json', 'w') as f:\n",
        "      for entry in test_json_result:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psAvAvJuMz4-"
      },
      "source": [
        "def get_data_tokens_score(binary):\n",
        "    TOKENS = data.Field(lower = True, batch_first = True)\n",
        "    if binary:\n",
        "        SCORE = data.LabelField(dtype = torch.float)\n",
        "    else:\n",
        "        SCORE = data.LabelField(dtype = torch.long)\n",
        "\n",
        "    fields = {'tokenized': ('tokens', TOKENS), 'overall': ('score', SCORE)}\n",
        "    train_data, test_data = data.TabularDataset.splits(\n",
        "        path = 'sample_data',\n",
        "        train = 'train.json',\n",
        "        test = 'test.json',\n",
        "        format = 'json',\n",
        "        fields = fields\n",
        "    )\n",
        "\n",
        "    TOKENS.build_vocab(train_data, \n",
        "                      max_size = 10000,\n",
        "                      vectors = \"glove.6B.100d\", \n",
        "                      unk_init = torch.Tensor.normal_)\n",
        "    SCORE.build_vocab(train_data)\n",
        "\n",
        "    return train_data, test_data, TOKENS, SCORE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64V9jCNeMIGt"
      },
      "source": [
        "import torch\n",
        "\n",
        "def get_iters(train_data, test_data):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    train_iterator = data.BucketIterator(train_data, sort_key = lambda x: x.tokens, \n",
        "                                        sort = False, sort_within_batch = True, batch_size= 64, device = device)\n",
        "    test_iterator = data.BucketIterator(test_data, sort_key = lambda x: x.tokens, \n",
        "                                        sort = False, sort_within_batch = True, batch_size= 64, device = device)\n",
        "    return train_iterator, test_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDousd4g3cl"
      },
      "source": [
        "def get_iters_tokens(dataset, binary):\n",
        "    path = '/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/'\n",
        "    if dataset == 'electronics':\n",
        "        electronics_train_path = os.path.join(path, 'electronics_train.csv')\n",
        "        electronics_test_path = os.path.join(path, 'electronics_test.csv')\n",
        "\n",
        "        train_df = pd.read_csv(electronics_train_path)\n",
        "        test_df = pd.read_csv(electronics_test_path)\n",
        "    else:\n",
        "        allcats_train_path = os.path.join(path, 'all_train.csv')\n",
        "        allcats_test_path = os.path.join(path, 'all_test.csv')\n",
        "\n",
        "        train_df = pd.read_csv(allcats_train_path)\n",
        "        test_df = pd.read_csv(allcats_test_path)\n",
        "    \n",
        "    train_df = cleanup(train_df, binary)\n",
        "    test_df = cleanup(test_df, binary)\n",
        "\n",
        "    train_df['tokenized'] = train_df['reviewText'].apply(tokenize)\n",
        "    train_df = train_df[['tokenized', 'overall']]\n",
        "\n",
        "    test_df['tokenized'] = test_df['reviewText'].apply(tokenize)\n",
        "    test_df = test_df[['tokenized', 'overall']]\n",
        "\n",
        "    output_to_json(train_df, test_df)\n",
        "\n",
        "    train_data, test_data, TOKENS, SCORE = get_data_tokens_score(binary)\n",
        "    train_iterator, test_iterator = get_iters(train_data, test_data)\n",
        "\n",
        "    return train_iterator, test_iterator, TOKENS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx-jdoldBEDw"
      },
      "source": [
        "## CNN's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdWzbgXZTqZi"
      },
      "source": [
        "'''\n",
        "model architecture taken from: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
        "'''\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self, vocab_size, \n",
        "                 vector_size, n_filters, \n",
        "                 filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vector_size, \n",
        "                                      padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, vector_size)) \n",
        "                                    for fs in filter_sizes])\n",
        "        \n",
        "        self.linear = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text).unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        return self.linear(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPLw0QxmVoWc"
      },
      "source": [
        "def get_cnn_model(num_classes, TOKENS):\n",
        "  input_dim = len(TOKENS.vocab)\n",
        "  embedding_dim = 100\n",
        "  n_filters = 100\n",
        "  filter_sizes = [1,2,3,4]\n",
        "  output_dim = num_classes\n",
        "  dropout = .5\n",
        "  pad_idx = TOKENS.vocab.stoi[TOKENS.pad_token]\n",
        "\n",
        "  model = CNN_Text(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)\n",
        "  pretrained_embeddings = TOKENS.vocab.vectors\n",
        "  model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "  unk_idx = TOKENS.vocab.stoi[TOKENS.unk_token]\n",
        "\n",
        "  model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "  model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEpTN2bS_m8y"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def get_f1_score(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    score = f1_score(y.cpu().detach().numpy(), rounded_preds.cpu().detach().numpy(), average = 'macro')\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17G86lZFbEBc"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tQdt2U1VSBF"
      },
      "source": [
        "def five_f1_score(preds, y):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    score = f1_score(y.cpu().detach().numpy(), predicted.cpu().detach().numpy(), average = 'macro')\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJD_he06UemC"
      },
      "source": [
        "def five_accuracy(preds, y):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct / len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCzbsXRDK7iM"
      },
      "source": [
        "\"\"\"\n",
        "Basic train loop for cnn\n",
        "\n",
        "Tuning learning rate, \n",
        "\n",
        "\"\"\"\n",
        "def train_cnn(model, iterator, optimizer, criterion, epochs=10, print_intermediate = False, five_class = False):\n",
        "    for child in model.children():\n",
        "      if hasattr(child, 'reset_parameters'):\n",
        "        child.reset_parameters()\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    f1_list = []\n",
        "    print('Starting Training\\n')\n",
        "    for epoch in range(epochs):\n",
        "      epoch_acc = 0\n",
        "      epoch_loss = 0\n",
        "      epoch_f1 = 0\n",
        "      i = 0\n",
        "      seen_since_last_print = 0\n",
        "      for batch in iterator:\n",
        "        i += 1\n",
        "        seen_since_last_print += 1\n",
        "\n",
        "        inputs = batch.tokens\n",
        "        labels = batch.score\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        if five_class:\n",
        "            epoch_f1 += five_f1_score(outputs, labels)\n",
        "            epoch_acc += five_accuracy(outputs, labels)\n",
        "        else:\n",
        "            epoch_f1 += get_f1_score(outputs, labels)\n",
        "            epoch_acc += binary_accuracy(outputs, labels).item()\n",
        "\n",
        "        \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "        if print_intermediate:\n",
        "          if (seen_since_last_print / len(iterator)) > .1:\n",
        "            percent = 100 * i / len(iterator)\n",
        "            print('Epoch %d is %d%% done' % (epoch + 1, percent))\n",
        "            seen_since_last_print = 0\n",
        "\n",
        "      epoch_acc = epoch_acc / len(iterator)\n",
        "      epoch_loss = epoch_loss / len(iterator)\n",
        "      epoch_f1 = epoch_f1 / len(iterator)\n",
        "      accuracy_list.append(epoch_acc)\n",
        "      loss_list.append(epoch_loss)\n",
        "      f1_list.append(epoch_f1)\n",
        "      print('\\nEpoch Num: %d, Accuracy: %.4f, Loss: %.4f, F1: %.4f\\n' % (epoch + 1, epoch_acc, epoch_loss, epoch_f1))\n",
        "\n",
        "    final_training_accuracy = accuracy_list[-1]     \n",
        "    final_training_loss = loss_list[-1]\n",
        "    final_training_f1 = f1_list[-1]\n",
        "    print('Done training\\n')\n",
        "    return final_training_accuracy, final_training_loss, final_training_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5AF4hxLZ9I7"
      },
      "source": [
        "def test_cnn_model(model, iterator, criterion, five_class = False):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    test_f1 = 0 \n",
        "    with torch.no_grad():\n",
        "      for batch in iterator:\n",
        "        outputs = model(batch.tokens).squeeze(1)\n",
        "        loss = criterion(outputs, batch.score)\n",
        "        test_loss += loss.item()\n",
        "        if five_class:\n",
        "            test_acc += five_accuracy(outputs, batch.score)\n",
        "            test_f1 += five_f1_score(outputs, batch.score)\n",
        "        else:\n",
        "            test_acc += binary_accuracy(outputs, batch.score)\n",
        "            test_f1 += get_f1_score(outputs, batch.score)\n",
        "    \n",
        "    testing_accuracy = test_acc / len(iterator)   \n",
        "    testing_loss = test_loss / len(iterator)\n",
        "    testing_f1 = test_f1 / len(iterator) \n",
        "    return testing_accuracy, testing_loss, testing_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3A81rpu-Kli"
      },
      "source": [
        "import madgrad\n",
        "\n",
        "model = get_cnn_model(num_classes = 1)\n",
        "optimizer = madgrad.MADGRAD(model.parameters(), lr = .001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_acc, train_loss, train_f1 = train_cnn(model, train_iterator, optimizer, criterion, epochs = 10, print_intermediate = True, five_class = False)\n",
        "test_acc, test_loss, test_f1 =  test_cnn_model(model, test_iterator, criterion, five_class = False)\n",
        "\n",
        "print('\\n---------------------------------------------')\n",
        "print('FULL TRAINING RESULTS (MADGRAD, lr .001)')\n",
        "print('TRAIN ACC: %.4f, TRAIN LOSS: %.4f, TRAIN f1: %.4f' % (train_acc, train_loss, train_f1))\n",
        "print('TEST ACC: %.4f, TEST LOSS: %.4f, TEST f1: %.4f' % (test_acc, test_loss, test_f1))\n",
        "print('---------------------------------------------\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBE9HyM_d7K1"
      },
      "source": [
        "def single_train_test_loop(summary_df, dataset_name, num_classes, optim_name, train_iter, test_iter, tokens):\n",
        "    model = get_cnn_model(num_classes = num_classes, TOKENS = tokens)\n",
        "    if optim_name == 'madgrad':\n",
        "        optimizer = madgrad.MADGRAD(model.parameters(), lr = .001)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = .001)\n",
        "    \n",
        "    if num_classes == 1:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    five_classes = (num_classes == 5)\n",
        "\n",
        "    train_acc, train_loss, train_f1 = train_cnn(model, train_iter, optimizer, criterion, print_intermediate=True, five_class=five_classes)\n",
        "    test_acc, test_loss, test_f1 = test_cnn_model(model, train_iter, criterion, five_class = five_classes)\n",
        "\n",
        "    print('-----------------------------------')\n",
        "    print('Test Statistics: ')\n",
        "    print(test_acc, test_loss, test_f1)\n",
        "    print('-----------------------------------')\n",
        "\n",
        "    prediction_type = 'five class' if num_classes == 5 else 'binary'\n",
        "    new_row = {'dataset': dataset_name, 'predicton_type': prediction_type, 'optimizer': optim_name,\n",
        "              'lr': .001, 'train_acc': train_acc, 'train_loss': train_loss, 'train_f1': train_f1,\n",
        "              'test_acc': test_acc, 'test_loss': test_loss, 'test_f1': test_f1}\n",
        "    summary_df.append(new_row, ignore_index = True)\n",
        "    return model, summary_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b-pnie7ZpdC"
      },
      "source": [
        "\"\"\"\n",
        "Comparing different algorithms\n",
        "\"\"\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cols = ['dataset', 'prediction_type', 'optimizer', 'lr', 'train_acc', 'train_loss', \\\n",
        "        'train_f1', 'test_acc', 'test_loss', 'test_f1']\n",
        "\n",
        "summary_df = pd.DataFrame(columns = cols)\n",
        "\n",
        "#compare binary electronics vs. binary allcats\n",
        "bin_elec_train_iter, bin_elec_test_iter, bin_elec_tokens = get_iters_tokens(dataset = 'electronics', binary = True)\n",
        "bin_elec_model, summary_df = single_train_test_loop(summary_df, 'electronics', 1, 'madgrad', \\\n",
        "                                        bin_elec_train_iter, bin_elec_test_iter,\n",
        "                                        bin_elec_tokens)\n",
        "\n",
        "print(summary_df)\n",
        "\n",
        "bin_all_train_iter, bin_all_test_iter, bin_all_tokens = get_iters_tokens(dataset = 'all', binary = True)\n",
        "bin_all_madgrad_model, summary_df = single_train_test_loop(summary_df, 'allcats', 1, 'madgrad', \\\n",
        "                                        bin_all_train_iter, bin_all_test_iter,\n",
        "                                        bin_all_tokens)\n",
        "\n",
        "\n",
        "#compare binary allcats vs. five allcats\n",
        "five_all_train, five_all_test, five_all_tokens = get_iters_tokens(dataset = 'all', binary = False)\n",
        "five_all_madgrad_model, summary_df = single_train_test_loop(summary_df, 'allcats', 5, 'madgrad', \\\n",
        "                                        five_all_train, five_all_test,\n",
        "                                        five_all_tokens)\n",
        "\n",
        "#compare adam to madgrad\n",
        "bin_all_adam_model, summary_df = single_train_test_loop(summary_df, 'allcats', 1, 'adam', \\\n",
        "                                        bin_all_train_iter, bin_all_test_iter,\n",
        "                                        bin_all_tokens)\n",
        "\n",
        "\n",
        "five_all_adam_model, summary_df = single_train_test_loop(summary_df, 'allcats', 5, 'adam', \\\n",
        "                                        five_all_train, five_all_test, \n",
        "                                        five_all_tokens)\n",
        "\n",
        "summary_df.to_csv('/content/drive/Shareddrives/519 Project/Data/Final Results/CNN_comparison_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}