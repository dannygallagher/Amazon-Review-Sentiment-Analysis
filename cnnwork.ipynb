{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/site-packages (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/site-packages (0.9.1)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.6/site-packages (from torchtext) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from torchtext) (4.60.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from torchtext) (2.25.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from torch==1.8.1->torchtext) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->torchtext) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->torchtext) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->torchtext) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/site-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install torch\n",
    "%pip install torchtext\n",
    "%pip install nltk\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ALYtb4z0LzVl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjOajYcXsl_N",
    "outputId": "401980e8-1a01-42b9-ea4d-efd8394c7cfe"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path = '/content/drive/Shareddrives/519 Project/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5h8fE9mfMOkj"
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "#gift_card_path = os.path.join(path, 'Gift_Cards_5.json.gz')\n",
    "#df = getDF(gift_card_path)\n",
    "\n",
    "electronics_aws_path = 'electronics_downsampled_pos_neg_binary.csv'\n",
    "\n",
    "#electronics_path = os.path.join(path, 'electronics_downsampled_pos_neg_binary.csv')\n",
    "df = pd.read_csv(electronics_aws_path, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2xjnwNBFgiH",
    "outputId": "a8c0524b-e0d9-46b7-a7ff-b4aee9460366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviewText', 'overall'], dtype='object')\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "#TODO: add in Dan's preprocessing code\n",
    "df = df[['reviewText', 'pos_neg']]\n",
    "df = df.rename(columns = {'pos_neg': 'overall'})\n",
    "\n",
    "#df = df[['reviewText', 'overall']]\n",
    "df = df[df['reviewText'].notna()]\n",
    "print(df.columns)\n",
    "print('hi')\n",
    "\n",
    "#from spell_check import fixSentence\n",
    "#df['reviewText'] = df['reviewText'].apply(lambda x: fixSentence(x))\n",
    "\n",
    "#print('CHECKPOINT: Spell Check Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1jt03k-c9_-",
    "outputId": "aa1aa4aa-1d2b-49b6-8327-165b52092f4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "def tokenize(sentence):\n",
    "  tokens = token.tokenize(sentence)\n",
    "  filtered = [x for x in tokens if not x in stop_words]\n",
    "  return filtered\n",
    "\n",
    "df['tokenized'] = df['reviewText'].apply(tokenize)\n",
    "df = df[['tokenized', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWHEsEPBqMc8"
   },
   "outputs": [],
   "source": [
    "#df['overall_adj'] = df['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
    "#df = df[['tokenized', 'overall_adj']]\n",
    "#df = df.rename(columns = {'overall_adj': 'overall'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "iG_2LD7LTv9x",
    "outputId": "ac3a3add-7d68-47df-de5e-62807634f3b7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWgElEQVR4nO3ce5RlZX3m8e8jNw3tAArpIBBaDWoQJg50EKOj1YlRIBecWSSBYSkoijESdaIzgjpoMjrBLC+JijKtIpogbeIltGhCUGmQmaDSBrkGbbUTQKDl1tjKmKC/+WPvwmOlqutU1amq06/fz1pn9T57v2fv5+yqevqc91xSVUiSdnwPWe4AkqTRsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoWtGSSaS3LII+z0nyf8Y8T5PTnLFKPc55HGvTzKx1MddaknOS/LG5c6h7bPQf0Ik2TZw+WGS+weun7iUWarqd6vqfy7V8ZKsSlID93dzktNHse+qemJVbRjFvqazHP9RLdd/jlq4nZc7gJZGVa2YXE6yGXhhVX1m+RItiz2r6oEkq4HLkmysqkuWO5Q0Kj5C/wmXZLckf5rkW/3lT5PsNsPYlyW5Icn+/e3ekuSfk9zRT6M8rB83keSWJK9MsiXJbUmeP7CfB5++J/nkNM8eTu63PSHJJUnuTnJTkt8e2Mcjk6xPcl+SLwKPHfY+V9VVwPXAkwb294IkNya5J8nFSQ7s178nyVumnIcLk/xBv7w5yTP75YckOT3J15PcleQvkzyi3/bBJK/sl/frnzG8tL/+2P4+zunvcZbzc16Ss5N8Ksl3knwhyWMHtj+rv83WJO9OclmSFyb5eeAc4Cn9z+PegUPuNdP+NB4sdL0WOJKu3H4BOAJ43dRBSc4ETgaeUVW3AGcBj+tv93PAfsCZAzf5GWCPfv0pwNlJ9pq636r6japa0T+D+C3gduCzSXYHLgE+DPw0cDzw7iQH9zc9G/h/wL7AC/rLUJIcCRwCbOqvHwu8BvjPwD7A54EL+uEXAL+TJP3YvYBnAeum2fXvA88BngE8CrinzwlwGTDRLz8D+Abw9IHrn6+qH87hPsx2fujX/SGwV39f39Tfdm/go8AZwCOBm4BfAqiqG4HfBf6+/7nsOdv+NEaqatkuwLnAFuC6Icf/NnAD3aOrDy9n9h35AmwGntkvfx04ZmDbs4HN/fIEcCvwNuAKYI9+fYDvAo8duN1TgG8O3O5+YOeB7VuAI/vl84A3Tsn0uH7M0/rrv0NXcoNj/jfwemAn4F+BJwxs+1/AFTPc31VAAff2uQp4C5B++98ApwyMfwjwPeDA/r7+M/D0ftuLgM/NcC5vBH5lYNu+fc6d6Z5B3NPv+xzgxcAt/bgPAn8wQ/aTp7tf2zs/A+f4fQPbjgH+sV9+Hl1hT24LcDPdNNy0x9ze/ryMz2W5H6GfBxw1zMAkB9E9onhqVT0ReMXixfqJ8ijgnwau/1O/btKewKnAH1fV1n7dPsBPARuT3Ns/Lf/bfv2ku6rqgYHr3wNWMI0kewAXAq+rqskX4w4Enjy5//4YJ9I98t+HriRvnpJ7Nnv3GV5J95/OLgPH+rOB49xNV3L7Vdde64AT+rH/BTh/hv0fCHxiYD83Aj8AVlbV1+n+E3wS8B+Bi4BvJXk83SP0y4bIP/VYM52fSbcPLA+e/0cxcO76+zjMu5lm2p/GxLIWelVdTvfH86B+PvFvk2xM8vkkT+g3vQg4u6ru6W+7ZYnjtupbdOUw6Wf7dZPuAX4d+ECSp/br7qR7pPvEqtqzv+xRAy+8DqufN/4wcGlVrR3YdDNw2cD+96xuCuAlwLeBB4ADpuSeVVX9oKreRjdd83sDx3rxlGM9rKr+b7/9AuC4fl79ycDHZtj9zcDRU/bz0Kq6td9+GXAcsGu/7jLgJLopjKuHyT/lWDOdn9ncBuw/eaWfTtp/YLtfwbqDWu5H6NNZC/x+VR0OvAp4d7/+ccDjkvyfJFcmGeqRvWZ1AfC6JPv0c6tnAn8xOKC6t+WdCHw8yRHVzfW+F3h7kp+GB1/oe/Y8jv8mYHfg5VPWX0T3835ukl36yy8m+fmq+gHwceANSX6qnzc+aY7HPQv470keSjcFckaSJ/b3ZY8kvzU5sKr+ge4/sfcBF1fVvTPs8xzgTQMvqO7Tz89Pugw4Dbi8v76hv35Ff59mkiQPHbywnfMzxH3/FHBokuck2Rl4KT/+yP4OYP8kuw6xL42RsSr0JCvoXpz5qyRX080J7ttv3hk4iO6p8gnAe5PsufQpm/NG4CrgGuBa4Mv9uh9T3dv7XgB8MslhwKvpXhi7Msl9wGeAx8/j+CfQvSh7TwbeF19V36F78fF4umcMtwNvBibfgXMa3VP+2+mm7j4wx+N+iu7Zx4uq6hP9vtf19+U64Ogp4z8MPLP/dyZ/BqwH/i7Jd4Ar6R7RT7oMeDg/KvQr6KauLmf7fonuGdHUy/bOz4yq6k66F6D/BLgLOJjud+D7/ZDP0b1OdXuSO2fbn8bH5ItCyxcgWQVcVFWHJPl3wE1Vte80484BvlBVH+ivfxY4vaq+tKSBpcb00163ACdW1aXLnUfzN1aP0KvqPuCbk0930/mFfvNf07/tq58aeBzdW78kzVGSZyfZM91nDl5D9yLwlcscSwu0rIWe5ALg74HHp/sgyil0c7WnJPkK3dO+yTnIi4G7ktwAXAr8t6q6azlySw14Ct1bVu8EfgN4TlXdv7yRtFDLPuUiSRqNsZpykSTN37J9Odfee+9dq1atmtdtv/vd77L77ruPNtCImXE0zLhw454PzDgXGzduvLOq9pl243J9RPXwww+v+br00kvnfdulYsbRMOPCjXu+KjPOBXBVjelH/yVJI2KhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhqxbB/9X4hrb93Kyad/almOvfmsX1uW40rSbHyELkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjZi30JAckuTTJDUmuT/LyacYkyTuSbEpyTZLDFieuJGkmOw8x5gHglVX15SQPBzYmuaSqbhgYczRwUH95MvCe/l9J0hKZ9RF6Vd1WVV/ul78D3AjsN2XYscCHqnMlsGeSfUeeVpI0o1TV8IOTVcDlwCFVdd/A+ouAs6rqiv76Z4FXV9VVU25/KnAqwMqVKw9ft27dvEJvuXsrd9w/r5su2KH77THUuG3btrFixYpFTrMwZhyNcc847vnAjHOxZs2ajVW1erptw0y5AJBkBfAx4BWDZT4XVbUWWAuwevXqmpiYmM9ueOf5F/LWa4eOPlKbT5wYatyGDRuY7/1bKmYcjXHPOO75wIyjMtS7XJLsQlfm51fVx6cZcitwwMD1/ft1kqQlMsy7XAK8H7ixqt42w7D1wPP6d7scCWytqttGmFOSNIth5i2eCjwXuDbJ1f261wA/C1BV5wCfBo4BNgHfA54/8qSSpO2atdD7Fzozy5gCXjqqUJKkufOTopLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqxKyFnuTcJFuSXDfD9okkW5Nc3V/OHH1MSdJsdh5izHnAu4APbWfM56vq10eSSJI0L7M+Qq+qy4G7lyCLJGkBUlWzD0pWARdV1SHTbJsAPgbcAnwLeFVVXT/Dfk4FTgVYuXLl4evWrZtX6C13b+WO++d10wU7dL89hhq3bds2VqxYschpFsaMozHuGcc9H5hxLtasWbOxqlZPt22YKZfZfBk4sKq2JTkG+GvgoOkGVtVaYC3A6tWra2JiYl4HfOf5F/LWa0cRfe42nzgx1LgNGzYw3/u3VMw4GuOecdzzgRlHZcHvcqmq+6pqW7/8aWCXJHsvOJkkaU4WXOhJfiZJ+uUj+n3etdD9SpLmZtZ5iyQXABPA3kluAV4P7AJQVecAxwEvSfIAcD9wfA0zMS9JGqlZC72qTphl+7vo3tYoSVpGflJUkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2YtdCTnJtkS5LrZtieJO9IsinJNUkOG31MSdJshnmEfh5w1Ha2Hw0c1F9OBd6z8FiSpLmatdCr6nLg7u0MORb4UHWuBPZMsu+oAkqShpOqmn1Qsgq4qKoOmWbbRcBZVXVFf/2zwKur6qppxp5K9yielStXHr5u3bp5hd5y91buuH9eN12wQ/fbY6hx27ZtY8WKFYucZmHMOBrjnnHc84EZ52LNmjUbq2r1dNt2XsogVbUWWAuwevXqmpiYmNd+3nn+hbz12iWN/qDNJ04MNW7Dhg3M9/4tFTOOxrhnHPd8YMZRGcW7XG4FDhi4vn+/TpK0hEZR6OuB5/XvdjkS2FpVt41gv5KkOZh13iLJBcAEsHeSW4DXA7sAVNU5wKeBY4BNwPeA5y9WWEnSzGYt9Ko6YZbtBbx0ZIkkSfPiJ0UlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1IihCj3JUUluSrIpyenTbD85ybeTXN1fXjj6qJKk7dl5tgFJdgLOBn4VuAX4UpL1VXXDlKEfqarTFiGjJGkIwzxCPwLYVFXfqKp/AdYBxy5uLEnSXKWqtj8gOQ44qqpe2F9/LvDkwUfjSU4G/hj4NvBV4L9W1c3T7OtU4FSAlStXHr5u3bp5hd5y91buuH9eN12wQ/fbY6hx27ZtY8WKFYucZmHMOBrjnnHc84EZ52LNmjUbq2r1dNtmnXIZ0ieBC6rq+0leDHwQ+OWpg6pqLbAWYPXq1TUxMTGvg73z/At567Wjij43m0+cGGrchg0bmO/9WypmHI1xzzju+cCMozLMlMutwAED1/fv1z2oqu6qqu/3V98HHD6aeJKkYQ1T6F8CDkry6CS7AscD6wcHJNl34OpvAjeOLqIkaRizzltU1QNJTgMuBnYCzq2q65P8EXBVVa0HXpbkN4EHgLuBkxcxsyRpGkNNRFfVp4FPT1l35sDyGcAZo40mSZoLPykqSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEYMVehJjkpyU5JNSU6fZvtuST7Sb/9CklUjTypJ2q5ZCz3JTsDZwNHAwcAJSQ6eMuwU4J6q+jng7cCbRx1UkrR9Ow8x5ghgU1V9AyDJOuBY4IaBMccCb+iXPwq8K0mqqkaYdSysOv1TQ4175aEPcPKQY4ex+axfG9m+JLVpmELfD7h54PotwJNnGlNVDyTZCjwSuHNwUJJTgVP7q9uS3DSf0MDeU/c9bl424oxZnOc8Y38eMeMojHs+MONcHDjThmEKfWSqai2wdqH7SXJVVa0eQaRFY8bRMOPCjXs+MOOoDPOi6K3AAQPX9+/XTTsmyc7AHsBdowgoSRrOMIX+JeCgJI9OsitwPLB+ypj1wEn98nHA51qcP5ekcTbrlEs/J34acDGwE3BuVV2f5I+Aq6pqPfB+4M+TbALupiv9xbTgaZslYMbRMOPCjXs+MONIxAfSktQGPykqSY2w0CWpETtcoc/2NQRLnGVzkmuTXJ3kqn7dI5JckuRr/b979euT5B197muSHLZImc5NsiXJdQPr5pwpyUn9+K8lOWm6Y40w3xuS3Nqfx6uTHDOw7Yw+301Jnj2wftF+D5IckOTSJDckuT7Jy/v143QeZ8o4FucyyUOTfDHJV/p8f9ivf3S6rwfZlO7rQnbt18/49SEz5V7EjOcl+ebAOXxSv37Jf85zVlU7zIXuRdmvA48BdgW+Ahy8jHk2A3tPWfcnwOn98unAm/vlY4C/AQIcCXxhkTI9HTgMuG6+mYBHAN/o/92rX95rEfO9AXjVNGMP7n/GuwGP7n/2Oy327wGwL3BYv/xw4Kt9lnE6jzNlHItz2Z+LFf3yLsAX+nPzl8Dx/fpzgJf0y78HnNMvHw98ZHu5R3QOZ8p4HnDcNOOX/Oc818uO9gj9wa8hqKp/ASa/hmCcHAt8sF/+IPCcgfUfqs6VwJ5J9h31wavqcrp3Gi0k07OBS6rq7qq6B7gEOGoR883kWGBdVX2/qr4JbKL7HVjU34Oquq2qvtwvfwe4ke7T0ON0HmfKOJMlPZf9udjWX92lvxTwy3RfDwL/9hxOntuPAr+SJNvJvWDbyTiTJf85z9WOVujTfQ3B9n6JF1sBf5dkY7qvNQBYWVW39cu3Ayv75eXMPtdMy5H1tP5p7LmTUxnjkK9/6v8f6B69jeV5nJIRxuRcJtkpydXAFrqS+zpwb1U9MM2xfuzrQ4DJrw9Z1HM4NWNVTZ7DN/Xn8O1JdpuacUqWsemlHa3Qx83Tquowum+ifGmSpw9urO752Fi9L3QcMwHvAR4LPAm4DXjrsqbpJVkBfAx4RVXdN7htXM7jNBnH5lxW1Q+q6kl0ny4/AnjCcmWZydSMSQ4BzqDL+ot00yivXr6Ec7OjFfowX0OwZKrq1v7fLcAn6H5p75icSun/3dIPX87sc820pFmr6o7+D+uHwHv50VPqZcuXZBe6ojy/qj7erx6r8zhdxnE8l1V1L3Ap8BS6aYrJDzQOHmumrw9Zkt/FgYxH9dNZVVXfBz7AGJzDYe1ohT7M1xAsiSS7J3n45DLwLOA6fvxrEE4CLuyX1wPP618pPxLYOvD0fbHNNdPFwLOS7NU/ZX9Wv25RTHkt4T/RncfJfMf374B4NHAQ8EUW+fegn7t9P3BjVb1tYNPYnMeZMo7LuUyyT5I9++WHAb9KN89/Kd3Xg8C/PYfTfX3ITLkXbIaM/zjwn3bo5vgHz+Gy/71s11K+AjuKC90rzV+lm4977TLmeAzdq+9fAa6fzEI37/dZ4GvAZ4BH1I9eUT+7z30tsHqRcl1A91T7X+nm8k6ZTybgBXQvQG0Cnr/I+f68P/41dH80+w6Mf22f7ybg6KX4PQCeRjedcg1wdX85ZszO40wZx+JcAv8e+Ic+x3XAmQN/N1/sz8dfAbv16x/aX9/Ub3/MbLkXMePn+nN4HfAX/OidMEv+c57rxY/+S1IjdrQpF0nSDCx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1Ij/D/wMgtNbTTlCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_tokens = [len(i) for i in df['tokenized']]\n",
    "pd.Series(len_tokens).hist()\n",
    "plt.title('Tokenized Review Length')\n",
    "plt.show()\n",
    "pd.Series(len_tokens).describe()\n",
    "\n",
    "df['len'] = df['tokenized'].apply(lambda x: len(x))\n",
    "df = df.loc[df['len'] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_VcuT5xJ9Lj",
    "outputId": "4ede464a-50e4-4376-acbc-0b6ef5d2132b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting split\n",
      "done split\n",
      "done writing train\n",
      "done writing test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('starting split')\n",
    "train_df, test_df = train_test_split(df, test_size = .2, random_state = 42)\n",
    "\n",
    "print('done split')\n",
    "train_json = train_df.to_json(orient = 'records')\n",
    "train_json_result = json.loads(train_json)\n",
    "with open('sample_data/train_gift_cards.json', 'w') as f:\n",
    "  for entry in train_json_result:\n",
    "    json.dump(entry, f)\n",
    "    f.write('\\n')\n",
    "\n",
    "print('done writing train')\n",
    "test_json = test_df.to_json(orient = 'records')\n",
    "test_json_result = json.loads(test_json)\n",
    "with open('sample_data/test_gift_cards.json', 'w') as f:\n",
    "  for entry in test_json_result:\n",
    "    json.dump(entry, f)\n",
    "    f.write('\\n')\n",
    "\n",
    "print('done writing test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDxun1vxMgZ6"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psAvAvJuMz4-",
    "outputId": "0f0cc247-7aee-4a52-c83f-11641649facc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['when', 'i', 'first', 'got', 'i', 'set', 'upstairs', 'bedroom', 'connected', 'tv', 'get', 'angle', 'right', 'away', 'i', 'got', 'something', 'like', '11', 'channels', 'mind', 'inside', 'house', 'pointing', 'kids', 'bathroom', 'another', 'bedroom', 'finally', 'side', 'house', 'trees', 'most', 'channels', 'wanted', 'i', 'got', 'way', 'turns', 'angle', 'really', 'issue', 'channels', 'area', 'grouped', 'pretty', 'close', 'when', 'mounted', 'attic', 'i', 'able', 'point', 'angle', 'i', 'wanted', 'i', 'mounted', 'i', 'slightly', 'worried', 'i', 'find', 'different', 'location', 'when', 'i', 'plugged', 'tv', 'search', 'channels', '18', 'channels', 'including', 'pbs', 'vhf', 'i', 'seattle', 'area', 'north', 'around', 'mill', 'creek', 'good', 'signals', 'channels', 'the', 'ion', 'channels', 'last', 'channels', 'get', 'i', 'find', 'sometimes', 'best', 'signal', 'we', 'see', 'happens', 'winter', 'far', 'big', 'disruptions', 'with', 'roku', 'xbox', 'netflix', 'hulu', 'i', 'say', 'goodbye', 'cable'], 'score': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "\n",
    "TOKENS = data.Field(lower = True, batch_first = True)\n",
    "SCORE = data.LabelField(dtype = torch.float)\n",
    "\n",
    "fields = {'tokenized': ('tokens', TOKENS), 'overall': ('score', SCORE)}\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "    path = 'sample_data',\n",
    "    train = 'train_gift_cards.json',\n",
    "    test = 'test_gift_cards.json',\n",
    "    format = 'json',\n",
    "    fields = fields\n",
    ")\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJL09fdZMPyL",
    "outputId": "e6b7b109-8b8d-4f50-8835-943522968013"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:46, 5.19MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:16<00:00, 24790.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done building vocab\n"
     ]
    }
   ],
   "source": [
    "TOKENS.build_vocab(train_data, \n",
    "                   max_size = 10000,\n",
    "                   vectors = \"glove.6B.100d\", \n",
    "                   unk_init = torch.Tensor.normal_)\n",
    "SCORE.build_vocab(train_data)\n",
    "\n",
    "print('done building vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "64V9jCNeMIGt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done making iterators\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator = data.BucketIterator(train_data, sort_key = lambda x: x.tokens, \n",
    "                                     sort = False, sort_within_batch = True, batch_size= 32, device = device)\n",
    "test_iterator = data.BucketIterator(test_data, sort_key = lambda x: x.tokens, \n",
    "                                    sort = False, sort_within_batch = True, batch_size= 1, device = device)\n",
    "print('done making iterators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VdWzbgXZTqZi"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model architecture taken from: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    ''' Define network architecture and forward path. '''\n",
    "    def __init__(self, vocab_size, \n",
    "                 vector_size, n_filters, \n",
    "                 filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        # Create word embeddings from the input words     \n",
    "        self.embedding = nn.Embedding(vocab_size, vector_size, \n",
    "                                      padding_idx = pad_idx)\n",
    "        \n",
    "        # Specify convolutions with filters of different sizes (fs)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, vector_size)) \n",
    "                                    for fs in filter_sizes])\n",
    "        \n",
    "        # Add a fully connected layer for final predicitons\n",
    "        self.linear = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        # Drop some of the nodes to increase robustness in training\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        '''Forward path of the network.'''       \n",
    "        # Get word embeddings and formt them for convolutions\n",
    "        embedded = self.embedding(text).unsqueeze(1)\n",
    "        \n",
    "        # Perform convolutions and apply activation functions\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        # Pooling layer to reduce dimensionality    \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        # Dropout layer\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        return self.linear(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cPLw0QxmVoWc"
   },
   "outputs": [],
   "source": [
    "input_dim = len(TOKENS.vocab)\n",
    "embedding_dim = 100\n",
    "n_filters = 100\n",
    "filter_sizes = [1,2,3,4]\n",
    "output_dim = 1\n",
    "dropout = .5\n",
    "pad_idx = TOKENS.vocab.stoi[TOKENS.pad_token]\n",
    "\n",
    "model = CNN_Text(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Wufh0kuJWari"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TOKENS.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "unk_idx = TOKENS.vocab.stoi[TOKENS.unk_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "17G86lZFbEBc"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cCzbsXRDK7iM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Basic train loop for cnn\n",
    "\"\"\"\n",
    "def train_cnn(model, iterator, optimizer, criterion, epochs=10):\n",
    "    print('start reached')\n",
    "    for child in model.children():\n",
    "        if hasattr(child, 'reset_parameters'):\n",
    "            child.reset_parameters()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    print('starting training')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_acc = 0\n",
    "        epoch_loss = 0\n",
    "        for batch in iterator:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch.tokens).squeeze(1)\n",
    "            \n",
    "            loss = criterion(outputs, batch.score)\n",
    "            \n",
    "            epoch_acc += binary_accuracy(outputs, batch.score).item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_acc = epoch_acc / len(iterator)\n",
    "        epoch_loss = epoch_loss / len(iterator)\n",
    "        accuracy_list.append(epoch_acc)\n",
    "        loss_list.append(epoch_loss)\n",
    "        print('Epoch Num: %d, Accuracy: %.4f, Loss: %.4f' % (epoch + 1, epoch_acc, epoch_loss))\n",
    "\n",
    "    final_training_accuracy = accuracy_list[-1]     \n",
    "    final_training_loss = loss_list[-1]\n",
    "    return final_training_accuracy, final_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hX1n_IFZero",
    "outputId": "ad008f53-890c-42f1-d964-81504ef7ff65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reached\n",
      "starting training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_cnn(model, train_iterator, optimizer, criterion)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cnnwork.ipynb",
   "provenance": []
  },
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
