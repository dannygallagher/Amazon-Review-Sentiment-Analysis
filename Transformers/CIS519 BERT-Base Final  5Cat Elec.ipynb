{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIS519 BERT-Base Final  5Cat Elec.ipynb","provenance":[{"file_id":"1HWXd65MOfO_yYjqefh_udUvmbJ-1gxwJ","timestamp":1619760406062},{"file_id":"1C3C2aCZlTJa6g7-OJoW0Tje70RAu30vH","timestamp":1619759955010},{"file_id":"1n6IaK9SZf45DetPIYd0OhH1WsMaswRXn","timestamp":1619748549672},{"file_id":"1zWRwNU8pZDcjV4M7WCJxZFKrMXSHHNtm","timestamp":1619747268272},{"file_id":"1O-K5y50OrF8JBofVUSiePU2Ovctf8zva","timestamp":1619728597899},{"file_id":"11Wm-7vmqd8ybbdj-F4G-ESFNF3cMdeMp","timestamp":1619671375445},{"file_id":"1qTO3jsEDFdASB2pQtKUltVTe2K_YV8vG","timestamp":1619279774381}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa841babffb9430f9954033dfed611ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6857b28679e04805870905902863c473","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f7479a5d6b074b8b9dc13c380c1bcc52","IPY_MODEL_5c26b41593cd4af689b6d5acd011cd99"]}},"6857b28679e04805870905902863c473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7479a5d6b074b8b9dc13c380c1bcc52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4010646d33c430db40e4dcea1598307","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7808,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7808,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51bd223fc62c4745b341e1459edbd2b6"}},"5c26b41593cd4af689b6d5acd011cd99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0398919ce95c4a8fbd055d302e242bac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7808/7808 [49:29&lt;00:00,  2.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0da2c0b6e8ba4acf9ecb8c0e825babc3"}},"d4010646d33c430db40e4dcea1598307":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51bd223fc62c4745b341e1459edbd2b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0398919ce95c4a8fbd055d302e242bac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0da2c0b6e8ba4acf9ecb8c0e825babc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f43ff0181a2145028f4da2fe5e57eef4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60fe7f4a5c3243a283fd4e27d747a90f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a14d649a073e4d7980f72c8cd9780e42","IPY_MODEL_037cc2391073403bb6a0b7e40ab549e5"]}},"60fe7f4a5c3243a283fd4e27d747a90f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a14d649a073e4d7980f72c8cd9780e42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43064b8a31404bdd8d378f9972b7ae30","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7808,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7808,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a6d32e8f24c47b0aac6ebb329a06c9b"}},"037cc2391073403bb6a0b7e40ab549e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9650af1651e49e1993cf02c5da389c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7808/7808 [49:29&lt;00:00,  2.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0fea47c515c644838683f7a7d494b71f"}},"43064b8a31404bdd8d378f9972b7ae30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a6d32e8f24c47b0aac6ebb329a06c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9650af1651e49e1993cf02c5da389c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0fea47c515c644838683f7a7d494b71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d38cfe4cd064c81921946c5a4c63c96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_57eaa8ed96af4addad9cf24b9f68c338","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd86369824a34d42bb6c515f724b8b73","IPY_MODEL_7ff9bbfc935347c09c22dc4058961e01"]}},"57eaa8ed96af4addad9cf24b9f68c338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd86369824a34d42bb6c515f724b8b73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_725afdaa5cb74f5c8a46c0896c6b2bb7","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7808,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7808,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d84f4700506d4b29906109b323f4a8d6"}},"7ff9bbfc935347c09c22dc4058961e01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f9be41bb34ca4aaba579d0ff31348186","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7808/7808 [49:30&lt;00:00,  2.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_100308203b9e4634970a7d070d48d839"}},"725afdaa5cb74f5c8a46c0896c6b2bb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d84f4700506d4b29906109b323f4a8d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9be41bb34ca4aaba579d0ff31348186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"100308203b9e4634970a7d070d48d839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cdc5ce3f9a424cbba801401d0476c541":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8d59d6d85cd249ed840345bc68998515","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0cc2b738bff04f6e8a69761f45feb752","IPY_MODEL_279eee16724542f48d56755e106921a3"]}},"8d59d6d85cd249ed840345bc68998515":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0cc2b738bff04f6e8a69761f45feb752":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ebcef04786df48bdb6325e046a291526","_dom_classes":[],"description":"Evaluating on Dev set...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":6245,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6245,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75049ce445f94ae2ac784db79c07f1df"}},"279eee16724542f48d56755e106921a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef6f9e3e92bf4897ab795b926163fb0a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6245/6245 [07:27&lt;00:00, 13.94it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9ac54bf933b4c37adaab68ab94489ed"}},"ebcef04786df48bdb6325e046a291526":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75049ce445f94ae2ac784db79c07f1df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef6f9e3e92bf4897ab795b926163fb0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9ac54bf933b4c37adaab68ab94489ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d52c347a3b2e497b81fc8b38a437cf22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a47df9ed8f64fb495ff681000b1c96e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c399dd979b0f4d54a5db820bd2c03b1d","IPY_MODEL_a0d85daf06124dab8920c3b69f6833e8"]}},"1a47df9ed8f64fb495ff681000b1c96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c399dd979b0f4d54a5db820bd2c03b1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b24f445b18ac40a69ec597ba40773344","_dom_classes":[],"description":"Evaluating on Experiment set...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":6243,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6243,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17439a154b7c4057a0aecce7ad4ab2d7"}},"a0d85daf06124dab8920c3b69f6833e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_520e0a97b667450a969e36ccc589d37e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6243/6243 [03:44&lt;00:00, 27.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_011108b82db04a6793ab1d172bc23b15"}},"b24f445b18ac40a69ec597ba40773344":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"17439a154b7c4057a0aecce7ad4ab2d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"520e0a97b667450a969e36ccc589d37e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"011108b82db04a6793ab1d172bc23b15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72a25da3a2654b828e54993446926ebc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9864eddd38704b788bf40bad3fa3a8d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4655882e3b904970b41fffe187d5ddac","IPY_MODEL_3f510e8efc514208bbae80e55f39e949"]}},"9864eddd38704b788bf40bad3fa3a8d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4655882e3b904970b41fffe187d5ddac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ae25d792af8468e85e5152794d58ecf","_dom_classes":[],"description":"Training Steps:  45%","_model_name":"FloatProgressModel","bar_style":"","max":7808,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3549,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05c1dde1ad454a2e9e5c87497eabe37a"}},"3f510e8efc514208bbae80e55f39e949":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c530f1b3fa94284bbfdf142f78cc481","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3549/7808 [22:38&lt;27:10,  2.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dd31dc8e3104d0ab8a6169bdfc2445d"}},"3ae25d792af8468e85e5152794d58ecf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05c1dde1ad454a2e9e5c87497eabe37a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c530f1b3fa94284bbfdf142f78cc481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3dd31dc8e3104d0ab8a6169bdfc2445d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"t-7aBAtpDG6U"},"source":["\n","## Modified from CIS 530 Homework Option 2 - Spring 2021\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"emdQC05Z2H8W"},"source":["### Installing the HuggingfaceðŸ¤— transformer package"]},{"cell_type":"code","metadata":{"id":"N5zqkZYt2Jg-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800861543,"user_tz":240,"elapsed":8145,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"9f9d58c1-e4e2-4cfb-8db4-23984669267e"},"source":["# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n","!pip install transformers\n","!pip3 install sentencepiece\n","!pip install madgrad\n","type_name = \"5Cat\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: madgrad in /usr/local/lib/python3.7/dist-packages (1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mtxqNoffUq7T","executionInfo":{"status":"ok","timestamp":1619800861544,"user_tz":240,"elapsed":8138,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["train_set_name = \"Elec\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdUHfAX97ARc"},"source":["### Import the important packages that we need"]},{"cell_type":"code","metadata":{"id":"KZo2Ls7I5Dmk","executionInfo":{"status":"ok","timestamp":1619800862374,"user_tz":240,"elapsed":8965,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import torch \n","import numpy as np\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTIMhxNC6aLA"},"source":["### Mount your google drive \n"]},{"cell_type":"code","metadata":{"id":"MrlKyHzY6zq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800862375,"user_tz":240,"elapsed":8962,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"d0e6eab6-0816-4dd1-d918-fa3959d75f75"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PkA42xeABjEo","executionInfo":{"status":"ok","timestamp":1619800862377,"user_tz":240,"elapsed":8959,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n","def get_metrics(true_labels, pred_labels):\n","    f1 = f1_score(true_labels, pred_labels, average='macro')\n","    acc = accuracy_score(true_labels, pred_labels)\n","    rec = recall_score(true_labels, pred_labels, average='macro')\n","    prec = precision_score(true_labels, pred_labels, average='macro')\n","    return f1, acc, rec, prec"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyvLholz7VHc"},"source":["### Download the Review Datset\n","\n","Note that with the default code, the files are not saved in your google drive, which means they will get deleted after the session close. You can either re-run this cell for each new colab session, or you can save it to the mounted drive at `/content/drive`"]},{"cell_type":"code","metadata":{"id":"-3ytJ_7TN_xo","executionInfo":{"status":"ok","timestamp":1619800862378,"user_tz":240,"elapsed":8956,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import json\n","import gzip\n","\n","def parse(path):\n","  true = True\n","  false = False\n","  g = gzip.open(path, 'r')\n","  for l in g:\n","    yield json.dumps(eval(l))\n","\n","def strict(path):\n","  max_reviews = 1689188\n","  iter = 5000\n","  counter = 0 \n","  f_path = path + \".json.gz\"\n","  true = True\n","  false = False\n","  f = open(path+\".json\", 'w')\n","  # f.write(\"[\")\n","  writable = \"[\"\n","  # writable.join\n","\n","  for l in parse(f_path):\n","    writable = writable + l + ',\\n'\n","    counter = counter + 1\n","    if (counter % iter) == 0:\n","      print(f\"On line{counter}, {counter/max_reviews} % done\")\n","  writable = writable[:-2]\n","  writable = writable + \"]\"\n","  f.write(writable)\n","\n","def fast_parse(path):\n","  # path = path + \".json.gz\"\n","  max_reviews = 1689188\n","  iter = 5000\n","  counter = 0 \n","  all_reviews = []\n","  g = open(path, 'r')\n","  for line in g:\n","    d = json.loads(line)\n","    all_reviews.append(d)\n","    if (counter % iter) == 0:\n","      print(f\"On line{counter}, {counter/max_reviews} % done\")\n","    counter = counter + 1\n","  return all_reviews"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOhxsOGy7cK4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800869465,"user_tz":240,"elapsed":16040,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"375df9e5-a044-4622-b4f3-0ef288a5f814"},"source":["#Csvs\n","\n","train_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_train.csv')\n","dev_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_test.csv')\n","experiment_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/all_test.csv')\n","train_set = train_set.to_dict(orient='records')\n","dev_set = dev_set.to_dict(orient='records')\n","experiment_set = experiment_set.to_dict(orient='records')\n","\n","# #Jsons\n","\n","# train_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_train_binaryposneg.json')\n","# dev_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_test_binaryposneg.json')\n","# experiment_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/all_test_binaryposneg.json')\n","  \n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"dGB5MH22B1dH"},"source":["### Load the dataset and see what it looks like\n","\n","For now let's first load the training dataset and see what it looks like. We will worry about the dev/test sets later...\n"]},{"cell_type":"code","metadata":{"id":"xaBayxnYB-7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800869466,"user_tz":240,"elapsed":16036,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"e483c6b9-da03-4a92-d1ea-d945f5e99c23"},"source":["print(train_set[0]['title_plus_review'])\n","print(\"Number of review in training set: {}\".format(len(train_set)))\n","print(\"Here's how one of the example looks like: {}\".format(json.dumps(train_set[100])))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["ok the camera is good ,  but the grip/stand could be a little better .   when i try to clip on the monitor ,  it falls off . \n","Number of review in training set: 249828\n","Here's how one of the example looks like: {\"Unnamed: 0\": 100, \"reviewText\": \"DO NOT BUY THIS!! It completely stopped working after 7 months, and went in and out of connectivity the whole 7 months that it did work\", \"summary\": \"DO NOT BUY\", \"overall\": 1.0, \"title_plus_review\": \"do not buy do not buy this !  !  it completely stopped working after 7 months ,  and went in and out of connectivity the whole 7 months that it did work\", \"pos_neg\": 0, \"neutrality\": 1, \"num_words\": 29, \"nw\": 26}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thxwPQ84FFrC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800869467,"user_tz":240,"elapsed":16031,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"f0b752d0-561b-44e0-d407-f80d139501e5"},"source":["import random\n","\n","training_reviews = []\n","id = 0;\n","for  review in train_set:\n","  if 'title_plus_review' not in review:\n","    continue\n","  training_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for training: {}\".format(len(training_reviews)))\n","\n","dev_reviews = []\n","id = 0;\n","for review in dev_set:\n","  #no Review text\n","  if 'title_plus_review' not in review:\n","    continue\n","  dev_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for dev: {}\".format(len(dev_reviews)))\n","\n","experiment_reviews = []\n","id = 0;\n","for review in experiment_set:\n","  #no Review text\n","  if 'title_plus_review' not in review:\n","    continue\n","  experiment_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for experiment: {}\".format(len(experiment_reviews)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Number of reviews for training: 249828\n","Number of reviews for dev: 49954\n","Number of reviews for experiment: 49943\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wcu0HdxgE7i9"},"source":["### Load Pretrained BERT Model\n"," \n","\n","You can search for the available models [here](https://huggingface.co/models?search=bert).\n","\n","You can find more examples of different use cases for BERT in the transformer github repo README -- https://github.com/huggingface/transformers\n"]},{"cell_type":"code","metadata":{"id":"P7YkHAIjCu4B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619800878962,"user_tz":240,"elapsed":25521,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"3b8ec081-3dd7-46d5-c0af-f864595b0395"},"source":["from transformers import InputExample\n","from transformers import (WEIGHTS_NAME, BertConfig,\n","                          BertForSequenceClassification, BertTokenizer)\n","from transformers import glue_convert_examples_to_features as convert_examples_to_features\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","import tqdm\n","\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,  TensorDataset)\n","\n","\n","bert_model_type = 'bert-base-uncased' \n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_type, num_labels = 5)\n","config = BertConfig.from_pretrained(bert_model_type)\n","tokenizer = BertTokenizer.from_pretrained(bert_model_type, num_labels = 5)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Cs-R81c66DoJ"},"source":["### Convert examples to BERT input features\n","\n"]},{"cell_type":"code","metadata":{"id":"0FBUds7v6V9L","executionInfo":{"status":"ok","timestamp":1619800878964,"user_tz":240,"elapsed":25518,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["relevance_label_mapping = {\n","    1.0: 1,\n","    2.0: 2,\n","    3.0: 3,\n","    4.0: 4,\n","    5.0: 5\n","}\n","\n","def convert_sentence_pair_to_tensor_input(sentence_reviews, label_mapping):\n","\n","    # STEP 1: convert each sentence \n","    input_examples = []\n","    for review in sentence_reviews:\n","        current_label = review[\"label\"] if \"label\" in review else print(\"dang\")\n","        input_examples.append(\n","            InputExample(guid=review[\"review_id\"], \n","                         text_a=str(review[\"review_text\"]), \n","                         label=label_mapping[current_label])\n","        )\n","\n","    label_list = [val for _, val in label_mapping.items()]\n","    features = convert_examples_to_features(input_examples,\n","                                                   tokenizer,\n","                                                   label_list=label_list,\n","                                                   max_length = 128,  \n","                                                   output_mode=\"classification\")\n","    \n","    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n","    token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n","    labels = torch.tensor([f.label for f in features], dtype=torch.long)\n","    dataset = TensorDataset(input_ids, attention_mask, token_type_ids, labels)\n","\n","    return dataset"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQHIh7iDMnEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619801355902,"user_tz":240,"elapsed":502451,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"f58e2791-e0f8-4a98-bf76-86ef5570a404"},"source":["train_dataset = convert_sentence_pair_to_tensor_input(training_reviews, relevance_label_mapping)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"V7YsIKmKAEVR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619801448161,"user_tz":240,"elapsed":594704,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"97f82dc5-b97d-482a-a48b-d9bde61d3e29"},"source":["dev_dataset = convert_sentence_pair_to_tensor_input(dev_reviews, relevance_label_mapping)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lTnO2-B1Su2c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619801518448,"user_tz":240,"elapsed":664985,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"d4ea0109-9b05-4b28-8b65-61b794028a75"},"source":["experiment_dataset = convert_sentence_pair_to_tensor_input(experiment_reviews, relevance_label_mapping)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OrKngYELCPal"},"source":["### Choose your hyperparameters + model output directory\n"]},{"cell_type":"code","metadata":{"id":"zxxxJxVkCOwJ","executionInfo":{"status":"ok","timestamp":1619761474425,"user_tz":240,"elapsed":620797,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["HYPER_PARAMS = {\n","    \"num_training_epoch\": 3,\n","    \"learning_rate\": 5e-5,        \n","    \"training_batch_size\": 32,    \n","    \"eval_batch_size\": 8,\n","    \"max_grad_norm\": 1.0,\n","    \"num_warmup_steps\": 0.1,\n","    \"dropout_prob\": 0.1\n","}\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpHkH6MlaJvh","colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["aa841babffb9430f9954033dfed611ae","6857b28679e04805870905902863c473","f7479a5d6b074b8b9dc13c380c1bcc52","5c26b41593cd4af689b6d5acd011cd99","d4010646d33c430db40e4dcea1598307","51bd223fc62c4745b341e1459edbd2b6","0398919ce95c4a8fbd055d302e242bac","0da2c0b6e8ba4acf9ecb8c0e825babc3","f43ff0181a2145028f4da2fe5e57eef4","60fe7f4a5c3243a283fd4e27d747a90f","a14d649a073e4d7980f72c8cd9780e42","037cc2391073403bb6a0b7e40ab549e5","43064b8a31404bdd8d378f9972b7ae30","6a6d32e8f24c47b0aac6ebb329a06c9b","d9650af1651e49e1993cf02c5da389c6","0fea47c515c644838683f7a7d494b71f","2d38cfe4cd064c81921946c5a4c63c96","57eaa8ed96af4addad9cf24b9f68c338","bd86369824a34d42bb6c515f724b8b73","7ff9bbfc935347c09c22dc4058961e01","725afdaa5cb74f5c8a46c0896c6b2bb7","d84f4700506d4b29906109b323f4a8d6","f9be41bb34ca4aaba579d0ff31348186","100308203b9e4634970a7d070d48d839"]},"executionInfo":{"status":"ok","timestamp":1619770390348,"user_tz":240,"elapsed":9536718,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"14b31693-be17-4261-bbad-f4f542d4b551"},"source":["torch.cuda.manual_seed(42)\n","torch.manual_seed(42)\n","random.seed(42)\n","np.random.seed(42)\n","\n","bert_model.hidden_dropout_prob = HYPER_PARAMS['dropout_prob']\n","bert_model.to(\"cuda\")\n","optimizer = AdamW(bert_model.parameters(), \n","                    lr=HYPER_PARAMS['learning_rate'], \n","                    correct_bias=False)\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, \n","                              sampler=train_sampler, \n","                              batch_size=HYPER_PARAMS[\"training_batch_size\"])\n","\n","# optimizer = AdamW(bert_model.parameters(), \n","#                   lr=HYPER_PARAMS['learning_rate'], \n","#                   correct_bias=False)\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=HYPER_PARAMS['num_warmup_steps'], \n","                                            num_training_steps=len(train_dataloader))\n","\n","\n","global_step = 0\n","tr_loss = 0.0\n","bert_model.zero_grad()\n","bert_model.train()\n","\n","for epc in range(HYPER_PARAMS[\"num_training_epoch\"]):\n","    print(\"Epoch #{}: \\n\".format(epc))\n","    epoch_iterator = tqdm.notebook.tqdm(train_dataloader, desc=\"Training Steps\")\n","    avg_loss_over_epoch = []\n","    for step, batch in enumerate(epoch_iterator):\n","        batch = tuple(t.to('cuda') for t in batch)\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'token_type_ids': batch[2],\n","                  'labels': batch[3]}\n","\n","        outputs = bert_model(**inputs)\n","        loss = outputs[0]  \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), HYPER_PARAMS[\"max_grad_norm\"])\n","        tr_loss += loss.item()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        bert_model.zero_grad()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch #0: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa841babffb9430f9954033dfed611ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7808.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #1: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f43ff0181a2145028f4da2fe5e57eef4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7808.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #2: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d38cfe4cd064c81921946c5a4c63c96","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7808.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mF4FJlwLaYpO","executionInfo":{"status":"ok","timestamp":1619770391878,"user_tz":240,"elapsed":9538245,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import os\n","output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/elec_5cat_bert_base_adam/'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","bert_model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","config.save_pretrained(output_dir)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4tGbX8HYEZE"},"source":["Load Model\n"]},{"cell_type":"code","metadata":{"id":"wnbXCg8_fvZz","executionInfo":{"status":"ok","timestamp":1619770395121,"user_tz":240,"elapsed":9541486,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/elec_5cat_bert_base_adam/'\n","bert_model = BertForSequenceClassification.from_pretrained(output_dir, num_labels = 5)\n","tokenizer = BertTokenizer.from_pretrained(output_dir, num_labels = 5)\n","\n","bert_model = bert_model.to(\"cuda\")\n","  "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mk3UTWDPf5Fn","executionInfo":{"status":"ok","timestamp":1619770395123,"user_tz":240,"elapsed":9541486,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["results = pd.DataFrame(columns=['Type', \"Model\", 'Optimizer', \"Train Set\", 'Test Set', 'LR', 'Dropout','F1', 'Accuracy', 'Recall', 'Precision' ])\n","optimizer_name = \"ADAM\"\n","test_set_name = \"Elec\""],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"0E2zPR6Zf9f4","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["cdc5ce3f9a424cbba801401d0476c541","8d59d6d85cd249ed840345bc68998515","0cc2b738bff04f6e8a69761f45feb752","279eee16724542f48d56755e106921a3","ebcef04786df48bdb6325e046a291526","75049ce445f94ae2ac784db79c07f1df","ef6f9e3e92bf4897ab795b926163fb0a","a9ac54bf933b4c37adaab68ab94489ed"]},"executionInfo":{"status":"ok","timestamp":1619770618511,"user_tz":240,"elapsed":9764871,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"20a6d481-256f-4b32-b4a8-8272bd9721ac"},"source":["\n","dev_sampler = SequentialSampler(dev_dataset)\n","dev_dataloader = DataLoader(dev_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Dev set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec}\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdc5ce3f9a424cbba801401d0476c541","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating on Dev set...', max=6245.0, style=ProgressStylâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","The accuracy on dev set = 0.5990511270368739\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vxSka3XzgSBc","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1619770618513,"user_tz":240,"elapsed":9764871,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"4341bfb5-2648-41a8-f9bd-36ec130f9011"},"source":["results"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Model</th>\n","      <th>Optimizer</th>\n","      <th>Train Set</th>\n","      <th>Test Set</th>\n","      <th>LR</th>\n","      <th>Dropout</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>Elec</td>\n","      <td>Elec</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.585401</td>\n","      <td>0.599051</td>\n","      <td>0.590016</td>\n","      <td>0.587779</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type              Model Optimizer  ...  Accuracy    Recall  Precision\n","0  5Cat  bert-base-uncased      ADAM  ...  0.599051  0.590016   0.587779\n","\n","[1 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"2vToncX0RXBL"},"source":["Test on other dataset"]},{"cell_type":"code","metadata":{"id":"NLOZ8euiVa9I","executionInfo":{"status":"ok","timestamp":1619770618515,"user_tz":240,"elapsed":9764870,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["test_set_name = \"All\""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2SfXooaRb_V","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["d52c347a3b2e497b81fc8b38a437cf22","1a47df9ed8f64fb495ff681000b1c96e","c399dd979b0f4d54a5db820bd2c03b1d","a0d85daf06124dab8920c3b69f6833e8","b24f445b18ac40a69ec597ba40773344","17439a154b7c4057a0aecce7ad4ab2d7","520e0a97b667450a969e36ccc589d37e","011108b82db04a6793ab1d172bc23b15"]},"executionInfo":{"status":"ok","timestamp":1619770841992,"user_tz":240,"elapsed":9988345,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"0ed982bd-3e7f-404a-ef5b-5b29d761da56"},"source":["dev_sampler = SequentialSampler(experiment_dataset)\n","dev_dataloader = DataLoader(experiment_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Experiment set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d52c347a3b2e497b81fc8b38a437cf22","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating on Experiment set...', max=6243.0, style=Progrâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","The accuracy on dev set = 0.6810163586488597\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ftVqdSfjZOvD","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1619770841993,"user_tz":240,"elapsed":9988344,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"0e3e9bd6-b00b-47fa-dd7c-abb13596ed4d"},"source":["results"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Model</th>\n","      <th>Optimizer</th>\n","      <th>Train Set</th>\n","      <th>Test Set</th>\n","      <th>LR</th>\n","      <th>Dropout</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>Elec</td>\n","      <td>Elec</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.585401</td>\n","      <td>0.599051</td>\n","      <td>0.590016</td>\n","      <td>0.587779</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>Elec</td>\n","      <td>All</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.520496</td>\n","      <td>0.681016</td>\n","      <td>0.559144</td>\n","      <td>0.495453</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type              Model Optimizer  ...  Accuracy    Recall  Precision\n","0  5Cat  bert-base-uncased      ADAM  ...  0.599051  0.590016   0.587779\n","1  5Cat  bert-base-uncased      ADAM  ...  0.681016  0.559144   0.495453\n","\n","[2 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"a_Pl3CTLhNEb"},"source":["##MADGRAD"]},{"cell_type":"code","metadata":{"id":"BQ671-9Rg7OY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619801528317,"user_tz":240,"elapsed":9852,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"aaeed1e7-9e19-4031-bcdc-072778beed02"},"source":["\n","bert_model_type = 'bert-base-uncased'  \n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_type, num_labels = 5)\n","config = BertConfig.from_pretrained(bert_model_type)\n","tokenizer = BertTokenizer.from_pretrained(bert_model_type, num_labels = 5)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QJ5ZvPUCg8Ci","executionInfo":{"status":"ok","timestamp":1619801528318,"user_tz":240,"elapsed":9839,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["HYPER_PARAMS = {\n","    \"num_training_epoch\": 3,\n","    \"learning_rate\": 5e-5,        \n","    \"training_batch_size\": 32,    \n","    \"eval_batch_size\": 8,\n","    \"max_grad_norm\": 1.0,\n","    \"num_warmup_steps\": 0.1,\n","    \"dropout_prob\": 0.1\n","}"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBqm2R_pX4z-"},"source":[""]},{"cell_type":"code","metadata":{"id":"kOSdC8fUhVDo","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["72a25da3a2654b828e54993446926ebc","9864eddd38704b788bf40bad3fa3a8d0","4655882e3b904970b41fffe187d5ddac","3f510e8efc514208bbae80e55f39e949","3ae25d792af8468e85e5152794d58ecf","05c1dde1ad454a2e9e5c87497eabe37a","1c530f1b3fa94284bbfdf142f78cc481","3dd31dc8e3104d0ab8a6169bdfc2445d"]},"outputId":"1db6a5a4-b327-4d93-8255-2c332cb835e3"},"source":["from madgrad import MADGRAD\n","torch.cuda.manual_seed(42)\n","torch.manual_seed(42)\n","random.seed(42)\n","np.random.seed(42)\n","\n","bert_model.hidden_dropout_prob = HYPER_PARAMS['dropout_prob']\n","bert_model.to(\"cuda\")\n","optimizer = MADGRAD(bert_model.parameters(), \n","                    lr=HYPER_PARAMS['learning_rate'])\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, \n","                              sampler=train_sampler, \n","                              batch_size=HYPER_PARAMS[\"training_batch_size\"])\n","\n","# optimizer = AdamW(bert_model.parameters(), \n","#                   lr=HYPER_PARAMS['learning_rate'], \n","#                   correct_bias=False)\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=HYPER_PARAMS['num_warmup_steps'], \n","                                            num_training_steps=len(train_dataloader))\n","\n","\n","global_step = 0\n","tr_loss = 0.0\n","bert_model.zero_grad()\n","bert_model.train()\n","\n","for epc in range(HYPER_PARAMS[\"num_training_epoch\"]):\n","    print(\"Epoch #{}: \\n\".format(epc))\n","    epoch_iterator = tqdm.notebook.tqdm(train_dataloader, desc=\"Training Steps\")\n","    avg_loss_over_epoch = []\n","    for step, batch in enumerate(epoch_iterator):\n","        batch = tuple(t.to('cuda') for t in batch)\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'token_type_ids': batch[2],\n","                  'labels': batch[3]}\n","\n","        outputs = bert_model(**inputs)\n","        loss = outputs[0]  \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), HYPER_PARAMS[\"max_grad_norm\"])\n","        tr_loss += loss.item()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        bert_model.zero_grad()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch #0: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72a25da3a2654b828e54993446926ebc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7808.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rmIQ1L8yhkee"},"source":["# This is where we mounted your google drive. \n","# You might need to re-mount it if your session was closed half way through\n","import os\n","output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/elec_5cat_bert_base_madgrad/'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","bert_model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","config.save_pretrained(output_dir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVTeKJlHYLPc"},"source":["Load Model\n"]},{"cell_type":"code","metadata":{"id":"_iutoZkqYKiB"},"source":["output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/elec_5cat_bert_base_madgrad/' \n","bert_model = BertForSequenceClassification.from_pretrained(output_dir, num_labels = 5)\n","tokenizer = BertTokenizer.from_pretrained(output_dir, num_labels = 5)\n","\n","bert_model = bert_model.to(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKMheJ4uj9oV"},"source":["results = pd.DataFrame(columns=['Type', \"Model\", 'Optimizer', \"Train Set\", 'Test Set', 'LR', 'Dropout','F1', 'Accuracy', 'Recall', 'Precision' ])\n","test_set_name = \"Elec\"\n","optimizer_name = \"Madgrad\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJkDdQApv1zM"},"source":["dev_sampler = SequentialSampler(dev_dataset)\n","dev_dataloader = DataLoader(dev_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Dev set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir+\"results.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bGz9OOrhwTmp"},"source":["results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"efFstRW0Yioa"},"source":["Test experiment"]},{"cell_type":"code","metadata":{"id":"Y6c0lpIiYlZc"},"source":["test_set_name = \"All\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1mZHjK-YlZe"},"source":["dev_sampler = SequentialSampler(experiment_dataset)\n","dev_dataloader = DataLoader(experiment_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Experiment set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJ-zt2Vkb3lT"},"source":["results"],"execution_count":null,"outputs":[]}]}