{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" CIS519 BERT-Base Final  5Cat All.ipynb","provenance":[{"file_id":"1ILCi7jOSLVyfYRTkJZyPxcgJU4FO-9DH","timestamp":1619764826428},{"file_id":"1HWXd65MOfO_yYjqefh_udUvmbJ-1gxwJ","timestamp":1619764592873},{"file_id":"1C3C2aCZlTJa6g7-OJoW0Tje70RAu30vH","timestamp":1619759955010},{"file_id":"1n6IaK9SZf45DetPIYd0OhH1WsMaswRXn","timestamp":1619748549672},{"file_id":"1zWRwNU8pZDcjV4M7WCJxZFKrMXSHHNtm","timestamp":1619747268272},{"file_id":"1O-K5y50OrF8JBofVUSiePU2Ovctf8zva","timestamp":1619728597899},{"file_id":"11Wm-7vmqd8ybbdj-F4G-ESFNF3cMdeMp","timestamp":1619671375445},{"file_id":"1qTO3jsEDFdASB2pQtKUltVTe2K_YV8vG","timestamp":1619279774381}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"108d4d1c7148439b80d878b1e818173a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e937a15f4fb94e5d8517a23941c9493e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9fffb14908c54b30b5ee593fc3e6b116","IPY_MODEL_be1d3fc12cdc4fb7aa0320beaf512f9f"]}},"e937a15f4fb94e5d8517a23941c9493e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fffb14908c54b30b5ee593fc3e6b116":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6fd7ec5ee2d74c5c8f4535ff464e01da","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd80bc741f844cda8f2fdbc7f36240b3"}},"be1d3fc12cdc4fb7aa0320beaf512f9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd7918b6d7b04885bf46264706ff640d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7805/7805 [49:46&lt;00:00,  2.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43171376d6d54ac1b2d8f38ca2eaa2e2"}},"6fd7ec5ee2d74c5c8f4535ff464e01da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd80bc741f844cda8f2fdbc7f36240b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd7918b6d7b04885bf46264706ff640d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43171376d6d54ac1b2d8f38ca2eaa2e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b8defba99f04e94ad1f0891cfcced7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4dea1492cc2148bcb0e8d4dd22287898","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d362bd5fb6104dea9d29719d6dd7e74a","IPY_MODEL_d8fdc1e7957c440893cded1439d2285b"]}},"4dea1492cc2148bcb0e8d4dd22287898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d362bd5fb6104dea9d29719d6dd7e74a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e39c6f3c068b4afb9b797d60e8a7a8e6","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2b6b160ee1c471f8b049b74c479c095"}},"d8fdc1e7957c440893cded1439d2285b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0a84b0056d3c46b4b95816fb46754a5e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7805/7805 [49:46&lt;00:00,  2.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d863ff311f14237986f609ada4c7a38"}},"e39c6f3c068b4afb9b797d60e8a7a8e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f2b6b160ee1c471f8b049b74c479c095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a84b0056d3c46b4b95816fb46754a5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d863ff311f14237986f609ada4c7a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00d4c92fa30f4328b722bcd19dc39453":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0ce5205eb674f598014caff2cd538cd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8dca804e5afc40feaf28114d48ad8736","IPY_MODEL_f47fd3309c42424bb6361ccd1738cc93"]}},"a0ce5205eb674f598014caff2cd538cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dca804e5afc40feaf28114d48ad8736":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c3d5233cc73e4f57b34a2a22c5c77479","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5251576755d5453d9ae97843101b1ff3"}},"f47fd3309c42424bb6361ccd1738cc93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7fecd30b65e141618ffcd9508424b36c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7805/7805 [49:46&lt;00:00,  2.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c3d6070a66847c08ff02ba3194025b9"}},"c3d5233cc73e4f57b34a2a22c5c77479":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5251576755d5453d9ae97843101b1ff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7fecd30b65e141618ffcd9508424b36c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c3d6070a66847c08ff02ba3194025b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8871744702ce4241881322572940ccc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c06018ece495435ca245a1acd8791b1e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_df40e40e2fb5477fbb1819572604cead","IPY_MODEL_8f5ba70d703f46afbea22a7d35b1dea9"]}},"c06018ece495435ca245a1acd8791b1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df40e40e2fb5477fbb1819572604cead":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e6fa7c164a294429bc91532db4550766","_dom_classes":[],"description":"Evaluating on Dev set...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":6243,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6243,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_861db3874cfe40ad9ab0aae2a15604b0"}},"8f5ba70d703f46afbea22a7d35b1dea9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_54a065417b314d759a5e19e7ad39940c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6243/6243 [03:48&lt;00:00, 27.32it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29bb95266be5449889a0a3922d22e07b"}},"e6fa7c164a294429bc91532db4550766":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"861db3874cfe40ad9ab0aae2a15604b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54a065417b314d759a5e19e7ad39940c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"29bb95266be5449889a0a3922d22e07b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f2bce081b334e2eae1177d0d15f5cf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d7d6384d21cd46bcb02df880cb89afad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c33c53566ec40b5918ac52976037984","IPY_MODEL_f56bf14042db42649a69a9c8ec478a66"]}},"d7d6384d21cd46bcb02df880cb89afad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c33c53566ec40b5918ac52976037984":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_17e02a9ed25f45bbbaa82c00a7bc21b8","_dom_classes":[],"description":"Evaluating on Experiment set...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":6245,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6245,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ec0cd60c486491fa252351f50aa8088"}},"f56bf14042db42649a69a9c8ec478a66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_991e3fa5b86c47a5bca5591ff87a1c53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6245/6245 [03:53&lt;00:00, 26.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8852fdc80b7f4947880b67cd9ff6c474"}},"17e02a9ed25f45bbbaa82c00a7bc21b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3ec0cd60c486491fa252351f50aa8088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"991e3fa5b86c47a5bca5591ff87a1c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8852fdc80b7f4947880b67cd9ff6c474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f48c5a09aff41c2a9606b7bae05b373":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b1a0347f54e4c96b993ab988aac2cf2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6f0873da5dd54c2bb367b2bc57fc8c8f","IPY_MODEL_a779b517ecd649439fc156d84dd56507"]}},"3b1a0347f54e4c96b993ab988aac2cf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f0873da5dd54c2bb367b2bc57fc8c8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_46b2cec21f114ac3bd783eb5fbfb1e22","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4133bd81ebc3498b985a4bdf10ab782c"}},"a779b517ecd649439fc156d84dd56507":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1549ecac5164f7080bd59b0b9857f7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7805/7805 [50:04&lt;00:00,  2.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43e5d58db5034b56b8d3c863ac85d536"}},"46b2cec21f114ac3bd783eb5fbfb1e22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4133bd81ebc3498b985a4bdf10ab782c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1549ecac5164f7080bd59b0b9857f7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43e5d58db5034b56b8d3c863ac85d536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9362d7d8ecbd49b285de2e1c3a0a3ea9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_48c4f5fe29ca4c069ebb0fb0d5fa8ae6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd85c9630463451fb47029a3bcbea15d","IPY_MODEL_9cf31b125cf14958afaae529d036c50b"]}},"48c4f5fe29ca4c069ebb0fb0d5fa8ae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd85c9630463451fb47029a3bcbea15d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d12fce0468214163a5fdebf483190fa1","_dom_classes":[],"description":"Training Steps: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22537fff5f364976a9ed9d4fd88d2ee4"}},"9cf31b125cf14958afaae529d036c50b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e5528b8ab1d4c8b897b11cab81a052f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7805/7805 [50:01&lt;00:00,  2.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe51610b215a429daf7685f82493f538"}},"d12fce0468214163a5fdebf483190fa1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"22537fff5f364976a9ed9d4fd88d2ee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e5528b8ab1d4c8b897b11cab81a052f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe51610b215a429daf7685f82493f538":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9c3a1b64c8a4d7ebeff14645548cc95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_92101677a82f45b3826de4f3dada80ae","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1b5006d6ec504d1aa79e4277083a2b82","IPY_MODEL_dec69030e7f54ff2ae39c9f9732b3d3d"]}},"92101677a82f45b3826de4f3dada80ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b5006d6ec504d1aa79e4277083a2b82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_089d40146c934218a890aa0bad8127cd","_dom_classes":[],"description":"Training Steps:  68%","_model_name":"FloatProgressModel","bar_style":"","max":7805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5331,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8dcb210eb3154e3fa9ba0b1648114ecc"}},"dec69030e7f54ff2ae39c9f9732b3d3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1aad3cf335f94621bcc72669465700ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5331/7805 [34:12&lt;15:51,  2.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb136725bae44d3988c27af247a6c908"}},"089d40146c934218a890aa0bad8127cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8dcb210eb3154e3fa9ba0b1648114ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1aad3cf335f94621bcc72669465700ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb136725bae44d3988c27af247a6c908":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"t-7aBAtpDG6U"},"source":["\n","## Modified from CIS 530 Homework Option 2 - Spring 2021\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"emdQC05Z2H8W"},"source":["### Installing the HuggingfaceðŸ¤— transformer package"]},{"cell_type":"code","metadata":{"id":"N5zqkZYt2Jg-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784752869,"user_tz":240,"elapsed":7632,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"f4d3433b-6a53-4909-bd12-e04ad2eb693f"},"source":["# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n","!pip install transformers\n","!pip3 install sentencepiece\n","!pip install madgrad\n","type_name = \"5Cat\""],"execution_count":36,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: madgrad in /usr/local/lib/python3.7/dist-packages (1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mtxqNoffUq7T","executionInfo":{"status":"ok","timestamp":1619784752870,"user_tz":240,"elapsed":7625,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["train_set_name = \"ALL\""],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdUHfAX97ARc"},"source":["### Import the important packages that we need"]},{"cell_type":"code","metadata":{"id":"KZo2Ls7I5Dmk","executionInfo":{"status":"ok","timestamp":1619784752871,"user_tz":240,"elapsed":7622,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import torch \n","import numpy as np\n","import pandas as pd"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTIMhxNC6aLA"},"source":["### Mount your google drive \n"]},{"cell_type":"code","metadata":{"id":"MrlKyHzY6zq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784752871,"user_tz":240,"elapsed":7619,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"a0870a44-506e-44c9-f314-9d469ce94837"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PkA42xeABjEo","executionInfo":{"status":"ok","timestamp":1619784752872,"user_tz":240,"elapsed":7615,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n","def get_metrics(true_labels, pred_labels):\n","    f1 = f1_score(true_labels, pred_labels, average='macro')\n","    acc = accuracy_score(true_labels, pred_labels)\n","    rec = recall_score(true_labels, pred_labels, average='macro')\n","    prec = precision_score(true_labels, pred_labels, average='macro')\n","    return f1, acc, rec, prec"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyvLholz7VHc"},"source":["### Download the Review Datset\n","\n","Note that with the default code, the files are not saved in your google drive, which means they will get deleted after the session close. You can either re-run this cell for each new colab session, or you can save it to the mounted drive at `/content/drive`"]},{"cell_type":"code","metadata":{"id":"-3ytJ_7TN_xo","executionInfo":{"status":"ok","timestamp":1619784752872,"user_tz":240,"elapsed":7612,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import json\n","import gzip\n","\n","def parse(path):\n","  true = True\n","  false = False\n","  g = gzip.open(path, 'r')\n","  for l in g:\n","    yield json.dumps(eval(l))\n","\n","def strict(path):\n","  max_reviews = 1689188\n","  iter = 5000\n","  counter = 0 \n","  f_path = path + \".json.gz\"\n","  true = True\n","  false = False\n","  f = open(path+\".json\", 'w')\n","  # f.write(\"[\")\n","  writable = \"[\"\n","  # writable.join\n","\n","  for l in parse(f_path):\n","    writable = writable + l + ',\\n'\n","    counter = counter + 1\n","    if (counter % iter) == 0:\n","      print(f\"On line{counter}, {counter/max_reviews} % done\")\n","  writable = writable[:-2]\n","  writable = writable + \"]\"\n","  f.write(writable)\n","\n","def fast_parse(path):\n","  # path = path + \".json.gz\"\n","  max_reviews = 1689188\n","  iter = 5000\n","  counter = 0 \n","  all_reviews = []\n","  g = open(path, 'r')\n","  for line in g:\n","    d = json.loads(line)\n","    all_reviews.append(d)\n","    if (counter % iter) == 0:\n","      print(f\"On line{counter}, {counter/max_reviews} % done\")\n","    counter = counter + 1\n","  return all_reviews"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOhxsOGy7cK4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784763135,"user_tz":240,"elapsed":17871,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"b8c12b85-1faf-4e2b-fa3a-047226d9799e"},"source":["#Csvs\n","\n","train_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/all_train.csv')\n","dev_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/all_test.csv')\n","experiment_set = pd.read_csv('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_test.csv')\n","train_set = train_set.to_dict(orient='records')\n","dev_set = dev_set.to_dict(orient='records')\n","experiment_set = experiment_set.to_dict(orient='records')\n","\n","# #Jsons\n","\n","# train_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_train_binaryposneg.json')\n","# dev_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/electronics_test_binaryposneg.json')\n","# experiment_set = fast_parse('/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/all_test_binaryposneg.json')\n","  \n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"dGB5MH22B1dH"},"source":["### Load the dataset and see what it looks like\n","\n","For now let's first load the training dataset and see what it looks like. We will worry about the dev/test sets later...\n"]},{"cell_type":"code","metadata":{"id":"xaBayxnYB-7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784763137,"user_tz":240,"elapsed":17868,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"81f2bcdb-2687-45b9-f0a5-1fa800e53e7d"},"source":["print(train_set[0]['title_plus_review'])\n","print(\"Number of review in training set: {}\".format(len(train_set)))\n","print(\"Here's how one of the example looks like: {}\".format(json.dumps(train_set[100])))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["great looking and high quality excellent quality ,  will have to remember to empty out the ashes ,  i have heard that will ruin the metal .  will also keep covered when not using . \n","Number of review in training set: 249758\n","Here's how one of the example looks like: {\"Unnamed: 0\": 100, \"reviewText\": \"runs very small. had to give it away; waited too long to return.\", \"summary\": \"Two Stars\", \"overall\": 2.0, \"title_plus_review\": \"two stars runs very small .  had to give it away ;  waited too long to return . \", \"pos_neg\": 0, \"neutrality\": 2, \"num_words\": 15, \"nw\": 13}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thxwPQ84FFrC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784763747,"user_tz":240,"elapsed":18474,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"5eb1987c-52ae-4f02-a8aa-3f643d4ef131"},"source":["import random\n","\n","training_reviews = []\n","id = 0;\n","for  review in train_set:\n","  if 'title_plus_review' not in review:\n","    continue\n","  training_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for training: {}\".format(len(training_reviews)))\n","\n","dev_reviews = []\n","id = 0;\n","for review in dev_set:\n","  #no Review text\n","  if 'title_plus_review' not in review:\n","    continue\n","  dev_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for dev: {}\".format(len(dev_reviews)))\n","\n","experiment_reviews = []\n","id = 0;\n","for review in experiment_set:\n","  #no Review text\n","  if 'title_plus_review' not in review:\n","    continue\n","  experiment_reviews.append({\n","            \"review_id\": id,\n","            \"review_text\": str(review['title_plus_review']).encode('utf-8'),\n","            \"label\": review['overall']\n","        })\n","  \n","  id = id + 1\n","print(\"Number of reviews for experiment: {}\".format(len(experiment_reviews)))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Number of reviews for training: 249758\n","Number of reviews for dev: 49943\n","Number of reviews for experiment: 49954\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wcu0HdxgE7i9"},"source":["### Load Pretrained BERT Model\n"," \n","\n","You can search for the available models [here](https://huggingface.co/models?search=bert).\n","\n","You can find more examples of different use cases for BERT in the transformer github repo README -- https://github.com/huggingface/transformers\n"]},{"cell_type":"code","metadata":{"id":"P7YkHAIjCu4B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619784769066,"user_tz":240,"elapsed":23785,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"0babf8df-7757-4429-e4cf-838600b0d78e"},"source":["from transformers import InputExample\n","from transformers import (WEIGHTS_NAME, BertConfig,\n","                          BertForSequenceClassification, BertTokenizer)\n","from transformers import glue_convert_examples_to_features as convert_examples_to_features\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","import tqdm\n","\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,  TensorDataset)\n","\n","\n","\n","bert_model_type = 'bert-base-uncased' \n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_type, num_labels = 5)\n","config = BertConfig.from_pretrained(bert_model_type)\n","tokenizer = BertTokenizer.from_pretrained(bert_model_type, num_labels = 5)\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Cs-R81c66DoJ"},"source":["### Convert examples to BERT input features\n","\n"]},{"cell_type":"code","metadata":{"id":"0FBUds7v6V9L","executionInfo":{"status":"ok","timestamp":1619784769067,"user_tz":240,"elapsed":23781,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["relevance_label_mapping = {\n","    1.0: 1,\n","    2.0: 2,\n","    3.0: 3,\n","    4.0: 4,\n","    5.0: 5\n","}\n","\n","def convert_sentence_pair_to_tensor_input(sentence_reviews, label_mapping):\n","\n","    # STEP 1: convert each sentence \n","    input_examples = []\n","    for review in sentence_reviews:\n","        current_label = review[\"label\"] if \"label\" in review else print(\"dang\")\n","        input_examples.append(\n","            InputExample(guid=review[\"review_id\"], \n","                         text_a=str(review[\"review_text\"]), \n","                         label=label_mapping[current_label])\n","        )\n","\n","    label_list = [val for _, val in label_mapping.items()]\n","    features = convert_examples_to_features(input_examples,\n","                                                   tokenizer,\n","                                                   label_list=label_list,\n","                                                   max_length = 128,  \n","                                                   output_mode=\"classification\")\n","    \n","    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n","    token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n","    labels = torch.tensor([f.label for f in features], dtype=torch.long)\n","    dataset = TensorDataset(input_ids, attention_mask, token_type_ids, labels)\n","\n","    return dataset"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQHIh7iDMnEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619785204538,"user_tz":240,"elapsed":459249,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"51933e94-413d-4f03-b703-5f76acbc1914"},"source":["train_dataset = convert_sentence_pair_to_tensor_input(training_reviews, relevance_label_mapping)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"V7YsIKmKAEVR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619785274840,"user_tz":240,"elapsed":529546,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"6a62e3b1-ab92-4e69-da17-b49a25caf49b"},"source":["dev_dataset = convert_sentence_pair_to_tensor_input(dev_reviews, relevance_label_mapping)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lTnO2-B1Su2c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619785370419,"user_tz":240,"elapsed":625122,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"29b7a793-20a4-44e5-b41a-87e79aaa58b2"},"source":["experiment_dataset = convert_sentence_pair_to_tensor_input(experiment_reviews, relevance_label_mapping)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OrKngYELCPal"},"source":["### Choose your hyperparameters + model output directory\n"]},{"cell_type":"code","metadata":{"id":"zxxxJxVkCOwJ","executionInfo":{"status":"ok","timestamp":1619785370421,"user_tz":240,"elapsed":625120,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["HYPER_PARAMS = {\n","    \"num_training_epoch\": 3,\n","    \"learning_rate\": 5e-5,        \n","    \"training_batch_size\": 32,    \n","    \"eval_batch_size\": 8,\n","    \"max_grad_norm\": 1.0,\n","    \"num_warmup_steps\": 0.1,\n","    \"dropout_prob\": 0.1\n","}\n"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpHkH6MlaJvh","colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["108d4d1c7148439b80d878b1e818173a","e937a15f4fb94e5d8517a23941c9493e","9fffb14908c54b30b5ee593fc3e6b116","be1d3fc12cdc4fb7aa0320beaf512f9f","6fd7ec5ee2d74c5c8f4535ff464e01da","bd80bc741f844cda8f2fdbc7f36240b3","cd7918b6d7b04885bf46264706ff640d","43171376d6d54ac1b2d8f38ca2eaa2e2","5b8defba99f04e94ad1f0891cfcced7b","4dea1492cc2148bcb0e8d4dd22287898","d362bd5fb6104dea9d29719d6dd7e74a","d8fdc1e7957c440893cded1439d2285b","e39c6f3c068b4afb9b797d60e8a7a8e6","f2b6b160ee1c471f8b049b74c479c095","0a84b0056d3c46b4b95816fb46754a5e","5d863ff311f14237986f609ada4c7a38","00d4c92fa30f4328b722bcd19dc39453","a0ce5205eb674f598014caff2cd538cd","8dca804e5afc40feaf28114d48ad8736","f47fd3309c42424bb6361ccd1738cc93","c3d5233cc73e4f57b34a2a22c5c77479","5251576755d5453d9ae97843101b1ff3","7fecd30b65e141618ffcd9508424b36c","1c3d6070a66847c08ff02ba3194025b9"]},"executionInfo":{"status":"ok","timestamp":1619794330275,"user_tz":240,"elapsed":9584970,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"5c8eb85a-53e4-4c5b-c294-b199de2ed5bb"},"source":["torch.cuda.manual_seed(42)\n","torch.manual_seed(42)\n","random.seed(42)\n","np.random.seed(42)\n","\n","bert_model.hidden_dropout_prob = HYPER_PARAMS['dropout_prob']\n","bert_model.to(\"cuda\")\n","optimizer = AdamW(bert_model.parameters(), \n","                    lr=HYPER_PARAMS['learning_rate'], \n","                    correct_bias=False)\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, \n","                              sampler=train_sampler, \n","                              batch_size=HYPER_PARAMS[\"training_batch_size\"])\n","\n","# optimizer = AdamW(bert_model.parameters(), \n","#                   lr=HYPER_PARAMS['learning_rate'], \n","#                   correct_bias=False)\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=HYPER_PARAMS['num_warmup_steps'], \n","                                            num_training_steps=len(train_dataloader))\n","\n","\n","global_step = 0\n","tr_loss = 0.0\n","bert_model.zero_grad()\n","bert_model.train()\n","\n","for epc in range(HYPER_PARAMS[\"num_training_epoch\"]):\n","    print(\"Epoch #{}: \\n\".format(epc))\n","    epoch_iterator = tqdm.notebook.tqdm(train_dataloader, desc=\"Training Steps\")\n","    avg_loss_over_epoch = []\n","    for step, batch in enumerate(epoch_iterator):\n","        batch = tuple(t.to('cuda') for t in batch)\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'token_type_ids': batch[2],\n","                  'labels': batch[3]}\n","\n","        outputs = bert_model(**inputs)\n","        loss = outputs[0]  \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), HYPER_PARAMS[\"max_grad_norm\"])\n","        tr_loss += loss.item()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        bert_model.zero_grad()"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Epoch #0: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"108d4d1c7148439b80d878b1e818173a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #1: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b8defba99f04e94ad1f0891cfcced7b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #2: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00d4c92fa30f4328b722bcd19dc39453","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mF4FJlwLaYpO","executionInfo":{"status":"ok","timestamp":1619794332219,"user_tz":240,"elapsed":9586908,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["import os\n","output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/all_5cat_bert_base_adam/'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","bert_model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","config.save_pretrained(output_dir)"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4tGbX8HYEZE"},"source":["Load Model\n"]},{"cell_type":"code","metadata":{"id":"wnbXCg8_fvZz","executionInfo":{"status":"ok","timestamp":1619794335801,"user_tz":240,"elapsed":9590488,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/all_5cat_bert_base_adam/'\n","bert_model = BertForSequenceClassification.from_pretrained(output_dir, num_labels = 5)\n","tokenizer = BertTokenizer.from_pretrained(output_dir, num_labels = 5)\n","\n","bert_model = bert_model.to(\"cuda\")\n","  "],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"mk3UTWDPf5Fn","executionInfo":{"status":"ok","timestamp":1619794335804,"user_tz":240,"elapsed":9590488,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["results = pd.DataFrame(columns=['Type', \"Model\", 'Optimizer', \"Train Set\", 'Test Set', 'LR', 'Dropout','F1', 'Accuracy', 'Recall', 'Precision' ])\n","optimizer_name = \"ADAM\"\n","test_set_name = \"All\""],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"0E2zPR6Zf9f4","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["8871744702ce4241881322572940ccc8","c06018ece495435ca245a1acd8791b1e","df40e40e2fb5477fbb1819572604cead","8f5ba70d703f46afbea22a7d35b1dea9","e6fa7c164a294429bc91532db4550766","861db3874cfe40ad9ab0aae2a15604b0","54a065417b314d759a5e19e7ad39940c","29bb95266be5449889a0a3922d22e07b"]},"executionInfo":{"status":"ok","timestamp":1619794564143,"user_tz":240,"elapsed":9818824,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"69b1a135-a237-4df7-8979-57f4a4304d2f"},"source":["\n","dev_sampler = SequentialSampler(dev_dataset)\n","dev_dataloader = DataLoader(dev_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Dev set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec}\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":55,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8871744702ce4241881322572940ccc8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating on Dev set...', max=6243.0, style=ProgressStylâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","The accuracy on dev set = 0.6367659131409807\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vxSka3XzgSBc","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1619794564399,"user_tz":240,"elapsed":9819075,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"a1cf3203-8b2c-42cf-c762-d67344840119"},"source":["results"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Model</th>\n","      <th>Optimizer</th>\n","      <th>Train Set</th>\n","      <th>Test Set</th>\n","      <th>LR</th>\n","      <th>Dropout</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>ALL</td>\n","      <td>All</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.515925</td>\n","      <td>0.636766</td>\n","      <td>0.577089</td>\n","      <td>0.496703</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type              Model Optimizer  ...  Accuracy    Recall  Precision\n","0  5Cat  bert-base-uncased      ADAM  ...  0.636766  0.577089   0.496703\n","\n","[1 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"2vToncX0RXBL"},"source":["Test on other dataset"]},{"cell_type":"code","metadata":{"id":"NLOZ8euiVa9I","executionInfo":{"status":"ok","timestamp":1619794564402,"user_tz":240,"elapsed":9819073,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["test_set_name = \"Elec\""],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2SfXooaRb_V","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["0f2bce081b334e2eae1177d0d15f5cf1","d7d6384d21cd46bcb02df880cb89afad","6c33c53566ec40b5918ac52976037984","f56bf14042db42649a69a9c8ec478a66","17e02a9ed25f45bbbaa82c00a7bc21b8","3ec0cd60c486491fa252351f50aa8088","991e3fa5b86c47a5bca5591ff87a1c53","8852fdc80b7f4947880b67cd9ff6c474"]},"executionInfo":{"status":"ok","timestamp":1619794792950,"user_tz":240,"elapsed":10047616,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"91368731-1d55-4bdd-a440-eaa0f2d4a97e"},"source":["dev_sampler = SequentialSampler(experiment_dataset)\n","dev_dataloader = DataLoader(experiment_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Experiment set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":58,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f2bce081b334e2eae1177d0d15f5cf1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating on Experiment set...', max=6245.0, style=Progrâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","The accuracy on dev set = 0.5700444408856148\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ftVqdSfjZOvD","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1619794792953,"user_tz":240,"elapsed":10047614,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"e0900f94-674c-4a41-aaf5-945b7cb6a6ea"},"source":["results"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Model</th>\n","      <th>Optimizer</th>\n","      <th>Train Set</th>\n","      <th>Test Set</th>\n","      <th>LR</th>\n","      <th>Dropout</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>ALL</td>\n","      <td>All</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.515925</td>\n","      <td>0.636766</td>\n","      <td>0.577089</td>\n","      <td>0.496703</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5Cat</td>\n","      <td>bert-base-uncased</td>\n","      <td>ADAM</td>\n","      <td>ALL</td>\n","      <td>Elec</td>\n","      <td>0.00005</td>\n","      <td>0.1</td>\n","      <td>0.558293</td>\n","      <td>0.570044</td>\n","      <td>0.559047</td>\n","      <td>0.565623</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type              Model Optimizer  ...  Accuracy    Recall  Precision\n","0  5Cat  bert-base-uncased      ADAM  ...  0.636766  0.577089   0.496703\n","1  5Cat  bert-base-uncased      ADAM  ...  0.570044  0.559047   0.565623\n","\n","[2 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"a_Pl3CTLhNEb"},"source":["##MADGRAD"]},{"cell_type":"code","metadata":{"id":"BQ671-9Rg7OY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619794798227,"user_tz":240,"elapsed":10052883,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}},"outputId":"fe6493d1-549c-4521-b689-ff82d4707995"},"source":["\n","bert_model_type = 'bert-base-uncased'  \n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_type, num_labels = 5)\n","config = BertConfig.from_pretrained(bert_model_type)\n","tokenizer = BertTokenizer.from_pretrained(bert_model_type, num_labels = 5)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QJ5ZvPUCg8Ci","executionInfo":{"status":"ok","timestamp":1619794798230,"user_tz":240,"elapsed":10052881,"user":{"displayName":"Tom Donnelly","photoUrl":"","userId":"14552623635511429550"}}},"source":["HYPER_PARAMS = {\n","    \"num_training_epoch\": 3,\n","    \"learning_rate\": 5e-5,        \n","    \"training_batch_size\": 32,    \n","    \"eval_batch_size\": 8,\n","    \"max_grad_norm\": 1.0,\n","    \"num_warmup_steps\": 0.1,\n","    \"dropout_prob\": 0.1\n","}"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBqm2R_pX4z-"},"source":[""]},{"cell_type":"code","metadata":{"id":"kOSdC8fUhVDo","colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["8f48c5a09aff41c2a9606b7bae05b373","3b1a0347f54e4c96b993ab988aac2cf2","6f0873da5dd54c2bb367b2bc57fc8c8f","a779b517ecd649439fc156d84dd56507","46b2cec21f114ac3bd783eb5fbfb1e22","4133bd81ebc3498b985a4bdf10ab782c","a1549ecac5164f7080bd59b0b9857f7e","43e5d58db5034b56b8d3c863ac85d536","9362d7d8ecbd49b285de2e1c3a0a3ea9","48c4f5fe29ca4c069ebb0fb0d5fa8ae6","cd85c9630463451fb47029a3bcbea15d","9cf31b125cf14958afaae529d036c50b","d12fce0468214163a5fdebf483190fa1","22537fff5f364976a9ed9d4fd88d2ee4","5e5528b8ab1d4c8b897b11cab81a052f","fe51610b215a429daf7685f82493f538","a9c3a1b64c8a4d7ebeff14645548cc95","92101677a82f45b3826de4f3dada80ae","1b5006d6ec504d1aa79e4277083a2b82","dec69030e7f54ff2ae39c9f9732b3d3d","089d40146c934218a890aa0bad8127cd","8dcb210eb3154e3fa9ba0b1648114ecc","1aad3cf335f94621bcc72669465700ab","eb136725bae44d3988c27af247a6c908"]},"outputId":"39e2c70b-4f9c-4c40-e1b4-1ed1e9fb05aa"},"source":["from madgrad import MADGRAD\n","torch.cuda.manual_seed(42)\n","torch.manual_seed(42)\n","random.seed(42)\n","np.random.seed(42)\n","\n","bert_model.hidden_dropout_prob = HYPER_PARAMS['dropout_prob']\n","bert_model.to(\"cuda\")\n","optimizer = MADGRAD(bert_model.parameters(), \n","                    lr=HYPER_PARAMS['learning_rate'])\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, \n","                              sampler=train_sampler, \n","                              batch_size=HYPER_PARAMS[\"training_batch_size\"])\n","\n","# optimizer = AdamW(bert_model.parameters(), \n","#                   lr=HYPER_PARAMS['learning_rate'], \n","#                   correct_bias=False)\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=HYPER_PARAMS['num_warmup_steps'], \n","                                            num_training_steps=len(train_dataloader))\n","\n","\n","global_step = 0\n","tr_loss = 0.0\n","bert_model.zero_grad()\n","bert_model.train()\n","\n","for epc in range(HYPER_PARAMS[\"num_training_epoch\"]):\n","    print(\"Epoch #{}: \\n\".format(epc))\n","    epoch_iterator = tqdm.notebook.tqdm(train_dataloader, desc=\"Training Steps\")\n","    avg_loss_over_epoch = []\n","    for step, batch in enumerate(epoch_iterator):\n","        batch = tuple(t.to('cuda') for t in batch)\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'token_type_ids': batch[2],\n","                  'labels': batch[3]}\n","\n","        outputs = bert_model(**inputs)\n","        loss = outputs[0]  \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), HYPER_PARAMS[\"max_grad_norm\"])\n","        tr_loss += loss.item()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        bert_model.zero_grad()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch #0: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f48c5a09aff41c2a9606b7bae05b373","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #1: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9362d7d8ecbd49b285de2e1c3a0a3ea9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch #2: \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9c3a1b64c8a4d7ebeff14645548cc95","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Training Steps', max=7805.0, style=ProgressStyle(descriptâ€¦"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rmIQ1L8yhkee"},"source":["# This is where we mounted your google drive. \n","# You might need to re-mount it if your session was closed half way through\n","output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/all_5cat_bert_base_madgrad/'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","bert_model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","config.save_pretrained(output_dir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVTeKJlHYLPc"},"source":["Load Model\n"]},{"cell_type":"code","metadata":{"id":"_iutoZkqYKiB"},"source":["output_dir = '/content/drive/MyDrive/cis519_final/Bert-Base Models/all_5cat_bert_base_madgrad/' \n","bert_model = BertForSequenceClassification.from_pretrained(output_dir, num_labels = 5)\n","tokenizer = BertTokenizer.from_pretrained(output_dir, num_labels = 5)\n","\n","bert_model = bert_model.to(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKMheJ4uj9oV"},"source":["results = pd.DataFrame(columns=['Type', \"Model\", 'Optimizer', \"Train Set\", 'Test Set', 'LR', 'Dropout','F1', 'Accuracy', 'Recall', 'Precision' ])\n","test_set_name = \"All\"\n","optimizer_name = \"Madgrad\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJkDdQApv1zM"},"source":["dev_sampler = SequentialSampler(dev_dataset)\n","dev_dataloader = DataLoader(dev_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Dev set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir+\"results.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bGz9OOrhwTmp"},"source":["results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"efFstRW0Yioa"},"source":["Test experiment"]},{"cell_type":"code","metadata":{"id":"Y6c0lpIiYlZc"},"source":["test_set_name = \"Elec\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1mZHjK-YlZe"},"source":["dev_sampler = SequentialSampler(experiment_dataset)\n","dev_dataloader = DataLoader(experiment_dataset, \n","                            sampler=dev_sampler, \n","                            batch_size=HYPER_PARAMS[\"eval_batch_size\"])\n","\n","predictions = None\n","out_label_ids = None\n","\n","for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating on Experiment set...\"):\n","    bert_model.eval()\n","    batch = tuple(t.to(\"cuda\") for t in batch)\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'token_type_ids': batch[2],\n","              'labels': batch[3]}\n","\n","    with torch.no_grad():\n","        outputs = bert_model(**inputs)\n","        logits = outputs[1] # This is 1x2 tensor, containing scores for both labels \n","    if predictions is None:\n","        predictions = logits.detach().cpu().numpy()\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\n","    else:\n","        predictions = np.append(predictions, logits.detach().cpu().numpy(), axis=0)\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","# whichever label gets higher score, we will predict that label\n","predictions = np.argmax(predictions, axis=1)\n","# print(predictions)\n","# print(out_label_ids)\n","\n","\n","f1, acc, rec, prec = get_metrics(out_label_ids, predictions)\n","row = {'Type': type_name, 'Model':bert_model_type, 'Optimizer':optimizer_name, \"Train Set\": train_set_name, \"Test Set\": test_set_name, 'LR': HYPER_PARAMS['learning_rate'], 'Dropout':HYPER_PARAMS['dropout_prob'], 'F1': f1, 'Accuracy': acc, 'Recall': rec, 'Precision':prec, }\n","print(\"The accuracy on dev set = {}\".format(acc))\n","results = results.append(row, ignore_index = True)\n","results.to_csv(output_dir +\"results.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJ-zt2Vkb3lT"},"source":["results"],"execution_count":null,"outputs":[]}]}