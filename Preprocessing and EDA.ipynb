{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in c:\\users\\galla\\anaconda3\\lib\\site-packages (2.25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\galla\\anaconda3\\lib\\site-packages (from dask) (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dask\n",
    "pip install delayed imbalanced-learn\n",
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask \n",
    "import dask.dataframe as dd\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in the form of zipped json files, so extract them and load them into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "#df = getDF('Gift_Cards_5.json.gz')\n",
    "#df = df[df['reviewText'].notna()]\n",
    "#df.info()\n",
    "#display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6738237 entries, 0 to 6739589\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   overall         float64\n",
      " 1   vote            object \n",
      " 2   verified        bool   \n",
      " 3   reviewTime      object \n",
      " 4   reviewerID      object \n",
      " 5   asin            object \n",
      " 6   style           object \n",
      " 7   reviewerName    object \n",
      " 8   reviewText      object \n",
      " 9   summary         object \n",
      " 10  unixReviewTime  int64  \n",
      " 11  image           object \n",
      "dtypes: bool(1), float64(1), int64(1), object(9)\n",
      "memory usage: 623.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>D. C. Carrad</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Evy</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Paperback'}</td>\n",
       "      <td>Kcorn</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Caf Girl Writes</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>W. Shane Schmidt</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n",
       "1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n",
       "2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n",
       "3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n",
       "4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n",
       "\n",
       "                            style      reviewerName  \\\n",
       "0       {'Format:': ' Hardcover'}      D. C. Carrad   \n",
       "1  {'Format:': ' Kindle Edition'}               Evy   \n",
       "2       {'Format:': ' Paperback'}             Kcorn   \n",
       "3       {'Format:': ' Hardcover'}   Caf Girl Writes   \n",
       "4       {'Format:': ' Hardcover'}  W. Shane Schmidt   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is the best novel I have read in 2 or 3 y...   \n",
       "1  Pages and pages of introspection, in the style...   \n",
       "2  This is the kind of novel to read when you hav...   \n",
       "3  What gorgeous language! What an incredible wri...   \n",
       "4  I was taken in by reviews that compared this b...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                                     A star is born       937612800   NaN  \n",
       "1                    A stream of consciousness novel      1382486400   NaN  \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   NaN  \n",
       "3          The most beautiful book I have ever read!       968025600   NaN  \n",
       "4                        A dissenting view--In part.       949622400   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elec = getDF('Electronics_5_2018.json.gz')\n",
    "\n",
    "#We don't have much use for any records without reviews\n",
    "elec = elec[elec['reviewText'].notna()]\n",
    "\n",
    "elec.info()\n",
    "display(elec.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a helpful reminder from the data doc, we know that:\n",
    "\n",
    "reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "\n",
    "asin - ID of the product, e.g. 0000013714\n",
    "\n",
    "reviewerName - name of the reviewer\n",
    "\n",
    "vote - helpful votes of the review\n",
    "\n",
    "style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "\n",
    "reviewText - text of the review\n",
    "\n",
    "overall - rating of the product\n",
    "\n",
    "summary - summary of the review\n",
    "\n",
    "unixReviewTime - time of the review (unix time)\n",
    "\n",
    "reviewTime - time of the review (raw)\n",
    "\n",
    "image - images that users post after they have received the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_ddf = dd.from_pandas(elec, npartitions = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go modeling, we want to get an idea of how our data is distributed. We are mainly interested in the rating of the product, the review itself, and potentially the review summary as well as users themselves.\n",
    "\n",
    "Let's start by looking at how our ground truths, the ratings, are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    4322520\n",
       "4.0    1137229\n",
       "3.0     504712\n",
       "1.0     467117\n",
       "2.0     306659\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec['overall'].value_counts()\n",
    "\n",
    "#using dask\n",
    "#elec_ddf.overall.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='overall', ylabel='count'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAERCAYAAABxZrw0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOzUlEQVR4nO3de4yldX3H8feHi0ULBJsdFFnsGoNUQhFki8RtQTfGrDewhlJMwUap26ZCIUVMbZNW2jRN02q0FrUbRKQqBrkYJK1IKjcpt1nuy0pCKFAq7S43uTShBb/94zzbHWZnd88y88w5+zvvVzLZOed55jy/+YV978NznvlNqgpJUnt2GfUAJEn9MPCS1CgDL0mNMvCS1CgDL0mNMvCS1KixC3yS85JsSHLPkPufkOTeJOuSfKvv8UnSziLjdh98kqOBZ4ELquqQ7ex7IHARsLKqnkyyb1VtWIxxStK4G7sz+Kq6Dnhi5nNJ3pjk+0nWJrk+yS91mz4OnFNVT3Zfa9wlqTN2gd+KNcBpVXUE8EngS93zbwLelOSGJDclWTWyEUrSmNlt1APYniR7Am8HvpNk09M/1/25G3Ag8A5gKXB9kkOq6qlFHqYkjZ2xDzyD/8t4qqoOm2PbI8BNVfW/wL8luY9B8G9dxPFJ0lga+0s0VfU0g3j/BkAG3tJt/i7wzu75JQwu2TwwinFK0rgZu8AnuRC4ETgoySNJTgF+CzglyZ3AOuC4bvcrgceT3AtcDZxVVY+PYtySNG7G7jZJSdLCGLszeEnSwhirN1mXLFlSy5YtG/UwJGmnsXbt2seqamqubWMV+GXLljE9PT3qYUjSTiPJQ1vb5iUaSWqUgZekRhl4SWqUgZekRhl4SWqUgZekRhl4SWqUgZekRhl4SWrUWP0kqyTN19+f+b1RD6EXp372Azv8NZ7BS1KjDLwkNcrAS1KjDLwkNcrAS1KjDLwkNcrAS1KjDLwkNcrAS1KjDLwkNcrAS1Kjeg98kl2T3J7kir6PJUnabDHO4E8H1i/CcSRJM/Qa+CRLgfcB5/Z5HEnSlvo+g/888CngZ1vbIcnqJNNJpjdu3NjzcCRpcvQW+CTvBzZU1dpt7VdVa6pqeVUtn5qa6ms4kjRx+jyDXwEcm+RB4NvAyiTf6PF4kqQZegt8VX26qpZW1TLgROCHVXVSX8eTJL2U98FLUqMW5XeyVtU1wDWLcSxJ0oBn8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUqN4Cn2SPJLckuTPJuiRn93UsSdKWduvxtZ8HVlbVs0l2B36U5J+r6qYejylJ6vQW+Koq4Nnu4e7dR/V1PEnSS/V6DT7JrknuADYAV1XVzXPsszrJdJLpjRs39jkcSZoovQa+ql6sqsOApcCRSQ6ZY581VbW8qpZPTU31ORxJmiiLchdNVT0FXAOsWozjSZL6vYtmKsk+3eevBN4F/Liv40mSXqrPu2j2A76eZFcG/5BcVFVX9Hg8SdIMfd5FcxdweF+vL0naNn+SVZIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVFDBT7JvwzznCRpfGzzd7Im2QN4FbAkyauBdJv2Bl7X89gkSfOwvV+6/bvAGQxivpbNgX8aOKe/YUmS5mubga+qLwBfSHJaVX1xkcYkSVoA2zuDB6Cqvpjk7cCymV9TVRf0NC5J0jwNFfgk/wi8EbgDeLF7ugADL0ljaqjAA8uBg6uq+hyMJGnhDHsf/D3Aa/sciCRpYQ17Br8EuDfJLcDzm56sqmN7GZUkad6GDfxn+hyEJGnhDXsXzbV9D0SStLCGvYvmGQZ3zQC8AtgdeK6q9u5rYJKk+Rn2DH6vmY+TfBA4so8BSZIWxstaTbKqvgusXNihSJIW0rCXaD404+EuDO6L9554SRpjw95F84EZn78APAgct+CjkSQtmGGvwX+074FIkhbWsL/wY2mSy5JsSPJfSS5JsrTvwUmSXr5h32T9GnA5g3Xh9we+1z0nSRpTwwZ+qqq+VlUvdB/nA1M9jkuSNE/DBv6xJCcl2bX7OAl4vM+BSZLmZ9jAfww4AfhP4FHgeGCbb7wmOSDJ1UnWJ1mX5PT5DVWStCOGvU3yL4DfrqonAZL8AvC3DMK/NS8AZ1bVbUn2AtYmuaqq7p3XiCVJQxn2DP7QTXEHqKongMO39QVV9WhV3dZ9/gywnsEbtJKkRTBs4HdJ8upND7oz+GHP/kmyjME/CDfPsW11kukk0xs3bhz2JSVJ2zFspD8L/GuSixksUXAC8JfDfGGSPYFLgDOq6unZ26tqDbAGYPny5S5/IEkLZNifZL0gyTSDBcYCfGiYa+lJdmcQ929W1aXzGqkkaYcMfZmlC/rQb5AmCfBVYH1Vfe5ljE2SNA8va7ngIa0ATgZWJrmj+3hvj8eTJM0w9Bn8jqqqHzG4nCNJGoE+z+AlSSNk4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhpl4CWpUQZekhq126gHIGn+rj36mFEPoRfHXHftqIewU/MMXpIaZeAlqVEGXpIa1Vvgk5yXZEOSe/o6hiRp6/o8gz8fWNXj60uStqG3wFfVdcATfb2+JGnbRn4NPsnqJNNJpjdu3Djq4UhSM0Ye+KpaU1XLq2r51NTUqIcjSc0YeeAlSf0w8JLUqD5vk7wQuBE4KMkjSU7p61iSpC31thZNVX24r9eWJG2fl2gkqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIaZeAlqVEGXpIa1duv7JP6tuKLK0Y9hF7ccNoNox6CGrFTBP6Isy4Y9RB6sfZvPjLqIUhqmJdoJKlRBl6SGmXgJalRBl6SGmXgJalRBl6SGmXgJalRO8V98Nrs4T//5VEPoRev/9O7Rz0EqTmewUtSowy8JDXKwEtSowy8JDXKwEtSowy8JDXKwEtSowy8JDXKwEtSowy8JDXKwEtSo3oNfJJVSe5Lcn+SP+rzWJKkl+ot8El2Bc4B3gMcDHw4ycF9HU+S9FJ9nsEfCdxfVQ9U1f8A3waO6/F4kqQZUlX9vHByPLCqqn6ne3wy8LaqOnXWfquB1d3Dg4D7ehnQ8JYAj414DOPCudjMudjMudhsHObiF6tqaq4Nfa4Hnzme2+Jfk6paA6zpcRw7JMl0VS0f9TjGgXOxmXOxmXOx2bjPRZ+XaB4BDpjxeCnwkx6PJ0maoc/A3wocmOQNSV4BnAhc3uPxJEkz9HaJpqpeSHIqcCWwK3BeVa3r63gLaGwuF40B52Iz52Iz52KzsZ6L3t5klSSNlj/JKkmNMvCS1KiJDHyS85JsSHLPVrYnyd91SyzcleStiz3GxZLkgCRXJ1mfZF2S0+fYZyLmI8keSW5Jcmc3F2fPsc9EzAUMfho9ye1Jrphj28TMA0CSB5PcneSOJNNzbB/L+ZjIwAPnA6u2sf09wIHdx2rgy4swplF5ATizqt4MHAV8Yo4lJSZlPp4HVlbVW4DDgFVJjpq1z6TMBcDpwPqtbJukedjknVV12Fbuex/L+ZjIwFfVdcAT29jlOOCCGrgJ2CfJfoszusVVVY9W1W3d588w+Au9/6zdJmI+uu/v2e7h7t3H7LsQJmIukiwF3gecu5VdJmIedsBYzsdEBn4I+wP/PuPxI2wZveYkWQYcDtw8a9PEzEd3WeIOYANwVVVN6lx8HvgU8LOtbJ+UedikgB8kWdstrzLbWM6HgZ/bUMsstCTJnsAlwBlV9fTszXN8SZPzUVUvVtVhDH7y+sgkh8zapfm5SPJ+YENVrd3WbnM819Q8zLKiqt7K4FLMJ5IcPWv7WM6HgZ/bRC2zkGR3BnH/ZlVdOscuEzUfAFX1FHANW75XMwlzsQI4NsmDDFaBXZnkG7P2mYR5+H9V9ZPuzw3AZQxWy51pLOfDwM/tcuAj3TvjRwE/rapHRz2oPiQJ8FVgfVV9biu7TcR8JJlKsk/3+SuBdwE/nrVb83NRVZ+uqqVVtYzBEiM/rKqTZu3W/DxskuTnk+y16XPg3cDsO/DGcj76XE1ybCW5EHgHsCTJI8CfMXhDjar6CvBPwHuB+4H/Bj46mpEuihXAycDd3bVngD8GXg8TNx/7AV/P4JfV7AJcVFVXJPk9mLi52MIEz8NrgMsG50LsBnyrqr6/M8yHSxVIUqO8RCNJjTLwktQoAy9JjTLwktQoAy9JjTLw0gJLck2S5d3nDyZZMuoxaTIZeGkHdT/M4t8djT3/I9VESPKHSe7pPs5I8tdJfn/G9s8kObP7/Kwkt3brep/dPbcsgzXzvwTcBhyQ5MtJpre2drw0agZezUtyBIOfLHwbgzXvP85gjZXfnLHbCcB3krybwZreRzJYE/6IGQtLHcRgSdjDq+oh4E+6tcEPBY5JcuhifD/SsCZyqQJNnF8FLquq5wCSXAr8GrBvktcBU8CTVfVwkj9gsNbI7d3X7skg+A8DD3VrfW9yQrd07G4Mljk4GLhrMb4haRgGXpNgrqVcAS4Gjgdey+CMftO+f1VV//CSFxislf/cjMdvAD4J/EpVPZnkfGCPhR22ND9eotEkuA74YJJXdasB/jpwPYOon8gg8hd3+14JfKxbH58k+yfZd47X3JtB8H+a5DUM1gmXxopn8GpeVd3WnWHf0j11blXdDtAtA/sfm5Z2raofJHkzcGO3euCzwEnAi7Ne884ktwPrgAeAGxbje5F2hKtJSlKjvEQjSY0y8JLUKAMvSY0y8JLUKAMvSY0y8JLUKAMvSY36P7NPp5wfIsmrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(elec['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reviews are highly skewed. This is not necessarily a problem with the sample- people may simply feel more comfortable rating things positively, or there may simply be fewer very bad experiences. However, this is not ideal for us, as we don't want our algorithm to become biased toward classifying reviews as positive (as it may be able to generally get more samples correct that way). Since we already have a massive abundance of data, we might want to try downsampling some of the higher ratings to make things a bit more even.\n",
    "\n",
    "But first, let's explore the data a bit more- some of our cleaning might make our data a bit more balanced naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's copy our dataframe and get rid of the style and image columns, which are not very useful and rather unwieldy\n",
    "\n",
    "el = elec.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "el.drop(['style', 'reviewerName', 'image'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Before cleaning, our data has 5 reviews from each user. Do we want to try to normalize the ratings by the other ratings users did, turning our problem into a continuous prediction problem rather than classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verified distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     6037146\n",
       "False     701091\n",
       "Name: verified, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el['verified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that while most of our reviews are verified, we have a significant amount of unverified reviews. Only using verified reviews will make our data less susceptible to bots and trolls, but may end up excluding a subpopulation of \"real\" shoppers (for instance, people reviewing something someone else bought for them, or people who received some sort of discount)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = pd.read_csv('electronics_shortened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the best novel i have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>pages and pages of introspective  ,   in the s...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>what gorgeous language  !   what an incredible...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>i was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 11, 2014</td>\n",
       "      <td>A1ZZFX6SHV84ZU</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>very nice item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1410393600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 11, 2014</td>\n",
       "      <td>A34JP15SDQIII6</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>since b and n no longer carry the book color  ...</td>\n",
       "      <td>If you need one, get this one</td>\n",
       "      <td>1410393600</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 18, 2016</td>\n",
       "      <td>A3HN9PMEGAM6JT</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>works great with book color</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1455753600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 11, 2016</td>\n",
       "      <td>A1CHTT6E3NV5YL</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>the 90 degree connector is a bonus that allows...</td>\n",
       "      <td>Works great on my Wife's older model Nook Color.</td>\n",
       "      <td>1455148800</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 7, 2016</td>\n",
       "      <td>A1N8CPCN6PT8FP</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>great solution to original power cord  .    ne...</td>\n",
       "      <td>Good Product</td>\n",
       "      <td>1454803200</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  overall vote  verified   reviewTime      reviewerID  \\\n",
       "0            0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM   \n",
       "1            1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV   \n",
       "2            2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3   \n",
       "3            3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5   \n",
       "4            4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE   \n",
       "..         ...      ...  ...       ...          ...             ...   \n",
       "95          95      5.0  NaN      True  09 11, 2014  A1ZZFX6SHV84ZU   \n",
       "96          96      5.0  NaN      True  09 11, 2014  A34JP15SDQIII6   \n",
       "97          97      5.0  NaN      True  02 18, 2016  A3HN9PMEGAM6JT   \n",
       "98          98      5.0  NaN      True  02 11, 2016  A1CHTT6E3NV5YL   \n",
       "99          99      5.0  NaN      True   02 7, 2016  A1N8CPCN6PT8FP   \n",
       "\n",
       "          asin                                         reviewText  \\\n",
       "0   0151004714  this is the best novel i have read in 2 or 3 y...   \n",
       "1   0151004714  pages and pages of introspective  ,   in the s...   \n",
       "2   0151004714  this is the kind of novel to read when you hav...   \n",
       "3   0151004714  what gorgeous language  !   what an incredible...   \n",
       "4   0151004714  i was taken in by reviews that compared this b...   \n",
       "..         ...                                                ...   \n",
       "95  0594033926                                     very nice item   \n",
       "96  0594033926  since b and n no longer carry the book color  ...   \n",
       "97  0594459451                        works great with book color   \n",
       "98  0594459451  the 90 degree connector is a bonus that allows...   \n",
       "99  0594459451  great solution to original power cord  .    ne...   \n",
       "\n",
       "                                              summary  unixReviewTime  \\\n",
       "0                                      A star is born       937612800   \n",
       "1                     A stream of consciousness novel      1382486400   \n",
       "2   I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3           The most beautiful book I have ever read!       968025600   \n",
       "4                         A dissenting view--In part.       949622400   \n",
       "..                                                ...             ...   \n",
       "95                                         Five Stars      1410393600   \n",
       "96                      If you need one, get this one      1410393600   \n",
       "97                                         Five Stars      1455753600   \n",
       "98   Works great on my Wife's older model Nook Color.      1455148800   \n",
       "99                                       Good Product      1454803200   \n",
       "\n",
       "    num_words  \n",
       "0         197  \n",
       "1          81  \n",
       "2         362  \n",
       "3         233  \n",
       "4         283  \n",
       "..        ...  \n",
       "95          3  \n",
       "96         26  \n",
       "97          5  \n",
       "98         49  \n",
       "99         39  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= el.iloc[:100]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 64.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galla\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test['reviewText'] = test['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_ddf = dd.from_pandas(test, npartitions = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galla\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:3207: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('reviewText', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_ddf['reviewText'] = test_ddf['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=50\n",
       "0     object\n",
       "2        ...\n",
       "       ...  \n",
       "98       ...\n",
       "99       ...\n",
       "Name: reviewText, dtype: object\n",
       "Dask Name: getitem, 250 tasks"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddf['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the best novel i have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>pages and pages of introspective   ,    in the...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>what gorgeous language   !    what an incredib...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>i was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 11, 2014</td>\n",
       "      <td>A1ZZFX6SHV84ZU</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>very nice item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1410393600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 11, 2014</td>\n",
       "      <td>A34JP15SDQIII6</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>since b and n no longer carry the book color  ...</td>\n",
       "      <td>If you need one, get this one</td>\n",
       "      <td>1410393600</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 18, 2016</td>\n",
       "      <td>A3HN9PMEGAM6JT</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>works great with book color</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1455753600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 11, 2016</td>\n",
       "      <td>A1CHTT6E3NV5YL</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>the 90 degree connector is a bonus that allows...</td>\n",
       "      <td>Works great on my Wife's older model Nook Color.</td>\n",
       "      <td>1455148800</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 7, 2016</td>\n",
       "      <td>A1N8CPCN6PT8FP</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>great solution to original power cord   .     ...</td>\n",
       "      <td>Good Product</td>\n",
       "      <td>1454803200</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  overall vote  verified   reviewTime      reviewerID  \\\n",
       "0            0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM   \n",
       "1            1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV   \n",
       "2            2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3   \n",
       "3            3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5   \n",
       "4            4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE   \n",
       "..         ...      ...  ...       ...          ...             ...   \n",
       "95          95      5.0  NaN      True  09 11, 2014  A1ZZFX6SHV84ZU   \n",
       "96          96      5.0  NaN      True  09 11, 2014  A34JP15SDQIII6   \n",
       "97          97      5.0  NaN      True  02 18, 2016  A3HN9PMEGAM6JT   \n",
       "98          98      5.0  NaN      True  02 11, 2016  A1CHTT6E3NV5YL   \n",
       "99          99      5.0  NaN      True   02 7, 2016  A1N8CPCN6PT8FP   \n",
       "\n",
       "          asin                                         reviewText  \\\n",
       "0   0151004714  this is the best novel i have read in 2 or 3 y...   \n",
       "1   0151004714  pages and pages of introspective   ,    in the...   \n",
       "2   0151004714  this is the kind of novel to read when you hav...   \n",
       "3   0151004714  what gorgeous language   !    what an incredib...   \n",
       "4   0151004714  i was taken in by reviews that compared this b...   \n",
       "..         ...                                                ...   \n",
       "95  0594033926                                     very nice item   \n",
       "96  0594033926  since b and n no longer carry the book color  ...   \n",
       "97  0594459451                        works great with book color   \n",
       "98  0594459451  the 90 degree connector is a bonus that allows...   \n",
       "99  0594459451  great solution to original power cord   .     ...   \n",
       "\n",
       "                                              summary  unixReviewTime  \\\n",
       "0                                      A star is born       937612800   \n",
       "1                     A stream of consciousness novel      1382486400   \n",
       "2   I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3           The most beautiful book I have ever read!       968025600   \n",
       "4                         A dissenting view--In part.       949622400   \n",
       "..                                                ...             ...   \n",
       "95                                         Five Stars      1410393600   \n",
       "96                      If you need one, get this one      1410393600   \n",
       "97                                         Five Stars      1455753600   \n",
       "98   Works great on my Wife's older model Nook Color.      1455148800   \n",
       "99                                       Good Product      1454803200   \n",
       "\n",
       "    num_words  \n",
       "0         197  \n",
       "1          81  \n",
       "2         362  \n",
       "3         233  \n",
       "4         283  \n",
       "..        ...  \n",
       "95          3  \n",
       "96         26  \n",
       "97          5  \n",
       "98         49  \n",
       "99         39  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to clean the text in the following way before vectorizing and embedding:\n",
    "\n",
    "**Lowercase all text.** We don't want multiple different versions of the same word diluting its embedding. *Note: Should we worry about losing a potential sentence boundary indicator?*\n",
    "\n",
    "**Spellcheck words.** This one's self-explanatory. *Note: may need to revisit when we spellcheck, see gibberish detection later* \n",
    "\n",
    "**Expand contractions into full word pairs.** Theoretically, pretrained embedding models may be able to learn context for contractions like any other word, but it should also be able to learn the word pair meanings in similar ways. To avoid redundancy and to make regex-based tokenizing easier later, we should expand these out. Contraction dict taken from https://www.analyticsvidhya.com/blog/2020/08/information-retrieval-using-word2vec-based-vector-space-model/\n",
    "\n",
    "**Get rid of links.** We are dealing with reviews where people may be trying to link to other products, etc. These are hyperspecific and thus are not going to be useful for embeddings.\n",
    "\n",
    "**Get rid of weird characters. Add spaces before and after kept punctuation** This one is a bit tough. We don't want to get rid of all punctuation, as if we tokenize some punctuation it can add depth to our embeddings (a period marking the end of a sentence, an exclamation adding emphasis, etc.). However, we want to make sure especially odd symbols, such as those that might appear from faulty encodings, is removed. We don't simply want to do this with our tokenizer, in case odd encodings occur in the middle of words (which might break them up into gibberish). We also want to tokenize punctuation independently from the attached words, to avoid standardization issues, so we need to separate them. We were fairly liberal with the punctuation we kept. \n",
    "\n",
    "*Note: Should we get rid of numbers?*\n",
    "\n",
    "*Note: How should we handle underscores?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spellchecking using the autocorrect package.\n",
    "\n",
    "#check = Speller(lang = 'en')\n",
    "\n",
    "#def fixSentence(sentence):\n",
    "    #return check(sentence)\n",
    "\n",
    "#Create a dictionary of english contractions and their expanded forms.\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\"can't\": \"can not\",\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\"i'll\": \"i will\",\"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\n",
    "\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\n",
    "\"there'd\": \"there would\",\"there'd've\": \"there would have\",\n",
    "\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\n",
    "\"what've\": \"what have\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
    "\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contraction(text, contractions_dict = contractions_dict):\n",
    "    \n",
    "    #for anything that matches the re we defined earlier for the contraction keys, replace with the value\n",
    "    \n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    \n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # make sure the text is of type str if not for some weird reason, then set to lowercase. \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    #Spell check\n",
    "    #text = fixSentence(text)\n",
    "    \n",
    "    #Expand contractions\n",
    "    text = expand_contraction(text)\n",
    "    \n",
    "    #Remove links. If any text starts with either http://, https://, or www., replace it with a space\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    #Clear newline chars\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    \n",
    "    #Add spaces before and after certain punctuation so we can tokenize it. \n",
    "    #We thought about using the + chararcter after everything, but embeddings for sequences like ?! are probably better off split up\n",
    "    #We only included it for periods so we can capture elipses, which have distinct meanings from periods.\n",
    "    text = re.sub(r\"[.]+|[,;!?]\",\" \\g<0> \", text)\n",
    "    \n",
    "    #change & to and\n",
    "    text = re.sub(r\"[&]\",\" and \", text)\n",
    "    \n",
    "    #change _ to a space\n",
    "    text = re.sub(r\"[_]\",\" \", text)\n",
    "    \n",
    "    #get rid of any character not in this list\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,;!?\\s/]\",\"\", text)\n",
    "    \n",
    "    #When it comes time to vectorize, we'll exclude unwanted symbols by using a regexpTokenizer and whitelisting approved punctuation\n",
    "    #token = RegexpTokenizer(r\"[a-zA-Z0-9.,;!?]+\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_clean = el.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-417245265e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mel_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-417245265e7a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mel_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-90a20f28b7d1>\u001b[0m in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m#Expand contractions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_contraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#Remove links. If any text starts with either http://, https://, or www., replace it with a space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-90a20f28b7d1>\u001b[0m in \u001b[0;36mexpand_contraction\u001b[1;34m(text, contractions_dict)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontractions_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontractions_re\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-90a20f28b7d1>\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(match)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontractions_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontractions_re\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "el_bin['reviewText'] = el_bin['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "el_clean2 = el.copy()\n",
    "el_clean2['reviewText'] = el_clean2['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_clean['reviewText'] = el_clean['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#via dask\n",
    "el_clean_dd = dd.from_pandas(elec, npartitions = 52)\n",
    "el_clean_dd['reviewText'] = el_clean_dd['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_clean.to_csv(\"el_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Groupings\n",
    "\n",
    "The relationship between sentiment and star ratings is a tricky thing. While a 5-star scale is more granular than a binary positive/negative rating, it can also be difficult to understand exactly what each value means. For instance, users may have different \"scales\" that can even change by the day. At the end of the day, this ground truth label is better than a lot of ground truths used in natural language processing, but still gives us some things to consider:\n",
    "\n",
    "**Scaling ratings by other user ratings** Our data has exactly 5 reviews for each user and exactly 5 reviews for each product. Theoretically, we could scale our star ratings by the mean and variance of that user's other ratings. For instance, we might want to value a 5 more highly if all the user's other reviews are 1s and 2s than if they were 4s and 5s. However, we would need to weight this scale to also retain the general magnitude of the original rating. For instance, by simply mean-centering and normalizing by std, a 1 from a user with all 1s would equal a 5 from a user with all 5s, which is definitely not what we want. Yet, deciding on a weight parameter is tricky. We could construct a similarity matrix with neighboring users, but since we only have 5 reviews for each item and user, our matrix is incredibly sparse and likely won't be of that much use. Furthermore, the fact that we only have 5 reviews for each user generally might make the mean and variance of their ratings too finicky to be usable. Because of this, we opted not to scale ratings in such a manner.\n",
    "\n",
    "**Grouping ratings** Another option is to \"smooth\" our data by grouping ratings. For instance, we may group 4 and 5 as positive, 3 as neutral, and 2 as negative. Or if we want to detect neutrality, perhaps 1 and 5 as non-neutral and 3 as neutral. This loses some of the granularity provided by our 5-class targets, but might smooth some of the individual differences a bit. Let's make extra target columns with these schemes, and we can hopefully test models on all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the best novel i have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>pages and pages of introspective   ,    in the...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>what gorgeous language   !    what an incredib...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>i was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall vote  verified   reviewTime      reviewerID  \\\n",
       "0           0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM   \n",
       "1           1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV   \n",
       "2           2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3   \n",
       "3           3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5   \n",
       "4           4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE   \n",
       "\n",
       "         asin                                         reviewText  \\\n",
       "0  0151004714  this is the best novel i have read in 2 or 3 y...   \n",
       "1  0151004714  pages and pages of introspective   ,    in the...   \n",
       "2  0151004714  this is the kind of novel to read when you hav...   \n",
       "3  0151004714  what gorgeous language   !    what an incredib...   \n",
       "4  0151004714  i was taken in by reviews that compared this b...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     A star is born       937612800   \n",
       "1                    A stream of consciousness novel      1382486400   \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3          The most beautiful book I have ever read!       968025600   \n",
       "4                        A dissenting view--In part.       949622400   \n",
       "\n",
       "   num_words   pos_neg  \n",
       "0        197  positive  \n",
       "1         81   neutral  \n",
       "2        362  positive  \n",
       "3        233  positive  \n",
       "4        283   neutral  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_clean['pos_neg'] = el_clean['overall'].apply(lambda x: 'positive' if x >3 else ('neutral' if x == 3 else 'negative'))\n",
    "el_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>pos_neg</th>\n",
       "      <th>neutrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the best novel i have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "      <td>positive</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>pages and pages of introspective   ,    in the...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>this is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "      <td>positive</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>what gorgeous language   !    what an incredib...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "      <td>positive</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>i was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall vote  verified   reviewTime      reviewerID  \\\n",
       "0           0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM   \n",
       "1           1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV   \n",
       "2           2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3   \n",
       "3           3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5   \n",
       "4           4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE   \n",
       "\n",
       "         asin                                         reviewText  \\\n",
       "0  0151004714  this is the best novel i have read in 2 or 3 y...   \n",
       "1  0151004714  pages and pages of introspective   ,    in the...   \n",
       "2  0151004714  this is the kind of novel to read when you hav...   \n",
       "3  0151004714  what gorgeous language   !    what an incredib...   \n",
       "4  0151004714  i was taken in by reviews that compared this b...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     A star is born       937612800   \n",
       "1                    A stream of consciousness novel      1382486400   \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3          The most beautiful book I have ever read!       968025600   \n",
       "4                        A dissenting view--In part.       949622400   \n",
       "\n",
       "   num_words   pos_neg neutrality  \n",
       "0        197  positive    extreme  \n",
       "1         81   neutral    neutral  \n",
       "2        362  positive    extreme  \n",
       "3        233  positive    extreme  \n",
       "4        283   neutral    neutral  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_clean['neutrality'] = el_clean['overall'].apply(lambda x: 'extreme' if x == 1 or x == 5 else ('neutral' if x == 3 else 'non_neutral'))\n",
    "el_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue that affects the meaning of our star ratings is \"malicious\" raters, such as bots and trolls.\n",
    "\n",
    "Let's get a basic idea of how long each review is. We may be able to see if review length correlates with overall rating, which could tell us something about our review quality. For instance, people who leave one word reviews could be bots or people who simply don't care, and might disproportionately answer a certain way (like \"5\" stars, in the case of a bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 5, 2013</td>\n",
       "      <td>A3IYSOTP3HA77N</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>I read this probably 50 years ago in my youth ...</td>\n",
       "      <td>Above average mystery</td>\n",
       "      <td>1370390400</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 27, 2016</td>\n",
       "      <td>A11SXV34PZUQ5E</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>I read every Perry mason book voraciously. Fin...</td>\n",
       "      <td>Lam is cool!</td>\n",
       "      <td>1466985600</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 30, 2015</td>\n",
       "      <td>A2AUQM1HT2D5T8</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>I love this series of Bertha and Lamb..  Great...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1438214400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 16, 2015</td>\n",
       "      <td>A3UD8JRWLX6SRX</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>Great read!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1424044800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11 21, 2013</td>\n",
       "      <td>A3MV1KKHX51FYT</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>Crows Can't Count, A.A. Fair\\n\\nMr. Harry Shar...</td>\n",
       "      <td>A Fast and Far Moving Adventure</td>\n",
       "      <td>1384992000</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n",
       "1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n",
       "2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n",
       "3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n",
       "4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n",
       "5      4.0  NaN      True   06 5, 2013  A3IYSOTP3HA77N  0380709473   \n",
       "6      5.0  NaN      True  06 27, 2016  A11SXV34PZUQ5E  0380709473   \n",
       "7      5.0  NaN      True  07 30, 2015  A2AUQM1HT2D5T8  0380709473   \n",
       "8      5.0  NaN      True  02 16, 2015  A3UD8JRWLX6SRX  0380709473   \n",
       "9      4.0  NaN     False  11 21, 2013  A3MV1KKHX51FYT  0380709473   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is the best novel I have read in 2 or 3 y...   \n",
       "1  Pages and pages of introspection, in the style...   \n",
       "2  This is the kind of novel to read when you hav...   \n",
       "3  What gorgeous language! What an incredible wri...   \n",
       "4  I was taken in by reviews that compared this b...   \n",
       "5  I read this probably 50 years ago in my youth ...   \n",
       "6  I read every Perry mason book voraciously. Fin...   \n",
       "7  I love this series of Bertha and Lamb..  Great...   \n",
       "8                                        Great read!   \n",
       "9  Crows Can't Count, A.A. Fair\\n\\nMr. Harry Shar...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     A star is born       937612800   \n",
       "1                    A stream of consciousness novel      1382486400   \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3          The most beautiful book I have ever read!       968025600   \n",
       "4                        A dissenting view--In part.       949622400   \n",
       "5                              Above average mystery      1370390400   \n",
       "6                                       Lam is cool!      1466985600   \n",
       "7                                         Five Stars      1438214400   \n",
       "8                                         Five Stars      1424044800   \n",
       "9                    A Fast and Far Moving Adventure      1384992000   \n",
       "\n",
       "   num_words  \n",
       "0        197  \n",
       "1         81  \n",
       "2        362  \n",
       "3        233  \n",
       "4        283  \n",
       "5         34  \n",
       "6         31  \n",
       "7         11  \n",
       "8          2  \n",
       "9        442  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "el['num_words'] = el['reviewText'].apply(lambda x: len(x.split(' ')))\n",
    "el.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.738237e+06\n",
       "mean     6.566639e+01\n",
       "std      1.169420e+02\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      2.900000e+01\n",
       "75%      7.300000e+01\n",
       "max      6.468000e+03\n",
       "Name: num_words, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el['num_words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num_words'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(el['num_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a heavy right skew, which makes sense- not everybody want to write a novel for a review, but there are those that do. Let's limit our scope to focus more on the lower end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num_words', ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEJCAYAAABPKPr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt2klEQVR4nO3de7xWZZn/8c/FwWNhqEAEFk5SM2aGyZCdrMkGyCw8YOFMSWVDmZZNzUw5M7/RdOg39nOyPFEaeCBTCVHMNCXN03hAMFIRGVFQTsLWjQpykA3X74/rWvtZ4Ga7JZ71wOb7fr2e117PvdZ9r3utda91rcO912PujoiISBW6NLoCIiKy81DQERGRyijoiIhIZRR0RESkMgo6IiJSGQUdERGpTN2CjpntZmbTzexPZjbbzH6Q6Wea2WIzm5WfI0t5TjezeWY218yGldIPNbNHc9z5ZmaZvquZXZvpD5rZgFKe0Wb2ZH5G12s5RUSk46xe/6eTgWFPd19lZt2Be4HTgOHAKnc/d7PpDwSuBoYAbwN+D7zL3TeY2fTM+wBwM3C+u99iZt8ADnb3r5vZKOAYd/+8me0NzAAGAw7MBA519xVbqu++++7rAwYM2JarQESk05s5c+bz7t6ro9N3q1dFPKLZqvzaPT/tRbgRwDXuvg6Yb2bzgCFmtgDo4e73A5jZlcDRwC2Z58zMPxm4MIPdMGCauzdnnmlEsLt6SzMfMGAAM2bMeOMLKiKyEzOzZ97I9HV9pmNmXc1sFrCcCAIP5qhTzewRM5tgZj0zrR+wsJR9Uab1y+HN0zfJ4+4twEvAPu2UJSIiDVTXoOPuG9x9ENCfuGo5CBgHvBMYBCwF/jsnt7aKaCd9a/O0MrMxZjbDzGY0NTW1syQiIrItVNJ7zd1fBO4Ehrv7sgxGG4FLiWc4EFcj+5Wy9QeWZHr/NtI3yWNm3YC9gOZ2ytq8Xpe4+2B3H9yrV4dvSYqIyFaqZ++1Xmb2lhzeHfgk8ISZ9S1NdgzwWA7fCIzKHmn7AwOB6e6+FFhpZofl85oTgamlPEXPtJHAHfks6VZgqJn1zNt3QzNNREQaqG4dCYC+wBVm1pUIbpPc/SYzm2hmg4jbXQuArwG4+2wzmwQ8DrQAp7j7hizrZOByYHeiA8EtmT4emJidDpqBUVlWs5mdDTyU051VdCoQEZHGqVuX6R3N4MGDXb3XRETeGDOb6e6DOzq93kggIiKVUdAREZHKKOiIiEhl6tmRYIfWNO6y1uFeJ3+5gTUREek8dKUjIiKVUdAREZHKKOiIiEhlFHRERKQyCjoiIlIZBR0REamMgo6IiFRGQUdERCqjoCMiIpVR0BERkcoo6IiISGUUdEREpDIKOiIiUhkFHRERqYyCjoiIVEZBR0REKqOgIyIilVHQERGRytQt6JjZbmY23cz+ZGazzewHmb63mU0zsyfzb89SntPNbJ6ZzTWzYaX0Q83s0Rx3vplZpu9qZtdm+oNmNqCUZ3TO40kzG12v5RQRkY6r55XOOuAT7v4+YBAw3MwOA74P3O7uA4Hb8ztmdiAwCngPMBy42My6ZlnjgDHAwPwMz/STgBXufgBwHnBOlrU3cAbwAWAIcEY5uImISGPULeh4WJVfu+fHgRHAFZl+BXB0Do8ArnH3de4+H5gHDDGzvkAPd7/f3R24crM8RVmTgSPyKmgYMM3dm919BTCNWqASEZEGqeszHTPramazgOVEEHgQ6OPuSwHyb++cvB+wsJR9Uab1y+HN0zfJ4+4twEvAPu2UtXn9xpjZDDOb0dTU9GcsqYiIdERdg467b3D3QUB/4qrloHYmt7aKaCd9a/OU63eJuw9298G9evVqp2oiIrItVNJ7zd1fBO4kbnEty1tm5N/lOdkiYL9Stv7Akkzv30b6JnnMrBuwF9DcTlkiItJA9ey91svM3pLDuwOfBJ4AbgSK3mSjgak5fCMwKnuk7U90GJiet+BWmtlh+bzmxM3yFGWNBO7I5z63AkPNrGd2IBiaaSIi0kDd6lh2X+CK7IHWBZjk7jeZ2f3AJDM7CXgWOB7A3Web2STgcaAFOMXdN2RZJwOXA7sDt+QHYDww0czmEVc4o7KsZjM7G3gopzvL3ZvruKwiItIBdQs67v4IcEgb6S8AR2whz1hgbBvpM4DXPA9y97Vk0Gpj3ARgwhurtYiI1JPeSCAiIpVR0BERkcoo6IiISGUUdEREpDIKOiIiUhkFHRERqYyCjoiIVEZBR0REKqOgIyIilVHQERGRyijoiIhIZRR0RESkMgo6IiJSGQUdERGpjIKOiIhURkFHREQqo6AjIiKVUdAREZHKKOiIiEhlFHRERKQyCjoiIlIZBR0REalM3YKOme1nZn8wszlmNtvMTsv0M81ssZnNys+RpTynm9k8M5trZsNK6Yea2aM57nwzs0zf1cyuzfQHzWxAKc9oM3syP6PrtZwiItJx3epYdgvwXXd/2MzeDMw0s2k57jx3P7c8sZkdCIwC3gO8Dfi9mb3L3TcA44AxwAPAzcBw4BbgJGCFux9gZqOAc4DPm9newBnAYMBz3je6+4o6Lq+IiLyOul3puPtSd384h1cCc4B+7WQZAVzj7uvcfT4wDxhiZn2BHu5+v7s7cCVwdCnPFTk8GTgir4KGAdPcvTkDzTQiUImISANV8kwnb3sdAjyYSaea2SNmNsHMemZaP2BhKduiTOuXw5unb5LH3VuAl4B92ilr83qNMbMZZjajqalp6xdQREQ6pO5Bx8zeBFwHfNvdXyZulb0TGAQsBf67mLSN7N5O+tbmqSW4X+Lug919cK9evdpbDBER2QbqGnTMrDsRcK5y9ykA7r7M3Te4+0bgUmBITr4I2K+UvT+wJNP7t5G+SR4z6wbsBTS3U5aIiDRQPXuvGTAemOPuPy6l9y1NdgzwWA7fCIzKHmn7AwOB6e6+FFhpZodlmScCU0t5ip5pI4E78rnPrcBQM+uZt++GZpqIiDRQPXuvfRj4IvComc3KtH8FTjCzQcTtrgXA1wDcfbaZTQIeJ3q+nZI91wBOBi4Hdid6rd2S6eOBiWY2j7jCGZVlNZvZ2cBDOd1Z7t5cl6UUEZEOq1vQcfd7afvZys3t5BkLjG0jfQZwUBvpa4Hjt1DWBGBCR+srIiL1pzcSiIhIZRR0RESkMgo6IiJSGQUdERGpjIKOiIhURkFHREQqo6AjIiKVUdAREZHKKOiIiEhlFHRERKQyCjoiIlIZBR0REamMgk5J07hf0jTul42uhohIp6WgIyIilVHQERGRyijoiIhIZRR0RESkMgo6IiJSGQUdERGpjIKOiIhURkFHREQqU7egY2b7mdkfzGyOmc02s9MyfW8zm2ZmT+bfnqU8p5vZPDOba2bDSumHmtmjOe58M7NM39XMrs30B81sQCnP6JzHk2Y2ul7LKSIiHVfPK50W4Lvu/lfAYcApZnYg8H3gdncfCNye38lxo4D3AMOBi82sa5Y1DhgDDMzP8Ew/CVjh7gcA5wHnZFl7A2cAHwCGAGeUg5uIiDRG3YKOuy9194dzeCUwB+gHjACuyMmuAI7O4RHANe6+zt3nA/OAIWbWF+jh7ve7uwNXbpanKGsycEReBQ0Dprl7s7uvAKZRC1QiItIglTzTydtehwAPAn3cfSlEYAJ652T9gIWlbIsyrV8Ob56+SR53bwFeAvZppywREWmgugcdM3sTcB3wbXd/ub1J20jzdtK3Nk+5bmPMbIaZzWhqamqnaiIisi3UNeiYWXci4Fzl7lMyeVneMiP/Ls/0RcB+pez9gSWZ3r+N9E3ymFk3YC+guZ2yNuHul7j7YHcf3KtXr61dTBER6aB69l4zYDwwx91/XBp1I1D0JhsNTC2lj8oeafsTHQam5y24lWZ2WJZ54mZ5irJGAnfkc59bgaFm1jM7EAzNNBERaaBuHZnIzG539yNeL20zHwa+CDxqZrMy7V+B/wImmdlJwLPA8QDuPtvMJgGPEz3fTnH3DZnvZOByYHfglvxABLWJZjaPuMIZlWU1m9nZwEM53Vnu3tyRZRURkfppN+iY2W7AHsC+ecVQPCvpAbytvbzufi9tP1sBaDNYuftYYGwb6TOAg9pIX0sGrTbGTQAmtFdHERGp1utd6XwN+DYRYGZSCyIvAxfVr1oiItIZtRt03P2nwE/N7JvufkFFdRIRkU6qQ8903P0CM/sQMKCcx92vrFO9RESkE+poR4KJwDuBWUDxcL94O4CIiEiHdCjoAIOBA7M7soiIyFbp6P/pPAa8tZ4VERGRzq+jVzr7Ao+b2XRgXZHo7p+tS61ERKRT6mjQObOeldjRLP/Zha3Dvb9+agNrIiKyY+lo77W76l0RERHp/Drae20ltbc07wJ0B15x9x71qpiIiHQ+Hb3SeXP5u5kdTfwip4iISIdt1Vum3f0G4BPbtioiItLZdfT22rGlr12I/9vR/+yIiMgb0tHea58pDbcAC4AR27w2IiLSqXX0mc6X612R7V3Tzy4BoNfXx2ySvmzcua3DfU7+p0rrJCKyo+nQMx0z629m15vZcjNbZmbXmVn/188pIiJS09GOBJcRPw39NqAf8JtMExER6bCOBp1e7n6Zu7fk53KgVx3rJSIinVBHg87zZvYFM+uany8AL9SzYiIi0vl0NOh8Bfgc8BywFBgJ7PSdC0RE5I3paJfps4HR7r4CwMz2Bs4lgpGIiEiHdPRK5+Ai4AC4ezNwSH2qtGN7btzZPDfu7EZXQ0Rku9TRoNPFzHoWX/JKp92rJDObkF2sHyulnWlmi81sVn6OLI073czmmdlcMxtWSj/UzB7NceebmWX6rmZ2baY/aGYDSnlGm9mT+RndwWUUEZE662jQ+W/gPjM728zOAu4DfvQ6eS4HhreRfp67D8rPzQBmdiAwCnhP5rnYzLrm9OOAMcDA/BRlngSscPcDgPOAc7KsvYEzgA8QLyU9oxwwRUSkcToUdNz9SuA4YBnQBBzr7hNfJ8/dQHMH6zECuMbd17n7fGAeMMTM+gI93P1+d3fgSuDoUp4rcngycEReBQ0Dprl7c94SnEbbwU9ERCrW0Y4EuPvjwOPbYJ6nmtmJwAzguxkY+gEPlKZZlGnrc3jzdPLvwqxbi5m9BOxTTm8jj4iINNBW/bTBn2Ec8E5gENH1+r8z3dqY1ttJ39o8mzCzMWY2w8xmNDU1tVNtERHZFioNOu6+zN03uPtG4FJqPwS3CNivNGl/YEmm928jfZM8ZtYN2Iu4nbelstqqzyXuPtjdB/fqpRcsiIjUW6VBJ5/RFI4Bip5tNwKjskfa/kSHgenuvhRYaWaH5fOaE4GppTxFz7SRwB353OdWYKiZ9cwOBEMzTUREGqzDz3TeKDO7Gvg4sK+ZLSJ6lH3czAYRt7sWAF8DcPfZZjaJeGbUApzi7huyqJOJnnC7A7fkB2A8MNHM5hFXOKOyrGYzOxt4KKc7K/+vSEREGqxuQcfdT2gjeXw7048FxraRPgM4qI30tcDxWyhrAjChw5UVEZFKVN2RQEREdmJ1u9IRWHrx6a3Dfb/xfxtYExGR7YOudEREpDIKOiIiUhkFHRERqYyCjoiIVEZBR0REKqOgIyIilVHQERGRyijoiIhIZfTPoRVZfNGprcP9TrmwgTUREWkcXemIiEhlFHRERKQyCjoiIlIZBR0REamMOhI0yMIL/q51eL9v/qqBNRERqY6udEREpDIKOiIiUhkFHRERqYye6UirGyZ8qnX46K/c0sCaiEhnpaAjbZp82fDW4ZFf/l0DayIinYmCznbgqQtGtA6/85tTG1gTEZH6qtszHTObYGbLzeyxUtreZjbNzJ7Mvz1L4043s3lmNtfMhpXSDzWzR3Pc+WZmmb6rmV2b6Q+a2YBSntE5jyfNbHS9llFERN6YenYkuBwYvlna94Hb3X0gcHt+x8wOBEYB78k8F5tZ18wzDhgDDMxPUeZJwAp3PwA4Dzgny9obOAP4ADAEOKMc3GTrXHP5sNaPiMjWqlvQcfe7gebNkkcAV+TwFcDRpfRr3H2du88H5gFDzKwv0MPd73d3B67cLE9R1mTgiLwKGgZMc/dmd18BTOO1wU9ERBqg6i7Tfdx9KUD+7Z3p/YCFpekWZVq/HN48fZM87t4CvATs005Zr2FmY8xshpnNaGpq+jMWa9uac9EI5lw04vUnFBHZwWwv/6djbaR5O+lbm2fTRPdL3H2wuw/u1atXhyoqIiJbr+rea8vMrK+7L81bZ8szfRGwX2m6/sCSTO/fRno5zyIz6wbsRdzOWwR8fLM8d27bxdi5TSw91/nil25tYE1EZEdT9ZXOjUDRm2w0MLWUPip7pO1PdBiYnrfgVprZYfm85sTN8hRljQTuyOc+twJDzaxndiAYmmk7pEfGfbb1IyKyo6vblY6ZXU1ccexrZouIHmX/BUwys5OAZ4HjAdx9tplNAh4HWoBT3H1DFnUy0RNud+CW/ACMByaa2TziCmdUltVsZmcDD+V0Z7n75h0aRESkAeoWdNz9hC2MOmIL048FxraRPgM4qI30tWTQamPcBGBChysrIiKV2F46EsgO7LIrhnLZFUMbXQ0R2QHoNTg7kJk/+0zr8KFf/00DayIisnV0pSMiIpXRlY5sU7+4stad+qsn7rCdBkWkTnSlswN74OdH8cDPj2p0NUREOkxXOp3EvZfWgs9H/uGmBtZERGTLFHSkbn42sXar7etf1K02EdHtNRERqZCCTid156Wf5s5LP93oamziwquGceFV+j0ekZ2Zgo6IiFRGz3R2Ar//xZGtw5/86s0NrImI7OwUdHYyt4yvBaBPndS4AHTer2q32f7x79TJQGRnoaCzk7tpwqcAOOort7zOlPXzo6trAehfTlAAEunM9ExHREQqoysd2e6MvbZ25fNvn9eVj0hnoisdERGpjK50ZLv2H5OGtw6f9bnfNbAmIrIt6EpHREQqo6AjO5TvTR7O9yYPf/0JRWS7pNtrssP65nW14HPBcbr1JrIjUNCRTuHL19cC0GXHKACJbK90e006pRFThzNiqm7DiWxvGhJ0zGyBmT1qZrPMbEam7W1m08zsyfzbszT96WY2z8zmmtmwUvqhWc48MzvfzCzTdzWzazP9QTMbUPlCynbjU1P/rvUjIo3VyCudv3H3Qe4+OL9/H7jd3QcCt+d3zOxAYBTwHmA4cLGZdc0844AxwMD8FKe2JwEr3P0A4DzgnAqWR3YQn5r6dT419euNrobITml7ur02Argih68Aji6lX+Pu69x9PjAPGGJmfYEe7n6/uztw5WZ5irImA0cUV0EiItI4jepI4MBtZubAz939EqCPuy8FcPelZtY7p+0HPFDKuyjT1ufw5ulFnoVZVouZvQTsAzxfroSZjSGulHj729++7ZZOdhhH3vCd0rfdWoduPvqH1VdGZCfQqKDzYXdfkoFlmpk90c60bV2heDvp7eXZNCGC3SUAgwcPfs142bkdef2ZANx8zJkNrYdIZ9KQoOPuS/LvcjO7HhgCLDOzvnmV0xdYnpMvAvYrZe8PLMn0/m2kl/MsMrNuwF5Ac72WRzq/I6+vXfncfMy/NrAmIju2yp/pmNmeZvbmYhgYCjwG3AiMzslGA1Nz+EZgVPZI25/oMDA9b8WtNLPD8nnNiZvlKcoaCdyRz31E/myfvv5HrR8ReWMacaXTB7g+n+t3A37l7r8zs4eASWZ2EvAscDyAu882s0nA40ALcIq7b8iyTgYuB3YHbskPwHhgopnNI65wRlWxYLJz+vSUH5e+1Xap3x77reorI7KdqzzouPvTwPvaSH8BOGILecYCY9tInwEc1Eb6WjJoiTTSp6dcDMBvj/1Gg2sisn3Qa3BEKvLp635e+ta1dei3x321+sqINIiCjsh24KjrLgPgpuO+zFHXXdGaftNxo7eURWSHpKAjsh07avIvW4dvGvmFBtZEZNtQ0BHZgRw1+Velb7VbdDeN/Hz1lRHZCgo6Ip3EUb/+NQA3HX88n5k8pTX9NyOPbVSVRF5DQUekk/vs5KmtwzeOHMFnJ9+Uw0c1qkqyE1PQEdmJjZhc+8G7qSOHc/TkaQDcMPJvOfq6O1rH3XDcJyqvm3ROCjoi8rqOue7u1uHrjzucY6+7D4Apx32oUVWSHZSCjoj8WY67bnrrsNG9dXjycYdw/HWPtX7/9XGv+T9u2Qkp6IhIJT533f+2Dk867l2cMOUZAK4+9h186/qFrePOP2a/1+SVzkNBR0S2K/9+/eLW4f88ph//df1SAL5/TF/Ov35Z67hvHdOn8rrJn09BR0R2WJdOiV9A+YdjezNxSlNr+q5e+0mtzx23Lzf8On6/8ejj9622gvIaCjoislO5+draDwh331j7xZO/PaEXd15VC1zdN9TyfPjEXpXUbWegoCMi0gEPXh5XVR/4Um8eHr+8Nb0cnN47pjdPXBy3AP/yG7r91xYFHRGROnnq/Odah7u31NLf/p23svScJa3frcv61uG3/vM7eO7cJ2P4nwbWv5IVU9AREdmOPffjOa3DZrXg1OcfD2bZTx6O4W+/n2U/qXVd7/PtISz7afwvVZ/TPsSy82v/Z9XnW4fXu8rtUtAREdmJLL+g9qaJ3t/8BMsvuC2Hh7L8wptrE1rt0qz3KZ9l+UVT2hz3RnXZ6pwiIiJvkIKOiIhURkFHREQqo6AjIiKVUdAREZHKdOqgY2bDzWyumc0zs+83uj4iIju7Tht0zKwrcBHwKeBA4AQzO7CxtRIR2bl12qADDAHmufvT7v4qcA0wosF1EhHZqZm7v/5UOyAzGwkMd/ev5vcvAh9w91NL04wBxuTXdwNzgX2B50tFlb9vaXhbTLejzUv17Tzz2tHqq3WzfdV3T3fv+BtR3b1TfoDjgV+Uvn8RuKAD+WZs6fuWhrfFdDvavFTfzjOvHa2+WjfbZ307+unMt9cWAeWfIOwPLNnCtCIiUoHOHHQeAgaa2f5mtgswCrixwXUSEdmpddoXfrp7i5mdCtwKdAUmuPvsDmS9pJ3vWxreFtPtaPPaFmWovtvHvLZFGZ11XtuijJ2lvh3SaTsSiIjI9qcz314TEZHtjIKOiIhUptM+03mjzGwCcBSwnHiLwZXAWwEH9gReJNbXZHc/I994MIP4/56ngA1AC/BJ4BfA+4G3Ac8Cq4G/BFYALwC7A72B7pl3JfDOTN+Qf5fnfN+S816WeXrkfF4B3gTMd/e/NLPpwF/nuJdzusXA0kw3on99tyzTgDlED7+VwN7EScirmadL1r9LTrsLsADYK+e7MdNfBPbI4WU5331zWd+cy+PAo8BBwK75vSXLduC5zNM1N0fXXGfLs36W060slb1n5l8NrM96teT8fgEcm3lbMu+GLO8J4PBcHs/lIIebch29O8t8BnhHrpMVOa935zJ8APhN1uPpLK+Y9kGgb+a/C/gRsC7nDdCP2MbPENt9HTCf2L59cnnXZn32ybLXZd43AauyPv1z2hVZXtdcHs86vpLzWAv8BdAz10fXLG9J1nkD0S6KvJbrdl3mXUu0mWJdFfN8U853F2Jf+ItMW5zbqdjWr+T0G3Le78x6PJPTOdGG1hP7hOfwbjn9q6V67Zr1eTq3BTltl6xHU+bZm1p76J5/1xJt7YAsaznQqzRdsZwtuay7ZNmW6+elrBPU2vASYlvvmnleJdr9y7luNmYZ63LdWH6/Pcv8dJZTLMNzRBt8O7HtPcvsVlovXbOc5qzLm/N74aUsq08O75HLZllW91y2DUTbfD/xj/PFcWXXXDcrgL/Kea/Osvrk/Jfm5zzg1Fy2BcDfu/vLtENXOjWXA8NzuAX4rrv/FXFweRU4ARgEDDezw4DTiIM2wN+4+yB3Hwz8FPidu/8FcQAeAnyG2HAfc/eDiEa1mgg478tx9xAHk88APyMayqnATGANccA+GriWOPgek/PqbWZF1/BVREM8JuvtRAP7cNb1vTluGbFTfBL4N6LRfoVo8P+VZfQk/rfpIuAGotH+C/AdorG9H7iUaLxfAv4VeIRofEuByVmf9wPHZf2/7O5dgQ9lHa4iurZ3BT5GBOg5wCzgglxPTTluXC7Pn4D/QwSZWUSPxKty+G+Afwe+kMvyEjA28/wNcBJwGDAi6/H2HDcZWJj1vYvYsR24LNNw94HETrgo188oYDZwl7sfnMszP7fjK8TBabec53rgGXcfBNxH7Ox3A+OB3wL35Ljdch2sze3RkzgoLSEC2XTiQH0ecFum35fr4835/TLg/Cznh8C9uc13z21+do7bD/hq1m3/XB/9soylwK+AXwMTc5veA5yefx/M+j9InJwtA+4k9pG3AA/kuJ9kGX8Afg88lvN7Kes2nWhDM3MbnJ71+jXRnhYDVxMnfwuJtrEM+I8sYw0RwC7Oeq7P9fb3Od0BxL60BhhItI3pOd3irPuqHHdk1qPI944cHpjTrs31txCYl9vwOmJf3I3YVy8mTsJagDMz7wbgf4Drc/ibxD53KDA0l+MnRHD6JvDlnLflen9/jrsz62PEsedZ4viyimgDRSepS4HfEe1/LfADos13zfV6Sw4PyfXxTeBvsx6XEseiIcBZxD77QSIIPUEcs5YQbWNOrttxwPfd/b25jP/M61DQSe5+N3nm4O5L3f3hHF4JPE7skN3zsy9xMPhFuQwz60GcRY/PvK+6+4vAR4gG97yZdSM27JyYxFuAqZnvxazHROK/fK8iGvBqd2/JcXcB3XPY83Me8A85XF6WvYHvE40Vd19OHDT2Bta4+1LiwL478ZqgWcSB8xCiy/nLwLlEsH0F6OXul+d0/YiztVU53Z7AwcQBpwux8y3O6b4E/LG0fqdnGcUBdSlxgO0P/C+xUzxI7HArcrkuIHayDTmuS073KLWzL89p3kwEZDK9GHcycQb3Uo57MccdketodyIg7kLsYJ/O6XYzs/457a45748A/wl4juuZy7IbEdyLIP8ScdJCTndcrtNdsvyLSuP2IoIQuRy7Ewd3iINrcXJxLfBRom0APJjtCOD+XI8QJy5F+yjOistOLtcv2wfE2f+jRJt8IOvxLuDC/Pt24mD0JeDjWe9r3f02Yv/4IHEAHpDraSbR5ocTwZr8/kHiAHs+sd4vJA6UH8nhPsD03If6E23hKaKtDgbmuPszuT6HEcHlOeIg/VSOe5Fo688QbfQTxP7ckvN+IcedDEwr5Ts45/UscSWznDjg9yOCTlfiYP/enF9zrud9c/keyb9dc7hXDjcT7XMfYt8priqLcd/IeXqu9xdz3CHEPriGuKLoT+y7LxJBcj8iMKzK9Tc3l/HeHP9ErvMBOfypLH834qqRrFMx7qRM/2S2radyXr2JY8NdxIlcuY1OI9p3+97of5N25k9ukMfaSHs2G84q4BzirOxQYodbDTxM7FhnEWdSlxMH2V8QDX0CtTP/JuK2zNPEgWkP4kCxrph3znNDDj9AvEOuqM/vqZ1xzc2/P81xLxMHkEeASdTOdP5INNi/Jg4kc3O6hURgmEkErWeJs03P4R5Z7ktZ1sdK66NH1mU1cfb/DHEG9GwO/4xo9I8RB4uXiVswdwGfJQ7yDxMH/JYsY2PO50dZL8/hWbnu1hJnfHPz+49Kdbsvl2ljTt+VCFAbiQPGC/n9XiJorcq6/yr/vkKcAT+X5byY23hd1q/Y5isz7QvE9r8px92dZW8gDkpjs8xDc15rsswXc56v5nr/WpZxZ+ZbRu02zStEUJqfaRuIA83DWafnsz5ziNc5zS/NY0POcz5xcjA/87xayrumtOwrs85LMn09tdsta3I9/5La7aIZRDsvyryZaGdTctzCLHMDsf2X5Lx+mXlW52dtbpv1uewLcnvdlvNdRbSNdbl+TyWuth04tbRfrAOeJILRhGIctX13IdEun8gyFmT6C5v9XUC00RtzusOz/s3UToBW5jKuy+8zqO3bRT1W5/cZ1G55Ly1txyeJK5bi1m9xm7ilVI9i3T2Rwy9m/sU5n2dz/JrSdro002ZleUcQAWtNLv+/ZfrKzP98Tv9SqX5zs37FNrkn04q2tjDnv4powyNyXX8HWPm6x9lGH+i3pw+bBR3i8nYmcGx+f0s2iGvy+8eBaTncmzhLbyHe8QZxtj02G/Q9xNlOd+J21dXZEO4mDtCvG3Sywdxamu7H2TD2yu+Ls1F0Ic4UNxBnkQOIM5X5xOXwdODZzPO5nMfLOc3Y3BGOLa2DInh8tFgfRDBbkcN7ZEN8Lr8/Q1zujyTO6tZnAzcicK0jbgGcThxgfpTz+jaxc68kDrYbiVszB+W6X0+cZQ3O708Tge8tOd3B1A4uB+U8D8hxlxA77aIcNySnWwz8P+Kg+UKOuynX3cys63rg4qxjcaAcTGz/6bn+rs/lWUDt9k+xjosAe3Eu73M53RBiR5+e6/eezDstt8v0XBfziLbSnOv18FyW2cSB/m+J24RXZT1657ifEwf7R4lbbM8Sb1yfTdxaejGX+XDiSqHYLvcQ29dzvf0ph4tAtTa3zQeIduPA1FzWq6ndDhqcw3+kFkzHZz2mULtCeCqHb8ztsZFox/fktjgb+G6m/4k4uXOgT85zlxz3P8StpOeJq6T/yGXqQ7TR4vlqn1z/K4irmC65XVpy3IeI7d8n1+F6IgDdQeyDzZn2m5xvE3Gl1J3aycInif39FSIA9MrpTsl6zMvtsIh4btJE3PpaQeyns4nbb8/kOp9M7NNP5/incju8RO1E4M5cz+uJY0ozEbDuznxrc7iYbm1um9uy3vfnuOIEbFFO90dqJ7qriCvFn+W2uS/zzwTOIK4cFXS2JuhkA7oV+M5m09xD7KwLiIPHauCXOe5coLk07UeJM50/AeNL6ScSt9CKef0wG90T+f2vgXXloAOMzkbxl6V8XyR2vgX5Kc4630rtlt7Hi+XKhrqcOJCVl7OFOEvpnsu3ntgZuxMH7OXE2d/9Od1Xch18L8s4hNoZ9ILcCVYQtwBupRbwinX6fJZ5J7FDFf8vZtm4zyCeLa0hAsI/ZX2ez7IG5/pYCJyeec8gnm08n/Vozr/PZhljc7kvA/4p8zxF7ERnU9uBmzPN828LtYfhC6k9bF9NbP/iIfQzOf3GHFfc+txYGi4C1sb8FOWvL03b2qZyXZyZy/80sfOfSQSEuTlcrI/rc93vkct2JtEeW3JbldfHuaX1cXlpfRQB/2WiDb2Y815JBMffZj2eyjr2JdrmOuDeLOMnuT72yDKWEsGghdoVTgvR3tcQ7erZUvkLiAPduqzHRzN9BNCS8zg559E3v38pt8+dRPu8jWgfTwC/z2nem+VtpHYVsQZ4a45/jLiNTc5rdWkdtBDvchxPtNHVWe+rsp73EycUfYl2/0pukwuJNnVJ5r+L2J+ez/kX+0xTljEx1/UU4tYh1K68r8iyTsx5Wc77G9Taxg+J2+lzc/h/qe0ri4DTSseb00r1eIFa2/gp8axnJdEGv5F5VlBrG5ZlfAN4uXRcexdxO7Td46ye6bTBzIxoYHOAiWb2lkzfPSf5grsPIBr7Xe7+BTPbkzhDWmJmRa+aI4jbazcCh5nZHln2EeR74Mzs7cTVwU3EGTvEFUK5B8gewPeI21JvLaX/BbHRB2R9lhP3pJ8jzpLWEfewIc4Ge1B7GLtn1uW3RIM6L5d5H+LqYXR+704cmN5NBI7HiSusa4EpWcY/EgeWG4gzqeK+8g9zfg8TO+J44uBSHGBnEQeAz+Y6Pja/DyMC7/3EGf8TxD3mojfVB4kzzueAR83so5mn2PFeJA5MS4keiR8mzv7nEmegC83sXcSziOIZ0QIicJxI7bZdD/IKzt33JK6+riUOzofneliT2+STOa+bc1vdDfzW3bsQB5Xb3H0P4uz4mZzu/VnWwzn93CzzLiI4PkM8B3k657Mwv+9HHFiH53r9WC7/GUA/M+uV44r5FetvKXFV9BHi2cO8rPdjZvY+4qq0uPobRFwBvDXnX/RqXJPboZm4+piS2/N5MxtO7SH+R7IdvkocpG7Icn+V5VxGHOxWU7stvJpNe2Ytzno/TjygXmRmXYgOLbOJNgrR/u7K4WHEld33iLY3DcDdHyVuGc3MfWUt8J9ZR3JbF8+9xuRyDsp6Lc/1dRjxTOoZogPQu4kz/EHUTgybiWcnh1N7JvhErqP35fb4Qa6jF4g2/PfE1c6bc9r3Am8xs4OJZ4hGnLguIY45xe1UJ/bVNTnueOIZyx3EvrSC2r7yKnClmR2e011J3AV5JZdrKdGJ6Uhi33yaeLZztZl9LOs2J7fJ8Vn+YuKYQG6XfyeugNqlNxIkM7uauCoouuQWD1N3IR6cLiM20CR3PyvznEBcfs8nGtqviIP4LzLfM8QBb3/iDOzzxBnFntQ6Jqwnzhx7EgdGiANh8YCx3BVyNdGojNrZMlm3xdS6RpfHWamsdUTjKh5ktmS9m4gD8C7EwXYhtS7ca3Oablmvok7lbpxdibOgF4irqhZiRyhura3JfG+idqa/B7Wrs/6lcotPccXRL5fDc9qie7ZT66ZedP0vrhqmEDv4wdS6ZhdXJhDbk6xHC7Gd3kQ8VG0ibqv0IM4OHyHaxYpcjr5ER4znc505ESwGUOuYcxdxZvoldz/KzNbkfObnvHoQV4fziLPb7xBXHo8RB4N35Hoq1tuexIF5D+IgVDzr6F1aX8WVRNEVvHw19hsi2By02fpoZtOTmOeINrk21/sqog2szvXThdjO5DT75PRdcl12zfTFRJsn61o8h1hGnFgdTOxLRZdwiG3YhWife2Q91xH742LiCr94ltGfOEiPz3U1gAgMRX3WlpatuPpcTASJg4kz+pXEyeABOf93EycCA3P4GOKE5xji4fgPc53sU1q/q3K+/al1md6Y26DovLKO2v5X7JOvEicNTxC99Iou4Ruynt1zffeg1tvvlUzfj9p+uILYx9bkPHfJ9fZCbrd9qO0rRT2K72TaPxA92D5cqkcLcQzoS63b92PEMaobsX8UnZDupvY7ZVOIOw/tBhUFHRERqYxur4mISGUUdEREpDIKOiIiUhkFHRERqYyCjoiIVEZBR2QnZWarGl0H2fko6IjsBPJFsyINp6AjshXMbICZzTGzS81stpndZma7m9mdZjY4p9nXzBbk8JfM7AYz+42ZzTezU83sO2b2RzN7wMz23sJ8epvZzBx+n5l5vsUCM3sq33LxDjO73cweyb/F+MvN7Mdm9gfgHDPb38zuN7OHzOzs0jz6mtndZjbLzB7LNzyI1IWCjsjWGwhc5O7vIV6983qvdT8I+DviRZ9jiXd9HUK87ufEtjJ4/NzAbvmzGcW7/D5qZu8Alrv7auIdX1d6/K7PVcTrTQrvIl5P/13ivVrj3P2vqb2dgazTrR6/6fM+4vVEInWhoCOy9ea7+6wcnkm8jqU9f3D3le7eRLza5DeZ/ujr5L2PeE3J4cTrWA4nAtA9Of6DxCuYIF6r85FS3l+7+4Yc/jDxFuhiusJDwJfN7EzgvR6/ISVSFwo6IltvXWl4A/FequLdZlD7aeO2pt9Y+r6R9n86/h4iyLyD+MG/9xGB5e4tTF9+t9Ur7YyLhPjRv8OJ935NNLM2r7pEtgUFHZFtawHxw20QbwvfFu4mfjTuSXcvfoPmSOLN3hBXQsUvcv498WNnbfmfzaYDoHSr7lLiJZrv30b1FnkNBR2Rbetc4GQzu4/aTxf/Wdx9QQ4WVzb3Ej9tviK/f4u4PfYI8RtLp22hqNOAU8zsIeIN2YWPA7PM7I/Ec6mftpFXZJvQW6ZFRKQyutIREZHK6B/GRLYTZnYR0cOs7Kfuflkj6iNSD7q9JiIildHtNRERqYyCjoiIVEZBR0REKqOgIyIilVHQERGRyvx/CnfzoCLjV7UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(el[el['num_words'] < 100]['num_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num_words', ylabel='count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(el[el['num_words'] < 30]['num_words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num_words', ylabel='overall'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x = 'num_words', y= 'overall', data= el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10369156678250079"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el['num_words'].corr(el['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, there is essentially no linear relationship between the number of words in the review and the star rating. Furthermore, a good portion of our data consists of reviews with only a few words. This leads us to believe that we probably don't have to worry about cleaning reviews based on length. But for the sheer fun of it, let's take a look at some of these 1-2 word reviews to see if anything stands out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 16, 2015</td>\n",
       "      <td>A3UD8JRWLX6SRX</td>\n",
       "      <td>0380709473</td>\n",
       "      <td>Great read!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1424044800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10 29, 2016</td>\n",
       "      <td>A1917RO9OGLVT9</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>Works great!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1477699200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>09 20, 2016</td>\n",
       "      <td>AIV2RLRZNV7TC</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>1474329600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 14, 2016</td>\n",
       "      <td>A17BMVVA8MND5C</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>very nice....</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1471132800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 26, 2016</td>\n",
       "      <td>A24VW8XTD8LSXE</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>Works great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1469491200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 5, 2015</td>\n",
       "      <td>A3J6X6RXNRHM8V</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>worked. cheap.</td>\n",
       "      <td>if the cable company is a dick. just buy one f...</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 30, 2015</td>\n",
       "      <td>A2R8N42G5EDN91</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1435622400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 10, 2015</td>\n",
       "      <td>A1VJ8WQJ5X5F5M</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>awesome product</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1433894400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 11, 2014</td>\n",
       "      <td>A3EEMBPGLSMFB6</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>IT WORKS WONDERFUL.........</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1412985600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 22, 2013</td>\n",
       "      <td>A3H86FCI0QZH7T</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>It was great.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1377129600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 11, 2014</td>\n",
       "      <td>A3OXZRN6VAXPBG</td>\n",
       "      <td>0545105668</td>\n",
       "      <td>great book</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1407715200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 2, 2015</td>\n",
       "      <td>A1IR4I87CHWR6U</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>It's great</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1427932800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 20, 2016</td>\n",
       "      <td>A1Q4Q0QGFOGG2L</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>Good condition</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1482192000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 11, 2014</td>\n",
       "      <td>A1ZZFX6SHV84ZU</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>very nice item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1410393600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 3, 2015</td>\n",
       "      <td>A2HXJSPV5HTGRR</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>Works perfectly</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1446508800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 1, 2015</td>\n",
       "      <td>AI0O8QKFUMLVP</td>\n",
       "      <td>0594459451</td>\n",
       "      <td>Works great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1443657600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 24, 2016</td>\n",
       "      <td>A372NLHXKJ0ZU7</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1453593600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 23, 2015</td>\n",
       "      <td>A1C4KLUCGA925L</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Works very well.</td>\n",
       "      <td>good Cord</td>\n",
       "      <td>1448236800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 29, 2014</td>\n",
       "      <td>A3ENTF3O6L6LRH</td>\n",
       "      <td>0594296420</td>\n",
       "      <td>Works as expected.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1411948800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 22, 2016</td>\n",
       "      <td>AVAK9OUO0KRBK</td>\n",
       "      <td>0594296420</td>\n",
       "      <td>Works great.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1477094400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 2016</td>\n",
       "      <td>AR2S1240FNCJJ</td>\n",
       "      <td>0594296420</td>\n",
       "      <td>Good product</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1474156800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 26, 2016</td>\n",
       "      <td>A1RSZO23H2V3JW</td>\n",
       "      <td>0594296420</td>\n",
       "      <td>met expectations</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1464220800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 7, 2015</td>\n",
       "      <td>A2KOMJ1WFJGHQN</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Very good</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1428364800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 7, 2015</td>\n",
       "      <td>AL5WUYUY7TCNQ</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>love it</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1428364800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 26, 2015</td>\n",
       "      <td>AH77RC0RZV1H9</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1424908800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 29, 2014</td>\n",
       "      <td>A2LB8FGV681YPY</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Works for me.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1419811200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 25, 2014</td>\n",
       "      <td>A21T769FJAJIYM</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>Life saver</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1414195200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>08 9, 2014</td>\n",
       "      <td>AQ9ZZ4WT23TZ0</td>\n",
       "      <td>0594481902</td>\n",
       "      <td>works great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1407542400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 25, 2016</td>\n",
       "      <td>A2JBLOPKBV3E3N</td>\n",
       "      <td>059449771X</td>\n",
       "      <td>Perfect!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1474761600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 30, 2015</td>\n",
       "      <td>A1DN3L6ZHLN7YQ</td>\n",
       "      <td>059449771X</td>\n",
       "      <td>Well pleased!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1440892800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 14, 2015</td>\n",
       "      <td>ATLBO2B3KETQI</td>\n",
       "      <td>059449771X</td>\n",
       "      <td>did not work</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1436832000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 25, 2016</td>\n",
       "      <td>AZBZ16EHM6UVY</td>\n",
       "      <td>0594450268</td>\n",
       "      <td>LOVE IT!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1469404800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 25, 2015</td>\n",
       "      <td>A1IR4I87CHWR6U</td>\n",
       "      <td>0594450268</td>\n",
       "      <td>great</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1432512000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 19, 2014</td>\n",
       "      <td>A2ZT9U9SFAO9Q1</td>\n",
       "      <td>0594450268</td>\n",
       "      <td>This work great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1413676800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 30, 2017</td>\n",
       "      <td>AESDP3GI6GYQD</td>\n",
       "      <td>073530498X</td>\n",
       "      <td>Nice photo album</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1485734400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 6, 2016</td>\n",
       "      <td>A27N2CH8M3O5JS</td>\n",
       "      <td>073530498X</td>\n",
       "      <td>Very cheap</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1478390400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 10, 2016</td>\n",
       "      <td>A2TNU7LSDHLIUR</td>\n",
       "      <td>073530498X</td>\n",
       "      <td>Cute</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1455062400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 10, 2015</td>\n",
       "      <td>A1A9K9PPJYQS7D</td>\n",
       "      <td>073530498X</td>\n",
       "      <td>cute</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1420848000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 3, 2014</td>\n",
       "      <td>AHLC1B2T1T0FM</td>\n",
       "      <td>073530498X</td>\n",
       "      <td>Small and cute.</td>\n",
       "      <td>Cute</td>\n",
       "      <td>1417564800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 4, 2015</td>\n",
       "      <td>AVI85DVUYOASS</td>\n",
       "      <td>0764207474</td>\n",
       "      <td>Good value</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1443916800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 21, 2014</td>\n",
       "      <td>A2JHQ6NUUM9KG2</td>\n",
       "      <td>0764207474</td>\n",
       "      <td>Good</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1419120000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 11, 2014</td>\n",
       "      <td>A1O17YGZA8GAH0</td>\n",
       "      <td>0764207474</td>\n",
       "      <td>excellent!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1418256000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 15, 2014</td>\n",
       "      <td>AVAA8Y0SYBCC2</td>\n",
       "      <td>0764207474</td>\n",
       "      <td>ok</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1408060800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11 13, 2016</td>\n",
       "      <td>A3QCRDOZ2UBXGI</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>It met expectations</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1478995200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>08 31, 2016</td>\n",
       "      <td>A2WSQF1FWD8F99</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>Very good</td>\n",
       "      <td>good device</td>\n",
       "      <td>1472601600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2016</td>\n",
       "      <td>A15PSEYKVZRYP8</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>just as advertised</td>\n",
       "      <td>works great</td>\n",
       "      <td>1468022400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 5, 2016</td>\n",
       "      <td>A2TR545Z1DIHHD</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>Excellent Product...</td>\n",
       "      <td>Excellent Product...</td>\n",
       "      <td>1467676800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 13, 2016</td>\n",
       "      <td>A33CGGVAP73IHU</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>Perfect fit</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1465776000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 2, 2016</td>\n",
       "      <td>A1MNILX1J1NWV7</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>works great.</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1464825600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>03 23, 2016</td>\n",
       "      <td>A3GL5CKBAASASK</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>A+++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1458691200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "8        5.0  NaN      True  02 16, 2015  A3UD8JRWLX6SRX  0380709473   \n",
       "19       5.0  NaN     False  10 29, 2016  A1917RO9OGLVT9  0511189877   \n",
       "20       5.0  NaN     False  09 20, 2016   AIV2RLRZNV7TC  0511189877   \n",
       "22       5.0  NaN      True  08 14, 2016  A17BMVVA8MND5C  0511189877   \n",
       "23       5.0  NaN      True  07 26, 2016  A24VW8XTD8LSXE  0511189877   \n",
       "35       5.0  NaN      True   08 5, 2015  A3J6X6RXNRHM8V  0511189877   \n",
       "37       5.0  NaN      True  06 30, 2015  A2R8N42G5EDN91  0511189877   \n",
       "38       5.0  NaN      True  06 10, 2015  A1VJ8WQJ5X5F5M  0511189877   \n",
       "47       5.0  NaN      True  10 11, 2014  A3EEMBPGLSMFB6  0511189877   \n",
       "58       5.0  NaN      True  08 22, 2013  A3H86FCI0QZH7T  0528881469   \n",
       "68       5.0  NaN      True  08 11, 2014  A3OXZRN6VAXPBG  0545105668   \n",
       "84       4.0  NaN      True   04 2, 2015  A1IR4I87CHWR6U  0594033926   \n",
       "86       5.0  NaN      True  12 20, 2016  A1Q4Q0QGFOGG2L  0594459451   \n",
       "95       5.0  NaN      True  09 11, 2014  A1ZZFX6SHV84ZU  0594033926   \n",
       "106      5.0  NaN      True   11 3, 2015  A2HXJSPV5HTGRR  0594459451   \n",
       "107      5.0  NaN      True   10 1, 2015   AI0O8QKFUMLVP  0594459451   \n",
       "117      5.0  NaN      True  01 24, 2016  A372NLHXKJ0ZU7  0594481902   \n",
       "119      5.0  NaN      True  11 23, 2015  A1C4KLUCGA925L  0594481902   \n",
       "128      5.0  NaN      True  09 29, 2014  A3ENTF3O6L6LRH  0594296420   \n",
       "135      5.0  NaN      True  10 22, 2016   AVAK9OUO0KRBK  0594296420   \n",
       "137      5.0  NaN      True  09 18, 2016   AR2S1240FNCJJ  0594296420   \n",
       "142      5.0  NaN      True  05 26, 2016  A1RSZO23H2V3JW  0594296420   \n",
       "149      5.0  NaN      True   04 7, 2015  A2KOMJ1WFJGHQN  0594481902   \n",
       "150      5.0  NaN      True   04 7, 2015   AL5WUYUY7TCNQ  0594481902   \n",
       "151      5.0  NaN      True  02 26, 2015   AH77RC0RZV1H9  0594481902   \n",
       "154      5.0  NaN      True  12 29, 2014  A2LB8FGV681YPY  0594481902   \n",
       "158      5.0  NaN      True  10 25, 2014  A21T769FJAJIYM  0594481902   \n",
       "163      5.0  NaN     False   08 9, 2014   AQ9ZZ4WT23TZ0  0594481902   \n",
       "185      5.0  NaN      True  09 25, 2016  A2JBLOPKBV3E3N  059449771X   \n",
       "195      5.0  NaN      True  08 30, 2015  A1DN3L6ZHLN7YQ  059449771X   \n",
       "196      1.0  NaN      True  07 14, 2015   ATLBO2B3KETQI  059449771X   \n",
       "208      5.0  NaN      True  07 25, 2016   AZBZ16EHM6UVY  0594450268   \n",
       "211      4.0  NaN      True  05 25, 2015  A1IR4I87CHWR6U  0594450268   \n",
       "215      5.0  NaN      True  10 19, 2014  A2ZT9U9SFAO9Q1  0594450268   \n",
       "221      5.0  NaN      True  01 30, 2017   AESDP3GI6GYQD  073530498X   \n",
       "225      3.0  NaN      True   11 6, 2016  A27N2CH8M3O5JS  073530498X   \n",
       "228      5.0  NaN      True  02 10, 2016  A2TNU7LSDHLIUR  073530498X   \n",
       "237      5.0  NaN      True  01 10, 2015  A1A9K9PPJYQS7D  073530498X   \n",
       "239      5.0  NaN      True   12 3, 2014   AHLC1B2T1T0FM  073530498X   \n",
       "259      5.0  NaN      True   10 4, 2015   AVI85DVUYOASS  0764207474   \n",
       "261      5.0  NaN      True  12 21, 2014  A2JHQ6NUUM9KG2  0764207474   \n",
       "262      5.0  NaN      True  12 11, 2014  A1O17YGZA8GAH0  0764207474   \n",
       "263      3.0  NaN      True  08 15, 2014   AVAA8Y0SYBCC2  0764207474   \n",
       "351      4.0  NaN     False  11 13, 2016  A3QCRDOZ2UBXGI  0972683275   \n",
       "354      5.0  NaN     False  08 31, 2016  A2WSQF1FWD8F99  0972683275   \n",
       "357      5.0  NaN      True   07 9, 2016  A15PSEYKVZRYP8  0972683275   \n",
       "358      5.0  NaN      True   07 5, 2016  A2TR545Z1DIHHD  0972683275   \n",
       "360      5.0  NaN      True  06 13, 2016  A33CGGVAP73IHU  0972683275   \n",
       "361      4.0  NaN      True   06 2, 2016  A1MNILX1J1NWV7  0972683275   \n",
       "366      5.0  NaN      True  03 23, 2016  A3GL5CKBAASASK  0972683275   \n",
       "\n",
       "                      reviewText  \\\n",
       "8                    Great read!   \n",
       "19                  Works great!   \n",
       "20                          Cool   \n",
       "22                 very nice....   \n",
       "23                   Works great   \n",
       "35                worked. cheap.   \n",
       "37                         great   \n",
       "38               awesome product   \n",
       "47   IT WORKS WONDERFUL.........   \n",
       "58                 It was great.   \n",
       "68                    great book   \n",
       "84                    It's great   \n",
       "86                Good condition   \n",
       "95                very nice item   \n",
       "106              Works perfectly   \n",
       "107                  Works great   \n",
       "117                      Perfect   \n",
       "119             Works very well.   \n",
       "128           Works as expected.   \n",
       "135                 Works great.   \n",
       "137                 Good product   \n",
       "142             met expectations   \n",
       "149                    Very good   \n",
       "150                      love it   \n",
       "151                      Awesome   \n",
       "154                Works for me.   \n",
       "158                   Life saver   \n",
       "163                  works great   \n",
       "185                     Perfect!   \n",
       "195                Well pleased!   \n",
       "196                 did not work   \n",
       "208                     LOVE IT!   \n",
       "211                        great   \n",
       "215              This work great   \n",
       "221             Nice photo album   \n",
       "225                   Very cheap   \n",
       "228                         Cute   \n",
       "237                         cute   \n",
       "239              Small and cute.   \n",
       "259                   Good value   \n",
       "261                         Good   \n",
       "262                   excellent!   \n",
       "263                           ok   \n",
       "351          It met expectations   \n",
       "354                    Very good   \n",
       "357           just as advertised   \n",
       "358         Excellent Product...   \n",
       "360                  Perfect fit   \n",
       "361                 works great.   \n",
       "366                         A+++   \n",
       "\n",
       "                                               summary  unixReviewTime  \\\n",
       "8                                           Five Stars      1424044800   \n",
       "19                                          Five Stars      1477699200   \n",
       "20                                             Awesome      1474329600   \n",
       "22                                          Five Stars      1471132800   \n",
       "23                                          Five Stars      1469491200   \n",
       "35   if the cable company is a dick. just buy one f...      1438732800   \n",
       "37                                          Five Stars      1435622400   \n",
       "38                                          Five Stars      1433894400   \n",
       "47                                          Five Stars      1412985600   \n",
       "58                                          Five Stars      1377129600   \n",
       "68                                          Five Stars      1407715200   \n",
       "84                                          Four Stars      1427932800   \n",
       "86                                          Five Stars      1482192000   \n",
       "95                                          Five Stars      1410393600   \n",
       "106                                         Five Stars      1446508800   \n",
       "107                                         Five Stars      1443657600   \n",
       "117                                         Five Stars      1453593600   \n",
       "119                                          good Cord      1448236800   \n",
       "128                                         Five Stars      1411948800   \n",
       "135                                         Five Stars      1477094400   \n",
       "137                                         Five Stars      1474156800   \n",
       "142                                         Five Stars      1464220800   \n",
       "149                                         Five Stars      1428364800   \n",
       "150                                         Five Stars      1428364800   \n",
       "151                                         Five Stars      1424908800   \n",
       "154                                         Five Stars      1419811200   \n",
       "158                                         Five Stars      1414195200   \n",
       "163                                         Five Stars      1407542400   \n",
       "185                                         Five Stars      1474761600   \n",
       "195                                         Five Stars      1440892800   \n",
       "196                                           One Star      1436832000   \n",
       "208                                         Five Stars      1469404800   \n",
       "211                                         Four Stars      1432512000   \n",
       "215                                         Five Stars      1413676800   \n",
       "221                                         Five Stars      1485734400   \n",
       "225                                        Three Stars      1478390400   \n",
       "228                                         Five Stars      1455062400   \n",
       "237                                         Five Stars      1420848000   \n",
       "239                                               Cute      1417564800   \n",
       "259                                         Five Stars      1443916800   \n",
       "261                                         Five Stars      1419120000   \n",
       "262                                         Five Stars      1418256000   \n",
       "263                                        Three Stars      1408060800   \n",
       "351                                         Four Stars      1478995200   \n",
       "354                                        good device      1472601600   \n",
       "357                                        works great      1468022400   \n",
       "358                               Excellent Product...      1467676800   \n",
       "360                                         Five Stars      1465776000   \n",
       "361                                         Four Stars      1464825600   \n",
       "366                                         Five Stars      1458691200   \n",
       "\n",
       "     num_words  \n",
       "8            2  \n",
       "19           2  \n",
       "20           1  \n",
       "22           2  \n",
       "23           2  \n",
       "35           2  \n",
       "37           1  \n",
       "38           2  \n",
       "47           3  \n",
       "58           3  \n",
       "68           2  \n",
       "84           2  \n",
       "86           2  \n",
       "95           3  \n",
       "106          2  \n",
       "107          2  \n",
       "117          1  \n",
       "119          3  \n",
       "128          3  \n",
       "135          2  \n",
       "137          2  \n",
       "142          2  \n",
       "149          2  \n",
       "150          2  \n",
       "151          1  \n",
       "154          3  \n",
       "158          2  \n",
       "163          2  \n",
       "185          1  \n",
       "195          2  \n",
       "196          3  \n",
       "208          2  \n",
       "211          1  \n",
       "215          3  \n",
       "221          3  \n",
       "225          2  \n",
       "228          1  \n",
       "237          1  \n",
       "239          3  \n",
       "259          2  \n",
       "261          1  \n",
       "262          1  \n",
       "263          1  \n",
       "351          3  \n",
       "354          2  \n",
       "357          3  \n",
       "358          2  \n",
       "360          2  \n",
       "361          2  \n",
       "366          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el[el['num_words'] < 4].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing too out of the ordinary here on first glance, but let's try one last analysis to get a more robust picture. Let's convert just these tiny reviews into a bag-of-words model to see the top words, and to see if there are any blaring contradictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', max_features=100, ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(el[el['num_words'] < 4]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['100', 'aaa', 'advertised', 'amazing', 'awesome', 'bad', 'battery', 'best', 'bueno', 'buy', 'cable', 'cables', 'camera', 'card', 'case', 'cheap', 'cool', 'deal', 'described', 'did', 'didn', 'does', 'drive', 'easy', 'exactly', 'excelent', 'excelente', 'excellent', 'expected', 'fantastic', 'fast', 'fine', 'fit', 'fits', 'gift', 'good', 'great', 'handy', 'happy', 'high', 'intended', 'issues', 'item', 'job', 'junk', 'just', 'lens', 'like', 'little', 'looks', 'love', 'loved', 'loves', 'mouse', 'muy', 'needed', 'nice', 'ok', 'okay', 'outstanding', 'perfect', 'perfectly', 'poor', 'pretty', 'price', 'problems', 'product', 'producto', 'promised', 'protection', 'purchase', 'quality', 'really', 'recommend', 'recommended', 'reliable', 'replacement', 'returned', 'right', 's', 'satisfied', 'small', 'solid', 'sound', 'sounds', 'stuff', 'sturdy', 'super', 't', 'thank', 'thanks', 'use', 'useful', 'value', 'wonderful', 'work', 'worked', 'working', 'works', 'worth']\n",
      "[  1174   1011  16994   2201  12325   1754    901   3423   1151   4769\n",
      "   4271   1999   1813   1054   4897   2375   2393   4489  13086   2165\n",
      "   1656   5086    897   2362   2158   4637   6164  39823  19122   1726\n",
      "   3850  13243   5304   3453   2046 123040 154910   1361   1977   1048\n",
      "   2041   1254   8365   6098   1313   6551   1117   5647   1907    908\n",
      "  25743   1938   1467   1027   1172   1078  27933  25670   2249    936\n",
      "  27722   8085    924   1403   6241   1964  56597   1779   1374    993\n",
      "   1601  16155   2538   1256   1334    931   1606   1479    991   5004\n",
      "   2201   1062   1388   4238    937   2124   1204   2018   3531   7023\n",
      "  12403   1338   1901   4589   1463  14385  17658   4003 124500    977]\n"
     ]
    }
   ],
   "source": [
    "print(f'words: {cv.get_feature_names()}')\n",
    "print(text_counts.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'great': 36, 'works': 98, 'cool': 16, 'nice': 56, 'worked': 96, 'cheap': 15, 'awesome': 4, 'product': 66, 'wonderful': 94, 's': 79, 'good': 35, 'item': 42, 'perfectly': 61, 'perfect': 60, 'expected': 28, 'love': 50, 'did': 19, 'work': 95, 'small': 81, 'value': 93, 'excellent': 27, 'ok': 57, 'just': 45, 'advertised': 2, 'fit': 32, 'fine': 31, 'exactly': 24, 'excelente': 26, 'really': 72, 'returned': 77, 't': 88, 'described': 18, 'didn': 20, 'price': 64, 'card': 13, 'job': 43, 'promised': 68, 'thank': 89, 'recommended': 74, 'gift': 34, 'loved': 51, 'quality': 71, 'thanks': 90, 'buy': 9, 'like': 47, 'best': 7, 'fast': 30, 'useful': 92, 'little': 48, 'does': 21, 'muy': 54, 'bueno': 8, 'satisfied': 80, 'handy': 37, 'deal': 17, 'easy': 23, 'happy': 38, 'sturdy': 86, 'use': 91, 'excelent': 25, 'drive': 22, 'intended': 40, 'stuff': 85, 'bad': 5, 'cable': 10, 'high': 39, '100': 0, 'purchase': 70, 'problems': 65, 'working': 97, 'needed': 55, 'looks': 49, 'okay': 58, 'camera': 12, 'right': 78, 'issues': 41, 'solid': 82, 'super': 87, 'fits': 33, 'cables': 11, 'sound': 83, 'recommend': 73, 'protection': 69, 'case': 14, 'fantastic': 29, 'junk': 44, 'poor': 62, 'amazing': 3, 'pretty': 63, 'sounds': 84, 'reliable': 75, 'producto': 67, 'worth': 99, 'loves': 52, 'lens': 46, 'aaa': 1, 'outstanding': 59, 'mouse': 53, 'replacement': 76, 'battery': 6}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 154910),\n",
       " ('works', 124500),\n",
       " ('good', 123040),\n",
       " ('product', 56597),\n",
       " ('excellent', 39823),\n",
       " ('nice', 27933),\n",
       " ('perfect', 27722),\n",
       " ('love', 25743),\n",
       " ('ok', 25670),\n",
       " ('expected', 19122),\n",
       " ('worked', 17658),\n",
       " ('advertised', 16994),\n",
       " ('quality', 16155),\n",
       " ('work', 14385),\n",
       " ('fine', 13243),\n",
       " ('described', 13086),\n",
       " ('thanks', 12403),\n",
       " ('awesome', 12325),\n",
       " ('item', 8365),\n",
       " ('perfectly', 8085),\n",
       " ('thank', 7023),\n",
       " ('just', 6551),\n",
       " ('price', 6241),\n",
       " ('excelente', 6164),\n",
       " ('job', 6098),\n",
       " ('like', 5647),\n",
       " ('fit', 5304),\n",
       " ('does', 5086),\n",
       " ('s', 5004),\n",
       " ('case', 4897),\n",
       " ('buy', 4769),\n",
       " ('excelent', 4637),\n",
       " ('value', 4589),\n",
       " ('deal', 4489),\n",
       " ('cable', 4271),\n",
       " ('sound', 4238),\n",
       " ('working', 4003),\n",
       " ('fast', 3850),\n",
       " ('t', 3531),\n",
       " ('fits', 3453),\n",
       " ('best', 3423),\n",
       " ('really', 2538),\n",
       " ('cool', 2393),\n",
       " ('cheap', 2375),\n",
       " ('easy', 2362),\n",
       " ('okay', 2249),\n",
       " ('satisfied', 2201),\n",
       " ('amazing', 2201),\n",
       " ('did', 2165),\n",
       " ('exactly', 2158),\n",
       " ('stuff', 2124),\n",
       " ('gift', 2046),\n",
       " ('intended', 2041),\n",
       " ('super', 2018),\n",
       " ('cables', 1999),\n",
       " ('happy', 1977),\n",
       " ('problems', 1964),\n",
       " ('loved', 1938),\n",
       " ('little', 1907),\n",
       " ('useful', 1901),\n",
       " ('camera', 1813),\n",
       " ('producto', 1779),\n",
       " ('bad', 1754),\n",
       " ('fantastic', 1726),\n",
       " ('didn', 1656),\n",
       " ('replacement', 1606),\n",
       " ('purchase', 1601),\n",
       " ('returned', 1479),\n",
       " ('loves', 1467),\n",
       " ('wonderful', 1463),\n",
       " ('pretty', 1403),\n",
       " ('solid', 1388),\n",
       " ('promised', 1374),\n",
       " ('handy', 1361),\n",
       " ('use', 1338),\n",
       " ('recommended', 1334),\n",
       " ('junk', 1313),\n",
       " ('recommend', 1256),\n",
       " ('issues', 1254),\n",
       " ('sturdy', 1204),\n",
       " ('100', 1174),\n",
       " ('muy', 1172),\n",
       " ('bueno', 1151),\n",
       " ('lens', 1117),\n",
       " ('needed', 1078),\n",
       " ('small', 1062),\n",
       " ('card', 1054),\n",
       " ('high', 1048),\n",
       " ('mouse', 1027),\n",
       " ('aaa', 1011),\n",
       " ('protection', 993),\n",
       " ('right', 991),\n",
       " ('worth', 977),\n",
       " ('sounds', 937),\n",
       " ('outstanding', 936),\n",
       " ('reliable', 931),\n",
       " ('poor', 924),\n",
       " ('looks', 908),\n",
       " ('battery', 901),\n",
       " ('drive', 897)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's display this in a more readable way\n",
    "\n",
    "word_counts = []\n",
    "text_sums = text_counts.toarray().sum(axis=0)\n",
    "for item in cv.vocabulary_.items():\n",
    "    tup = (item[0], text_sums[item[1]])\n",
    "    word_counts.append(tup)\n",
    "\n",
    "#sort by most common words first\n",
    "word_counts.sort(key=lambda x:x[1], reverse = True)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78769</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 18, 2017</td>\n",
       "      <td>AU4AHWVX4777F</td>\n",
       "      <td>B0000665UZ</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1484697600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93003</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 13, 2018</td>\n",
       "      <td>A1VFHC9IE14X3H</td>\n",
       "      <td>B000068O1B</td>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1518480000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93169</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 13, 2018</td>\n",
       "      <td>A1VFHC9IE14X3H</td>\n",
       "      <td>B000068O1D</td>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1518480000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93327</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 13, 2018</td>\n",
       "      <td>A1VFHC9IE14X3H</td>\n",
       "      <td>B000068O18</td>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1518480000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93469</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 3, 2015</td>\n",
       "      <td>A17YHRD5OVH9AA</td>\n",
       "      <td>B000068NYI</td>\n",
       "      <td>chyeaaaaa boiiiii</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1438560000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106909</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2016</td>\n",
       "      <td>A1XY01IGE7ZTW4</td>\n",
       "      <td>B00006B83E</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1464912000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107497</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 8, 2015</td>\n",
       "      <td>A1C0RGLZ5F4BR</td>\n",
       "      <td>B00006B9W2</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1444262400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188455</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 2016</td>\n",
       "      <td>AZ3GAQJUYXO5C</td>\n",
       "      <td>B0000B006W</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1474156800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228173</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2016</td>\n",
       "      <td>A1XY01IGE7ZTW4</td>\n",
       "      <td>B0001PFQAI</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1464912000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275537</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>A2WC2I3A9DCIHF</td>\n",
       "      <td>B0002MQGK4</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450443</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 14, 2014</td>\n",
       "      <td>AXF43WVHAVHSJ</td>\n",
       "      <td>B000EVSLRO</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1415923200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460269</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2017</td>\n",
       "      <td>AK4X50RLUP5QC</td>\n",
       "      <td>B000F7857S</td>\n",
       "      <td>naaa</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1486512000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465241</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 14, 2015</td>\n",
       "      <td>A3C66RYQCMPT6X</td>\n",
       "      <td>B000FBRQZG</td>\n",
       "      <td>aaaaaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1439510400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478310</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 3, 2016</td>\n",
       "      <td>A3ONIHO7HNCI00</td>\n",
       "      <td>B000FNFSPY</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1454457600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600839</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 10, 2017</td>\n",
       "      <td>A1HC2P9S3COTH8</td>\n",
       "      <td>B000NO9G8A</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1491782400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635729</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>03 8, 2018</td>\n",
       "      <td>A1ULBUAKHSBGIP</td>\n",
       "      <td>B000Q7V0W4</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1520467200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684970</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 13, 2014</td>\n",
       "      <td>A3H8LY3ZA50AKZ</td>\n",
       "      <td>B000UZL0YU</td>\n",
       "      <td>aaa+++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1413158400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741519</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 6, 2017</td>\n",
       "      <td>AFLW9GN8V3GKL</td>\n",
       "      <td>B000XMNPUM</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1501977600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742317</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 6, 2017</td>\n",
       "      <td>AFLW9GN8V3GKL</td>\n",
       "      <td>B000XMM1FW</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1501977600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748222</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 7, 2015</td>\n",
       "      <td>A20M75XKE4123Q</td>\n",
       "      <td>B000Y9TZ9Y</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1428364800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751072</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 19, 2016</td>\n",
       "      <td>A2LE3GX2F4J6M0</td>\n",
       "      <td>B000YFBOV0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1453161600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827264</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 15, 2014</td>\n",
       "      <td>A1LPG8FH1VXPFG</td>\n",
       "      <td>B0014CC9FW</td>\n",
       "      <td>Aaaaaa++++++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416009600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827320</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 15, 2014</td>\n",
       "      <td>A1LPG8FH1VXPFG</td>\n",
       "      <td>B0014CC9G6</td>\n",
       "      <td>Aaaaaaa+++++++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416009600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854596</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 18, 2014</td>\n",
       "      <td>A10O53IQXHUTMK</td>\n",
       "      <td>B0015M22C6</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1416268800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883700</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>08 26, 2014</td>\n",
       "      <td>A2HLNXOYLMERTC</td>\n",
       "      <td>B0017K51WE</td>\n",
       "      <td>works greaaaaaaaaat</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1409011200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885065</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2016</td>\n",
       "      <td>A1XY01IGE7ZTW4</td>\n",
       "      <td>B0017KTNSM</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1464912000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929790</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 6, 2017</td>\n",
       "      <td>AFLW9GN8V3GKL</td>\n",
       "      <td>B000XMNPUM</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1501977600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930588</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 6, 2017</td>\n",
       "      <td>AFLW9GN8V3GKL</td>\n",
       "      <td>B000XMM1FW</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1501977600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936493</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 7, 2015</td>\n",
       "      <td>A20M75XKE4123Q</td>\n",
       "      <td>B000Y9TZ9Y</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1428364800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939343</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 19, 2016</td>\n",
       "      <td>A2LE3GX2F4J6M0</td>\n",
       "      <td>B000YFBOV0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1453161600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015535</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 15, 2014</td>\n",
       "      <td>A1LPG8FH1VXPFG</td>\n",
       "      <td>B0014CC9FW</td>\n",
       "      <td>Aaaaaa++++++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416009600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015591</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 15, 2014</td>\n",
       "      <td>A1LPG8FH1VXPFG</td>\n",
       "      <td>B0014CC9G6</td>\n",
       "      <td>Aaaaaaa+++++++</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416009600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042867</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 18, 2014</td>\n",
       "      <td>A10O53IQXHUTMK</td>\n",
       "      <td>B0015M22C6</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1416268800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071971</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>08 26, 2014</td>\n",
       "      <td>A2HLNXOYLMERTC</td>\n",
       "      <td>B0017K51WE</td>\n",
       "      <td>works greaaaaaaaaat</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1409011200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073336</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2016</td>\n",
       "      <td>A1XY01IGE7ZTW4</td>\n",
       "      <td>B0017KTNSM</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1464912000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095053</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>A2WC2I3A9DCIHF</td>\n",
       "      <td>B0019EHU8G</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098196</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 14, 2014</td>\n",
       "      <td>AXF43WVHAVHSJ</td>\n",
       "      <td>B0019EHU8G</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1415923200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099772</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>A2WC2I3A9DCIHF</td>\n",
       "      <td>B0019HL8Q8</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104928</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 14, 2014</td>\n",
       "      <td>AXF43WVHAVHSJ</td>\n",
       "      <td>B0019HL8Q8</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1415923200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127943</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 14, 2014</td>\n",
       "      <td>AXF43WVHAVHSJ</td>\n",
       "      <td>B001B1AR50</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1415923200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136667</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 9, 2015</td>\n",
       "      <td>AQ54XIRX4T7GX</td>\n",
       "      <td>B001C1MD9M</td>\n",
       "      <td>naaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1431129600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146371</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>04 23, 2016</td>\n",
       "      <td>A3T9PMKJ2OVK1T</td>\n",
       "      <td>B001CQT0X4</td>\n",
       "      <td>Aaaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1461369600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159314</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>A2WC2I3A9DCIHF</td>\n",
       "      <td>B001DHECXA</td>\n",
       "      <td>aaa++++</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183131</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 9, 2016</td>\n",
       "      <td>A1X8JJF45FO5DF</td>\n",
       "      <td>B001F0RPGG</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1478649600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242459</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 14, 2017</td>\n",
       "      <td>AKNW0ZR7V9EPY</td>\n",
       "      <td>B001LQG28G</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1499990400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244905</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11 4, 2016</td>\n",
       "      <td>A9GCLNSM9FTI7</td>\n",
       "      <td>B001M4HXB2</td>\n",
       "      <td>Kebideeeyeeeeeeehaaaaaaaa!!!!!</td>\n",
       "      <td>Kebideeeyeeeeeeehaaaaaaaa!!!!!</td>\n",
       "      <td>1478217600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249537</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 23, 2017</td>\n",
       "      <td>A29GG5LACSB1Y2</td>\n",
       "      <td>B001MSS6CS</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1485129600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276693</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A3P5JCNYXC76UV</td>\n",
       "      <td>B001P8XVK2</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1408924800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294308</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>A2WC2I3A9DCIHF</td>\n",
       "      <td>B001R0LMMM</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300712</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 18, 2015</td>\n",
       "      <td>AKVOMT3J1NMSM</td>\n",
       "      <td>B001RQ4NDG</td>\n",
       "      <td>Aaawe yeaaah...</td>\n",
       "      <td>Everything is awesome!</td>\n",
       "      <td>1424217600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "78769        5.0  NaN      True  01 18, 2017   AU4AHWVX4777F  B0000665UZ   \n",
       "93003        4.0  NaN      True  02 13, 2018  A1VFHC9IE14X3H  B000068O1B   \n",
       "93169        4.0  NaN      True  02 13, 2018  A1VFHC9IE14X3H  B000068O1D   \n",
       "93327        4.0  NaN      True  02 13, 2018  A1VFHC9IE14X3H  B000068O18   \n",
       "93469        5.0  NaN      True   08 3, 2015  A17YHRD5OVH9AA  B000068NYI   \n",
       "106909       3.0  NaN      True   06 3, 2016  A1XY01IGE7ZTW4  B00006B83E   \n",
       "107497       5.0  NaN      True   10 8, 2015   A1C0RGLZ5F4BR  B00006B9W2   \n",
       "188455       5.0  NaN      True  09 18, 2016   AZ3GAQJUYXO5C  B0000B006W   \n",
       "228173       5.0  NaN      True   06 3, 2016  A1XY01IGE7ZTW4  B0001PFQAI   \n",
       "275537       5.0  NaN      True  02 27, 2017  A2WC2I3A9DCIHF  B0002MQGK4   \n",
       "450443       5.0  NaN      True  11 14, 2014   AXF43WVHAVHSJ  B000EVSLRO   \n",
       "460269       2.0  NaN      True   02 8, 2017   AK4X50RLUP5QC  B000F7857S   \n",
       "465241       5.0  NaN      True  08 14, 2015  A3C66RYQCMPT6X  B000FBRQZG   \n",
       "478310       5.0  NaN      True   02 3, 2016  A3ONIHO7HNCI00  B000FNFSPY   \n",
       "600839       5.0  NaN      True  04 10, 2017  A1HC2P9S3COTH8  B000NO9G8A   \n",
       "635729       5.0  NaN      True   03 8, 2018  A1ULBUAKHSBGIP  B000Q7V0W4   \n",
       "684970       5.0  NaN      True  10 13, 2014  A3H8LY3ZA50AKZ  B000UZL0YU   \n",
       "741519       5.0  NaN      True   08 6, 2017   AFLW9GN8V3GKL  B000XMNPUM   \n",
       "742317       5.0  NaN      True   08 6, 2017   AFLW9GN8V3GKL  B000XMM1FW   \n",
       "748222       5.0  NaN      True   04 7, 2015  A20M75XKE4123Q  B000Y9TZ9Y   \n",
       "751072       5.0  NaN      True  01 19, 2016  A2LE3GX2F4J6M0  B000YFBOV0   \n",
       "827264       5.0  NaN      True  11 15, 2014  A1LPG8FH1VXPFG  B0014CC9FW   \n",
       "827320       5.0  NaN      True  11 15, 2014  A1LPG8FH1VXPFG  B0014CC9G6   \n",
       "854596       3.0  NaN      True  11 18, 2014  A10O53IQXHUTMK  B0015M22C6   \n",
       "883700       5.0  NaN     False  08 26, 2014  A2HLNXOYLMERTC  B0017K51WE   \n",
       "885065       4.0  NaN      True   06 3, 2016  A1XY01IGE7ZTW4  B0017KTNSM   \n",
       "929790       5.0  NaN      True   08 6, 2017   AFLW9GN8V3GKL  B000XMNPUM   \n",
       "930588       5.0  NaN      True   08 6, 2017   AFLW9GN8V3GKL  B000XMM1FW   \n",
       "936493       5.0  NaN      True   04 7, 2015  A20M75XKE4123Q  B000Y9TZ9Y   \n",
       "939343       5.0  NaN      True  01 19, 2016  A2LE3GX2F4J6M0  B000YFBOV0   \n",
       "1015535      5.0  NaN      True  11 15, 2014  A1LPG8FH1VXPFG  B0014CC9FW   \n",
       "1015591      5.0  NaN      True  11 15, 2014  A1LPG8FH1VXPFG  B0014CC9G6   \n",
       "1042867      3.0  NaN      True  11 18, 2014  A10O53IQXHUTMK  B0015M22C6   \n",
       "1071971      5.0  NaN     False  08 26, 2014  A2HLNXOYLMERTC  B0017K51WE   \n",
       "1073336      4.0  NaN      True   06 3, 2016  A1XY01IGE7ZTW4  B0017KTNSM   \n",
       "1095053      5.0  NaN      True  02 27, 2017  A2WC2I3A9DCIHF  B0019EHU8G   \n",
       "1098196      5.0  NaN      True  11 14, 2014   AXF43WVHAVHSJ  B0019EHU8G   \n",
       "1099772      5.0  NaN      True  02 27, 2017  A2WC2I3A9DCIHF  B0019HL8Q8   \n",
       "1104928      5.0  NaN      True  11 14, 2014   AXF43WVHAVHSJ  B0019HL8Q8   \n",
       "1127943      5.0  NaN      True  11 14, 2014   AXF43WVHAVHSJ  B001B1AR50   \n",
       "1136667      5.0  NaN      True   05 9, 2015   AQ54XIRX4T7GX  B001C1MD9M   \n",
       "1146371      5.0  NaN     False  04 23, 2016  A3T9PMKJ2OVK1T  B001CQT0X4   \n",
       "1159314      4.0  NaN      True  02 27, 2017  A2WC2I3A9DCIHF  B001DHECXA   \n",
       "1183131      5.0  NaN      True   11 9, 2016  A1X8JJF45FO5DF  B001F0RPGG   \n",
       "1242459      5.0  NaN      True  07 14, 2017   AKNW0ZR7V9EPY  B001LQG28G   \n",
       "1244905      5.0  NaN      True   11 4, 2016   A9GCLNSM9FTI7  B001M4HXB2   \n",
       "1249537      5.0  NaN      True  01 23, 2017  A29GG5LACSB1Y2  B001MSS6CS   \n",
       "1276693      5.0  NaN      True  08 25, 2014  A3P5JCNYXC76UV  B001P8XVK2   \n",
       "1294308      4.0  NaN      True  02 27, 2017  A2WC2I3A9DCIHF  B001R0LMMM   \n",
       "1300712      5.0  NaN      True  02 18, 2015   AKVOMT3J1NMSM  B001RQ4NDG   \n",
       "\n",
       "                             reviewText                         summary  \\\n",
       "78769                               aaa                      Five Stars   \n",
       "93003                           aaaaaaa                      Four Stars   \n",
       "93169                           aaaaaaa                      Four Stars   \n",
       "93327                           aaaaaaa                      Four Stars   \n",
       "93469                 chyeaaaaa boiiiii                      Five Stars   \n",
       "106909                              aaa                     Three Stars   \n",
       "107497                              aaa                      Five Stars   \n",
       "188455                              aaa                      Five Stars   \n",
       "228173                              aaa                      Five Stars   \n",
       "275537                              aaa                      Five Stars   \n",
       "450443                            aaaaa                      Five Stars   \n",
       "460269                             naaa                       Two Stars   \n",
       "465241                          aaaaaaa                      Five Stars   \n",
       "478310                              aaa                      Five Stars   \n",
       "600839                              aaa                      Five Stars   \n",
       "635729                              aaa                      Five Stars   \n",
       "684970                           aaa+++                      Five Stars   \n",
       "741519                              aaa                      Five Stars   \n",
       "742317                              aaa                      Five Stars   \n",
       "748222                             aaaa                      Five Stars   \n",
       "751072                              aaa                      Five Stars   \n",
       "827264                     Aaaaaa++++++                      Five Stars   \n",
       "827320                   Aaaaaaa+++++++                      Five Stars   \n",
       "854596                              aaa                     Three Stars   \n",
       "883700              works greaaaaaaaaat                      Five Stars   \n",
       "885065                              aaa                      Four Stars   \n",
       "929790                              aaa                      Five Stars   \n",
       "930588                              aaa                      Five Stars   \n",
       "936493                             aaaa                      Five Stars   \n",
       "939343                              aaa                      Five Stars   \n",
       "1015535                    Aaaaaa++++++                      Five Stars   \n",
       "1015591                  Aaaaaaa+++++++                      Five Stars   \n",
       "1042867                             aaa                     Three Stars   \n",
       "1071971             works greaaaaaaaaat                      Five Stars   \n",
       "1073336                             aaa                      Four Stars   \n",
       "1095053                            aaaa                      Five Stars   \n",
       "1098196                           aaaaa                      Five Stars   \n",
       "1099772                            aaaa                      Five Stars   \n",
       "1104928                           aaaaa                      Five Stars   \n",
       "1127943                           aaaaa                      Five Stars   \n",
       "1136667                            naaa                      Five Stars   \n",
       "1146371                            Aaaa                      Five Stars   \n",
       "1159314                         aaa++++                      Four Stars   \n",
       "1183131                             aaa                      Five Stars   \n",
       "1242459                             aaa                      Five Stars   \n",
       "1244905  Kebideeeyeeeeeeehaaaaaaaa!!!!!  Kebideeeyeeeeeeehaaaaaaaa!!!!!   \n",
       "1249537                             aaa                      Five Stars   \n",
       "1276693                             aaa                      Five Stars   \n",
       "1294308                             aaa                      Four Stars   \n",
       "1300712                 Aaawe yeaaah...          Everything is awesome!   \n",
       "\n",
       "         unixReviewTime  num_words  \n",
       "78769        1484697600          1  \n",
       "93003        1518480000          1  \n",
       "93169        1518480000          1  \n",
       "93327        1518480000          1  \n",
       "93469        1438560000          2  \n",
       "106909       1464912000          1  \n",
       "107497       1444262400          1  \n",
       "188455       1474156800          1  \n",
       "228173       1464912000          1  \n",
       "275537       1488153600          1  \n",
       "450443       1415923200          1  \n",
       "460269       1486512000          1  \n",
       "465241       1439510400          1  \n",
       "478310       1454457600          1  \n",
       "600839       1491782400          1  \n",
       "635729       1520467200          1  \n",
       "684970       1413158400          1  \n",
       "741519       1501977600          1  \n",
       "742317       1501977600          1  \n",
       "748222       1428364800          1  \n",
       "751072       1453161600          1  \n",
       "827264       1416009600          1  \n",
       "827320       1416009600          1  \n",
       "854596       1416268800          1  \n",
       "883700       1409011200          2  \n",
       "885065       1464912000          1  \n",
       "929790       1501977600          1  \n",
       "930588       1501977600          1  \n",
       "936493       1428364800          1  \n",
       "939343       1453161600          1  \n",
       "1015535      1416009600          1  \n",
       "1015591      1416009600          1  \n",
       "1042867      1416268800          1  \n",
       "1071971      1409011200          2  \n",
       "1073336      1464912000          1  \n",
       "1095053      1488153600          1  \n",
       "1098196      1415923200          1  \n",
       "1099772      1488153600          1  \n",
       "1104928      1415923200          1  \n",
       "1127943      1415923200          1  \n",
       "1136667      1431129600          1  \n",
       "1146371      1461369600          1  \n",
       "1159314      1488153600          1  \n",
       "1183131      1478649600          1  \n",
       "1242459      1499990400          1  \n",
       "1244905      1478217600          1  \n",
       "1249537      1485129600          1  \n",
       "1276693      1408924800          1  \n",
       "1294308      1488153600          1  \n",
       "1300712      1424217600          2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_el = el[el['num_words'] < 4]\n",
    "tiny_el[tiny_el['reviewText'].str.contains('aaa')].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have a lot of values that just say \"aaa\" or \"t\" or the like. These could be the values for people who wrote what they wanted in the summary and didn't want to write an actual review, or they could be bots. Either way, these are probably reviews that should be excluded from training. However, how do we go about testing for other types of these words? We could compare against a corpus, but in that case we need to see in more detail how our spellchecker works (is there a point where it \"gives up\" and doesn't change the word?) We don't want all these aaaaa's just becoming \"a\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spellchecking and detecting gibberish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "el.to_csv('electronics_shortened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galla\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "el = pd.read_csv('electronics_shortened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6738237 entries, 0 to 6738236\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   Unnamed: 0      int64  \n",
      " 1   overall         float64\n",
      " 2   vote            object \n",
      " 3   verified        bool   \n",
      " 4   reviewTime      object \n",
      " 5   reviewerID      object \n",
      " 6   asin            object \n",
      " 7   reviewText      object \n",
      " 8   summary         object \n",
      " 9   unixReviewTime  int64  \n",
      " 10  num_words       int64  \n",
      "dtypes: bool(1), float64(1), int64(3), object(6)\n",
      "memory usage: 520.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall vote  verified   reviewTime      reviewerID  \\\n",
       "0           0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM   \n",
       "1           1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV   \n",
       "2           2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3   \n",
       "3           3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5   \n",
       "4           4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE   \n",
       "\n",
       "         asin                                         reviewText  \\\n",
       "0  0151004714  This is the best novel I have read in 2 or 3 y...   \n",
       "1  0151004714  Pages and pages of introspection, in the style...   \n",
       "2  0151004714  This is the kind of novel to read when you hav...   \n",
       "3  0151004714  What gorgeous language! What an incredible wri...   \n",
       "4  0151004714  I was taken in by reviews that compared this b...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     A star is born       937612800   \n",
       "1                    A stream of consciousness novel      1382486400   \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   \n",
       "3          The most beautiful book I have ever read!       968025600   \n",
       "4                        A dissenting view--In part.       949622400   \n",
       "\n",
       "   num_words  \n",
       "0        197  \n",
       "1         81  \n",
       "2        362  \n",
       "3        233  \n",
       "4        283  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el.info()\n",
    "el.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all is said and done, let's take another look at our class balance to see if we should still downsample our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='overall', ylabel='count'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(el['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    4322520\n",
       "4.0    1137229\n",
       "3.0     504712\n",
       "1.0     467117\n",
       "2.0     306659\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_counts = el_clean['overall'].value_counts()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the 5-class downsampler, though we will likely want to downsample separately for each target scheme we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a randomUnderSampler. Here we set the sampling strategy to downsample until #minority/#class = threshold\n",
    "# This should help us cut back a bit on removing potentially valuable information (and the distribution)\n",
    "# while also not affecting the non-5 classes much\n",
    "\n",
    "\n",
    "def define_sample_counts(rating_counts, threshold):\n",
    "    min_count = min(rating_counts)\n",
    "    sample_counts = rating_counts.copy()\n",
    "    #If class/min_count < threshold, we don't want to downsample (these classes are likely also pseudo minorities)\n",
    "    sample_counts['sample_target'] = rating_counts.apply(lambda x: int(min_count/threshold) if min_count/x < threshold else int(x))\n",
    "    \n",
    "    return sample_counts\n",
    "\n",
    "sample_counts = define_sample_counts(rating_counts, .5)\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy={1: sample_counts['sample_target'][1] , 2: sample_counts['sample_target'][2], 3: sample_counts['sample_target'][3], 4: sample_counts['sample_target'][4], 5: sample_counts['sample_target'][5]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4.0: 613318, 5.0: 613318, 3.0: 504712, 1.0: 467117, 2.0: 306659})\n"
     ]
    }
   ],
   "source": [
    "x = el_clean.drop(['overall', 'pos_neg', 'neutrality'], axis=1)\n",
    "y = el_clean['overall']\n",
    "\n",
    "x_under, y_under = under.fit_resample(x, y)\n",
    "print(Counter(y_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6738186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 21, 2018</td>\n",
       "      <td>AYTXY5M812ZL6</td>\n",
       "      <td>B01HBUHA6S</td>\n",
       "      <td>Sent it back...enough said</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1532131200</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1796377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 2, 2016</td>\n",
       "      <td>A1ITYGP3HOC9JD</td>\n",
       "      <td>B0049S6ZUS</td>\n",
       "      <td>it didn't work with Apple TV - returned it</td>\n",
       "      <td>didn't work with Apple TV</td>\n",
       "      <td>1480636800</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379541</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 24, 2009</td>\n",
       "      <td>A3M3N4GLK2Y8PG</td>\n",
       "      <td>B0023B14TU</td>\n",
       "      <td>My first camcorder had a battery life of minut...</td>\n",
       "      <td>Must be unlucky</td>\n",
       "      <td>1253750400</td>\n",
       "      <td>111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5582677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>09 12, 2017</td>\n",
       "      <td>A3J4FE8RJ60WFH</td>\n",
       "      <td>B015MPQQ0A</td>\n",
       "      <td>This keyboard was really good while it worked ...</td>\n",
       "      <td>BAD QC DONT BUY</td>\n",
       "      <td>1505174400</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3554074</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>04 10, 2017</td>\n",
       "      <td>A2KCWWV1YPNNJE</td>\n",
       "      <td>B00DYSKWEO</td>\n",
       "      <td>Okay, here's the deal.  I love this headset fo...</td>\n",
       "      <td>EXTREMELY cheap plastic</td>\n",
       "      <td>1491782400</td>\n",
       "      <td>655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0     6738186  NaN      True  07 21, 2018   AYTXY5M812ZL6  B01HBUHA6S   \n",
       "1     1796377  NaN      True   12 2, 2016  A1ITYGP3HOC9JD  B0049S6ZUS   \n",
       "2     1379541    5      True  09 24, 2009  A3M3N4GLK2Y8PG  B0023B14TU   \n",
       "3     5582677  NaN      True  09 12, 2017  A3J4FE8RJ60WFH  B015MPQQ0A   \n",
       "4     3554074    4      True  04 10, 2017  A2KCWWV1YPNNJE  B00DYSKWEO   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0                         Sent it back...enough said   \n",
       "1         it didn't work with Apple TV - returned it   \n",
       "2  My first camcorder had a battery life of minut...   \n",
       "3  This keyboard was really good while it worked ...   \n",
       "4  Okay, here's the deal.  I love this headset fo...   \n",
       "\n",
       "                     summary  unixReviewTime  num_words  overall  \n",
       "0                   One Star      1532131200          4      1.0  \n",
       "1  didn't work with Apple TV      1480636800          9      1.0  \n",
       "2            Must be unlucky      1253750400        111      1.0  \n",
       "3            BAD QC DONT BUY      1505174400         85      1.0  \n",
       "4    EXTREMELY cheap plastic      1491782400        655      1.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_downsampled = x_under.join(y_under)\n",
    "el_downsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_downsampled.to_csv('electronics_downsampled_5_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For positive/negative/neutral scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5459749\n",
       "negative     773776\n",
       "neutral      504712\n",
       "Name: pos_neg, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_counts = el_clean['pos_neg'].value_counts()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009424"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counts = define_sample_counts(rating_counts, .5)\n",
    "sample_counts['sample_target']['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 1009424, 'negative': 773776, 'neutral': 504712})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4288402</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>01 15, 2017</td>\n",
       "      <td>AD2IZQY0C25XM</td>\n",
       "      <td>B00K9SYPAE</td>\n",
       "      <td>Was really excited for this unit to take with ...</td>\n",
       "      <td>Beware, Lack of Q.C. !</td>\n",
       "      <td>1484438400</td>\n",
       "      <td>35</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6449861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 2, 2014</td>\n",
       "      <td>A2JE48R9QP7MLD</td>\n",
       "      <td>B00D40B0ES</td>\n",
       "      <td>This compact camera works great and is very in...</td>\n",
       "      <td>Not the best deal.....</td>\n",
       "      <td>1401667200</td>\n",
       "      <td>110</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2074387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A1QBQLW1ZO5NDX</td>\n",
       "      <td>B0054JE706</td>\n",
       "      <td>I purchased this with an iPad 4th Generation f...</td>\n",
       "      <td>DOES NOT WORK after 1 week</td>\n",
       "      <td>1356480000</td>\n",
       "      <td>192</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4541949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 18, 2015</td>\n",
       "      <td>AHIRI4VEJS8OT</td>\n",
       "      <td>B00MHIP94A</td>\n",
       "      <td>Not sure but whatever it's doing is not what w...</td>\n",
       "      <td>be sure your needs match its capabilites</td>\n",
       "      <td>1450396800</td>\n",
       "      <td>39</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>04 13, 2015</td>\n",
       "      <td>A3PQ7HUVTLH1EJ</td>\n",
       "      <td>B00A81SXHI</td>\n",
       "      <td>Update 10/17/2016: This thing has turned into ...</td>\n",
       "      <td>Garbage</td>\n",
       "      <td>1428883200</td>\n",
       "      <td>715</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0     4288402    2      True  01 15, 2017   AD2IZQY0C25XM  B00K9SYPAE   \n",
       "1     6449861  NaN      True   06 2, 2014  A2JE48R9QP7MLD  B00D40B0ES   \n",
       "2     2074387  NaN      True  12 26, 2012  A1QBQLW1ZO5NDX  B0054JE706   \n",
       "3     4541949  NaN      True  12 18, 2015   AHIRI4VEJS8OT  B00MHIP94A   \n",
       "4     3005594  NaN     False  04 13, 2015  A3PQ7HUVTLH1EJ  B00A81SXHI   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Was really excited for this unit to take with ...   \n",
       "1  This compact camera works great and is very in...   \n",
       "2  I purchased this with an iPad 4th Generation f...   \n",
       "3  Not sure but whatever it's doing is not what w...   \n",
       "4  Update 10/17/2016: This thing has turned into ...   \n",
       "\n",
       "                                    summary  unixReviewTime  num_words  \\\n",
       "0                    Beware, Lack of Q.C. !      1484438400         35   \n",
       "1                    Not the best deal.....      1401667200        110   \n",
       "2                DOES NOT WORK after 1 week      1356480000        192   \n",
       "3  be sure your needs match its capabilites      1450396800         39   \n",
       "4                                   Garbage      1428883200        715   \n",
       "\n",
       "    pos_neg  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "under_pn = RandomUnderSampler(sampling_strategy={'positive': sample_counts['sample_target']['positive'] , 'negative': sample_counts['sample_target']['negative'], 'neutral': sample_counts['sample_target']['neutral']})\n",
    "\n",
    "x = el_clean.drop(['overall', 'pos_neg', 'neutrality'], axis=1)\n",
    "y = el_clean['pos_neg']\n",
    "\n",
    "x_under, y_under = under_pn.fit_resample(x, y)\n",
    "print(Counter(y_under))\n",
    "\n",
    "el_downsampled_pn = x_under.join(y_under)\n",
    "el_downsampled_pn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_downsampled_pn.to_csv('electronics_downsampled_pos_neg_neutral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pos/Neg scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5459749\n",
       "negative     773776\n",
       "neutral      504712\n",
       "Name: pos_neg, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#drop all neutral items before downsampling\n",
    "drop_indices = el_clean[el_clean['pos_neg'] == 'neutral'].index\n",
    "el_posneg = el_clean.drop(drop_indices, inplace = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5459749\n",
       "negative     773776\n",
       "Name: pos_neg, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check no positive or negative recors were deleted\n",
    "rating_counts = el_posneg['pos_neg'].value_counts()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 1547552, 'negative': 773776})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>04 14, 2014</td>\n",
       "      <td>A3J3BRHTDRFJ2G</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>this remote   ,    for whatever reason   ,    ...</td>\n",
       "      <td>Ergonomic nightmare</td>\n",
       "      <td>1397433600</td>\n",
       "      <td>166</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11 11, 2016</td>\n",
       "      <td>A2OSUEZJIN7BI</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>i have an older url7 remote and thought this w...</td>\n",
       "      <td>Cannot Learn</td>\n",
       "      <td>1478822400</td>\n",
       "      <td>113</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 11, 2015</td>\n",
       "      <td>A2R9IT1MU2LOJW</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>volume buttons were dead on arrival   .    be ...</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1449792000</td>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>06 21, 2010</td>\n",
       "      <td>A2CPBQ5W4OGBX</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>my brother is a tracker and preorder this   . ...</td>\n",
       "      <td>New GPS doesn't work with new Windows 7</td>\n",
       "      <td>1277078400</td>\n",
       "      <td>259</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2016</td>\n",
       "      <td>AIS5NRQWZJCY0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>works great when i tape up  the plug to the po...</td>\n",
       "      <td>plug falls out</td>\n",
       "      <td>1454889600</td>\n",
       "      <td>26</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0          16   12     False  04 14, 2014  A3J3BRHTDRFJ2G  0511189877   \n",
       "1          18  NaN     False  11 11, 2016   A2OSUEZJIN7BI  0511189877   \n",
       "2          29  NaN      True  12 11, 2015  A2R9IT1MU2LOJW  0511189877   \n",
       "3          54   25     False  06 21, 2010   A2CPBQ5W4OGBX  0528881469   \n",
       "4          55  NaN      True   02 8, 2016   AIS5NRQWZJCY0  0528881469   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  this remote   ,    for whatever reason   ,    ...   \n",
       "1  i have an older url7 remote and thought this w...   \n",
       "2  volume buttons were dead on arrival   .    be ...   \n",
       "3  my brother is a tracker and preorder this   . ...   \n",
       "4  works great when i tape up  the plug to the po...   \n",
       "\n",
       "                                   summary  unixReviewTime  num_words  \\\n",
       "0                      Ergonomic nightmare      1397433600        166   \n",
       "1                             Cannot Learn      1478822400        113   \n",
       "2                                 One Star      1449792000         11   \n",
       "3  New GPS doesn't work with new Windows 7      1277078400        259   \n",
       "4                           plug falls out      1454889600         26   \n",
       "\n",
       "    pos_neg  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since this is now a binary classification problem we can just put in a float, \n",
    "#and the majority class is automatically chosen to be downsampled relative to the minority class\n",
    "under_pn = RandomUnderSampler(sampling_strategy= .5 )\n",
    "\n",
    "x = el_posneg.drop(['overall', 'pos_neg', 'neutrality'], axis=1)\n",
    "y = el_posneg['pos_neg']\n",
    "\n",
    "x_under, y_under = under_pn.fit_resample(x, y)\n",
    "print(Counter(y_under))\n",
    "\n",
    "el_downsampled_pn_bin = x_under.join(y_under)\n",
    "el_downsampled_pn_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_downsampled_pn_bin.to_csv('electronics_downsampled_pos_neg_binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neutrality scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extreme        4789637\n",
       "non_neutral    1443888\n",
       "neutral         504712\n",
       "Name: neutrality, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_counts = el_clean['neutrality'].value_counts()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'extreme': 1009424, 'non_neutral': 1009424, 'neutral': 504712})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_words</th>\n",
       "      <th>neutrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2262820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 8, 2014</td>\n",
       "      <td>AX1A5TGV29UP9</td>\n",
       "      <td>B005K96VE0</td>\n",
       "      <td>It's a cable. It has plugs on each end. Since ...</td>\n",
       "      <td>it either works or it doesn't</td>\n",
       "      <td>1417996800</td>\n",
       "      <td>50</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1582420</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11 27, 2014</td>\n",
       "      <td>A2FZMLW3K282X2</td>\n",
       "      <td>B003AIL2HE</td>\n",
       "      <td>I had the wonderful JVC HAFX67 air-fit earbuds...</td>\n",
       "      <td>Suitable replacement for the HAFX67</td>\n",
       "      <td>1417046400</td>\n",
       "      <td>142</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3149747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 7, 2015</td>\n",
       "      <td>A2GSSPC5WXFF3Y</td>\n",
       "      <td>B00B973X66</td>\n",
       "      <td>Does what it's meant to do. I bought it so i c...</td>\n",
       "      <td>Works Great!</td>\n",
       "      <td>1420588800</td>\n",
       "      <td>20</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>383548</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>01 27, 2015</td>\n",
       "      <td>A1KIC631L85FHO</td>\n",
       "      <td>B000ALLMI8</td>\n",
       "      <td>I love it, it can shoot telephoto, and it can ...</td>\n",
       "      <td>Great for telephoto and macro shots. Very vers...</td>\n",
       "      <td>1422316800</td>\n",
       "      <td>37</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5580724</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12 18, 2016</td>\n",
       "      <td>A20YR5KQN1DSUM</td>\n",
       "      <td>B015LZYGMG</td>\n",
       "      <td>I cant go back to plugging in headphones at th...</td>\n",
       "      <td>Absolutely recommend</td>\n",
       "      <td>1482019200</td>\n",
       "      <td>108</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0     2262820  NaN      True   12 8, 2014   AX1A5TGV29UP9  B005K96VE0   \n",
       "1     1582420    2      True  11 27, 2014  A2FZMLW3K282X2  B003AIL2HE   \n",
       "2     3149747  NaN      True   01 7, 2015  A2GSSPC5WXFF3Y  B00B973X66   \n",
       "3      383548    3      True  01 27, 2015  A1KIC631L85FHO  B000ALLMI8   \n",
       "4     5580724    2      True  12 18, 2016  A20YR5KQN1DSUM  B015LZYGMG   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  It's a cable. It has plugs on each end. Since ...   \n",
       "1  I had the wonderful JVC HAFX67 air-fit earbuds...   \n",
       "2  Does what it's meant to do. I bought it so i c...   \n",
       "3  I love it, it can shoot telephoto, and it can ...   \n",
       "4  I cant go back to plugging in headphones at th...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                      it either works or it doesn't      1417996800   \n",
       "1                Suitable replacement for the HAFX67      1417046400   \n",
       "2                                       Works Great!      1420588800   \n",
       "3  Great for telephoto and macro shots. Very vers...      1422316800   \n",
       "4                               Absolutely recommend      1482019200   \n",
       "\n",
       "   num_words neutrality  \n",
       "0         50    extreme  \n",
       "1        142    extreme  \n",
       "2         20    extreme  \n",
       "3         37    extreme  \n",
       "4        108    extreme  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counts = define_sample_counts(rating_counts, .5)\n",
    "\n",
    "under_neut = RandomUnderSampler(sampling_strategy={'non_neutral': sample_counts['sample_target']['non_neutral'] , 'extreme': sample_counts['sample_target']['extreme'], 'neutral': sample_counts['sample_target']['neutral']})\n",
    "\n",
    "x = el_clean.drop(['overall', 'pos_neg', 'neutrality'], axis=1)\n",
    "y = el_clean['neutrality']\n",
    "\n",
    "x_under, y_under = under_neut.fit_resample(x, y)\n",
    "print(Counter(y_under))\n",
    "\n",
    "el_downsampled_neut = x_under.join(y_under)\n",
    "el_downsampled_neut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_downsampled_neut.to_csv('electronics_downsampled_neutrality.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if we want to get really fancy we can try to use cluster-based downsampling, where the downsampled classes are split into clusters and downsampled evenly from them. Trouble is it's a bit harder to cluster text, we'd likely have to use paragraph2Vec style embedding which maybe is just not worth it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to do:\n",
    "\n",
    "create gibberish detector and run it over reviews with a few words to delete spam reviews\n",
    "\n",
    "(Maybe) correlate most frequent words with ratings to see if we see anything funny?\n",
    "\n",
    "### Other considerations:\n",
    "\n",
    "should we try normalizing review scores by user? Should we aggregate into binary labels?\n",
    "\n",
    "if we want to get really fancy we can try to use cluster-based downsampling, where the downsampled classes are split into clusters and downsampled evenly from them. Trouble is it's a bit harder to cluster text, we'd likely have to use paragraph2Vec style embedding which maybe is just not worth it\n",
    "\n",
    "Filtering by verified and/or helpfulness scores of review?\n",
    "\n",
    "Include review summary in our text? Will probably increase our accuracy a good deal, but might also not make sense for the problem if we are trying to just classify reviews. For instance, a lot of review summaries straight up say \"five stars\" which might be sort of cheating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target groupings\n",
    "\n",
    "5-class\n",
    "\n",
    "Binary positive/negative - 4-5 positive, 1-2 negative, exclude 3\n",
    "\n",
    "Binary neutral vs non-neutral- 1 and 5 neutral, 3 neutral\n",
    "\n",
    "3-class- 4-5 positive, 1-2 negative, 3 neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(el[el['num_words'] < 4]['reviewText'])\n",
    "\n",
    "from spell_check import fixSentence\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: fixSentence(x))\n",
    "\n",
    "print('CHECKPOINT: Spell Check Complete')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depth = [int(x) for x in np.linspace(10, 40, num = 5)]\n",
    "estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 5)]\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid = {'max_depth': depth, 'n_estimators': estimators}\n",
    "GS_object = GridSearchCV(estimator = rf, param_grid = grid)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df['reviewText'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_counts, df['overall'], test_size = 0.25, random_state = 5)\n",
    "\n",
    "GS_object.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "#train scores\n",
    "train_predicted = GS_object.predict(X_train)\n",
    "train_accuracy_score = metrics.accuracy_score(y_train, train_predicted)\n",
    "train_f1_score = metrics.f1_score(y_train, train_predicted, average = 'macro')\n",
    "print(str('{:04.2f}'.format(train_accuracy_score*100))+'%')\n",
    "print(train_f1_score)\n",
    "\n",
    "#test scores\n",
    "test_predicted = GS_object.predict(X_test)\n",
    "test_accuracy_score = metrics.accuracy_score(y_test, test_predicted)\n",
    "test_f1_score = metrics.f1_score(y_test, test_predicted, average = 'macro')\n",
    "print(str('{:04.2f}'.format(train_accuracy_score*100))+'%')\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8\n",
      "  Downloading gensim-3.8.0.tar.gz (23.4 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from gensim==3.8) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from gensim==3.8) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from gensim==3.8) (1.15.0)\n",
      "Collecting smart_open>=1.7.0\n",
      "  Downloading smart_open-5.0.0-py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-3.8.0-cp37-cp37m-win_amd64.whl size=23718069 sha256=3fd605a4f38e3afa821d19ec1fad2265ca2319fc3a20d1658a75236b0ef14de8\n",
      "  Stored in directory: c:\\users\\galla\\appdata\\local\\pip\\cache\\wheels\\97\\76\\35\\1143c6fcbd7bb620c7644e234180531956f17850e07557f18f\n",
      "Successfully built gensim\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.0 smart-open-5.0.0\n",
      "Collecting torchtext==0.4.0\n",
      "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\galla\\anaconda3\\lib\\site-packages (from torchtext==0.4.0) (4.48.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\galla\\anaconda3\\lib\\site-packages (from torchtext==0.4.0) (1.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\galla\\anaconda3\\lib\\site-packages (from torchtext==0.4.0) (2.24.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.8.1-cp37-cp37m-win_amd64.whl (190.5 MB)\n",
      "Requirement already satisfied: six in c:\\users\\galla\\anaconda3\\lib\\site-packages (from torchtext==0.4.0) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->torchtext==0.4.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->torchtext==0.4.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->torchtext==0.4.0) (1.25.10)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\galla\\anaconda3\\lib\\site-packages (from torch->torchtext==0.4.0) (3.7.4.3)\n",
      "Installing collected packages: torch, torchtext\n",
      "Successfully installed torch-1.8.1 torchtext-0.4.0\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.2.0\n",
      "Collecting d2l\n",
      "  Downloading d2l-0.16.2-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\galla\\anaconda3\\lib\\site-packages (from d2l) (1.19.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\galla\\anaconda3\\lib\\site-packages (from d2l) (1.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\galla\\anaconda3\\lib\\site-packages (from d2l) (3.3.1)\n",
      "Requirement already satisfied: jupyter in c:\\users\\galla\\anaconda3\\lib\\site-packages (from d2l) (1.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\galla\\anaconda3\\lib\\site-packages (from d2l) (2.24.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from pandas->d2l) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from pandas->d2l) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from matplotlib->d2l) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from matplotlib->d2l) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from matplotlib->d2l) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from matplotlib->d2l) (2020.12.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from matplotlib->d2l) (7.2.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (5.3.4)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (5.6.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (6.0.0)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (6.2.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (7.5.1)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter->d2l) (4.7.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->d2l) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->d2l) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from requests->d2l) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->d2l) (1.15.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->d2l) (7.18.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->d2l) (6.1.6)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->d2l) (6.0.4)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->d2l) (4.3.3)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (0.6.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (3.1.5)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (1.4.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (2.6.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (4.6.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (2.11.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (0.4.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (5.0.7)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l) (0.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l) (19.0.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\galla\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l) (0.8.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\galla\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\galla\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->d2l) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
      "Requirement already satisfied: qtpy in c:\\users\\galla\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->d2l) (1.9.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (0.17.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (49.6.0.post20200814)\n",
      "Requirement already satisfied: backcall in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (4.4.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\galla\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l) (0.4.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\galla\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\galla\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->d2l) (20.4)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert->jupyter->d2l) (227)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->jupyter->d2l) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->jupyter->d2l) (3.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\galla\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l) (0.7.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->d2l) (1.7.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->d2l) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->d2l) (20.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\galla\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->d2l) (3.1.0)\n",
      "Installing collected packages: d2l\n",
      "Successfully installed d2l-0.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8\n",
    "!pip install torchtext==0.4.0\n",
    "!pip install unidecode\n",
    "!pip install d2l\n",
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import string\n",
    "import unidecode\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "from IPython.display import Image, YouTubeVideo\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec_model(category = 'news', size = 50, sg = 1, min_count = 5):\n",
    "  try:\n",
    "    sentences = brown.sents(categories=brown.categories()) \n",
    "    model = Word2Vec(sentences, size=size, sg=sg, min_count=min_count)\n",
    "\n",
    "  except (AttributeError, TypeError):\n",
    "      raise AssertionError('Input variable \"category\" should be a string or list,' \n",
    "      '\"size\", \"sg\", \"min_count\" should be integers')\n",
    "\n",
    "  return model\n",
    "\n",
    "def model_dictionary(model):\n",
    "  words = list(w2vmodel.wv.vocab)\n",
    "  return words \n",
    "\n",
    "def get_embedding(word, model):\n",
    "  if word in w2vmodel.wv.vocab:\n",
    "    return model.wv[word]\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = create_word2vec_model(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "\n",
    "def load_dataset(sentence_length = 50):\n",
    "    TEXT = data.Field(sequential=True, tokenize=nltk.word_tokenize, lower=True,\n",
    "                      include_lengths=True, batch_first=True, fix_length=sentence_length)\n",
    "    LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "    train_data, test_data = el_clean.split(split_ratio = .7)\n",
    "\n",
    "    # If no specific vector embeddings are specified,\n",
    "    # Torchtext initializes random vector embeddings\n",
    "    # which would get updated during training through backpropagation.\n",
    "    \n",
    "    # Build the vocabulary indexes for our data\n",
    "    TEXT.build_vocab(train_data)\n",
    "    LABEL.build_vocab(train_data)\n",
    "    \n",
    "    #Create validation set\n",
    "    train_data, valid_data = train_data.split(split_ratio=0.7)\n",
    "    \n",
    "    #creates batches of \n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                                                                   batch_size=batch_size, sort_key=lambda x: len(x.text),\n",
    "                                                                   repeat=False, shuffle=True)\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT, vocab_size, train_iter, valid_iter, test_iter = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_iter, valid_iter, epochs, learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loss, validation_loss = [], []\n",
    "    train_acc, validation_acc = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      #train\n",
    "      model.train()\n",
    "      running_loss = 0.\n",
    "      correct, total = 0, 0 \n",
    "      steps = 0\n",
    "\n",
    "      for idx, batch in enumerate(train_iter):\n",
    "        text = batch.text[0]\n",
    "        # print(type(text), text.shape)\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        text, target = text.to(device), target.to(device)\n",
    "\n",
    "        # add micro for coding training loop\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text)\n",
    " \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        steps += 1\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # get accuracy \n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "      train_loss.append(running_loss/len(train_iter))\n",
    "      train_acc.append(correct/total)\n",
    "\n",
    "      print(f'Epoch: {epoch + 1},  Training Loss: {running_loss/len(train_iter):.4f}, Training Accuracy: {100*correct/total: .2f}%')\n",
    "\n",
    "      # evaluate on validation data\n",
    "      model.eval()\n",
    "      running_loss = 0.\n",
    "      correct, total = 0, 0 \n",
    "\n",
    "      with torch.no_grad():\n",
    "        for idx, batch in enumerate(valid_iter):\n",
    "            text = batch.text[0]\n",
    "            target = batch.label\n",
    "            target = torch.autograd.Variable(target).long()\n",
    "            text, target = text.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(text)\n",
    "    \n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # get accuracy \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "      validation_loss.append(running_loss/len(valid_iter))\n",
    "      validation_acc.append(correct/total)\n",
    "\n",
    "      print (f'Validation Loss: {running_loss/len(valid_iter):.4f}, Validation Accuracy: {100*correct/total: .2f}%')\n",
    "  \n",
    "    return train_loss, train_acc, validation_loss, validation_acc\n",
    "\n",
    "def test(model,  device, test_iter):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for idx, batch in enumerate(test_iter):\n",
    "        text = batch.text[0]\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        text, target = text.to(device), target.to(device)\n",
    "\n",
    "        outputs = model(text)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val(x, train, val, train_label, val_label, title):\n",
    "  with plt.xkcd():\n",
    "    plt.plot(x, train, label=train_label)\n",
    "    plt.plot(x, val, label=val_label)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def count_parameters(model):\n",
    "    parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return parameters\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.fc = nn.Linear(sum(num_channels), 2)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.convs = nn.ModuleList()\n",
    "        # This for loop adds the Conv1D layers to your network\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(embed_size, c, k))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # Concatenating the average-pooled outputs \n",
    "        encoding = torch.cat([\n",
    "            torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1)\n",
    "            for conv in self.convs], dim=1)\n",
    "        \n",
    "        outputs = self.fc(encoding)\n",
    "        return outputs\n",
    "\n",
    "# Uncomment to test\n",
    "sampleCNN = TextCNN(1000, 300, [1, 2, 3], [10, 20, 30])\n",
    "print(sampleCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "learning_rate = 0.00001\n",
    "embedding_length = 100\n",
    "kernel_sizes = [3, 4, 5]\n",
    "nums_channels = [100, 100, 100]\n",
    "epochs = 10\n",
    "\n",
    "# Initialize model, training and testing\n",
    "cnn_model = TextCNN(vocab_size, embedding_length, kernel_sizes, nums_channels)\n",
    "cnn_model.to(device)\n",
    "cnn_model.apply(init_weights)\n",
    "cnn_start_time = time.time()\n",
    "cnn_train_loss, cnn_train_acc, cnn_validation_loss, cnn_validation_acc = train(cnn_model, device, train_iter, valid_iter, epochs, learning_rate)\n",
    "print(\"--- Time taken to train = %s seconds ---\" % (time.time() - cnn_start_time))\n",
    "test_accuracy = test(cnn_model, device, test_iter)\n",
    "print('Test Accuracy: ',  test_accuracy, '%')\n",
    "\n",
    "# Plot accuracies\n",
    "plot_train_val(np.arange(0,epochs), cnn_train_acc, cnn_validation_acc, 'training_accuracy', 'validation_accuracy', 'CNN on IMDB text classification')\n",
    "\n",
    "# Number of parameters in model\n",
    "paramters = count_parameters(cnn_model)\n",
    "print('\\n\\nNumber of parameters = ',  paramters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galla\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#el = pd.read_csv(\"electronics_downsampled_5_class.csv\")\n",
    "el_bin = pd.read_csv(\"electronics_downsampled_pos_neg_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bin['pos_neg'] = el_bin['pos_neg'].apply(lambda x: 1 if x == 'positive' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this remote   ,    for whatever reason   ,    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have an older url7 remote and thought this w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume buttons were dead on arrival   .    be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my brother is a tracker and preorder this   . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>works great when i tape up  the plug to the po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  pos_neg\n",
       "0  this remote   ,    for whatever reason   ,    ...        0\n",
       "1  i have an older url7 remote and thought this w...        0\n",
       "2  volume buttons were dead on arrival   .    be ...        0\n",
       "3  my brother is a tracker and preorder this   . ...        0\n",
       "4  works great when i tape up  the plug to the po...        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_bin = el_bin[['reviewText', 'pos_neg']]\n",
    "el_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bin.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el_bin['reviewText'] = el_bin['reviewText'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this remote   ,    for whatever reason   ,    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have an older url7 remote and thought this w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume buttons were dead on arrival   .    be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my brother is a tracker and preorder this   . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>works great when i tape up  the plug to the po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  pos_neg\n",
       "0  this remote   ,    for whatever reason   ,    ...        0\n",
       "1  i have an older url7 remote and thought this w...        0\n",
       "2  volume buttons were dead on arrival   .    be ...        0\n",
       "3  my brother is a tracker and preorder this   . ...        0\n",
       "4  works great when i tape up  the plug to the po...        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "el_bin['reviewText'] = el_bin['reviewText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this remote    ,     for whatever reason    , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have an older url7 remote and thought this w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume buttons were dead on arrival    .     b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my brother is a tracker and preorder this    ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>works great when i tape up  the plug to the po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  pos_neg\n",
       "0  this remote    ,     for whatever reason    , ...        0\n",
       "1  i have an older url7 remote and thought this w...        0\n",
       "2  volume buttons were dead on arrival    .     b...        0\n",
       "3  my brother is a tracker and preorder this    ....        0\n",
       "4  works great when i tape up  the plug to the po...        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(el_bin['pos_neg'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bin2 = el_bin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bin['pos_neg'] = el_bin['pos_neg'].apply(lambda x: np.float16(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1469355</th>\n",
       "      <td>exactly what i expected .  ipad cases are hard...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452168</th>\n",
       "      <td>did not work great for me .</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494877</th>\n",
       "      <td>i would not recommend this product due to coup...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936223</th>\n",
       "      <td>i am glad that i bought this for my expensive ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113044</th>\n",
       "      <td>woeks as it should</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviewText  pos_neg\n",
       "1469355  exactly what i expected .  ipad cases are hard...      1.0\n",
       "452168                      did not work great for me .         0.0\n",
       "494877   i would not recommend this product due to coup...      0.0\n",
       "936223   i am glad that i bought this for my expensive ...      1.0\n",
       "1113044                                 woeks as it should      1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(el_bin, test_size = 0.2)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bc6c6b9037d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mel_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mel_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "el_tensor = torch.tensor(el_bin.values)\n",
    "train_data, test_data = el_tensor.split(split_ratio=0.8)\n",
    "el_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_text = el_bin['reviewText'].to_numpy()\n",
    "el_labels = el_bin['pos_neg'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-870fa34d956d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "el_data = TensorDataset(torch.from_numpy(el_text), torch.from_numpy(el_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-98be63ebaaae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#el_bin = el_bin.to_numpy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mel_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mel_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "\n",
    "el_tensor = torch.from_numpy(el_bin)\n",
    "train_data, test_data = el_tensor.split(split_ratio=0.8)\n",
    "el_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-4c8a00e4e03d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mel_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mel_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'overall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mel_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-154-4c8a00e4e03d>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mfiltered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-154-4c8a00e4e03d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mfiltered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "def tokenize(sentence):\n",
    "  tokens = token.tokenize(sentence)\n",
    "  filtered = [x for x in tokens]\n",
    "  return filtered\n",
    "\n",
    "el_bin['tokenized'] = el_bin['reviewText'].apply(tokenize)\n",
    "el_bin = el_bin[['tokenized', 'overall']]\n",
    "el_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "#from nltk.tokenize import word_tokenize\n",
    "token = RegexpTokenizer(r\"[a-zA-Z0-9.,;!?]+\")\n",
    "\n",
    "#token = WordPunctTokenizer()\n",
    "#token = WhitespaceTokenizer()\n",
    "#token = StringTokenizer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return token.tokenize(sentence)\n",
    "\n",
    "\n",
    "\n",
    "el_bin['tokenized'] = el_bin['reviewText'].apply(lambda x: token.tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[this, remote, ,, for, whatever, reason, ,, wa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, have, an, older, url7, remote, and, though...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[volume, buttons, were, dead, on, arrival, ., ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[my, brother, is, a, tracker, and, preorder, t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[works, great, when, i, tape, up, the, plug, t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tokenized  pos_neg\n",
       "0  [this, remote, ,, for, whatever, reason, ,, wa...      0.0\n",
       "1  [i, have, an, older, url7, remote, and, though...      0.0\n",
       "2  [volume, buttons, were, dead, on, arrival, ., ...      0.0\n",
       "3  [my, brother, is, a, tracker, and, preorder, t...      0.0\n",
       "4  [works, great, when, i, tape, up, the, plug, t...      0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_bin = el_bin[['tokenized', 'pos_neg']]\n",
    "el_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Could not reserve memory block",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-547d8f410d21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_json_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'elec_bin_train.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_json_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m   2303\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2304\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2305\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2306\u001b[0m         )\n\u001b[0;32m   2307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdefault_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     ).write()\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iso\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         )\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, obj, orient, double_precision, ensure_ascii, date_unit, iso_dates, default_handler, indent)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0miso_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, obj, orient, double_precision, ensure_ascii, date_unit, iso_dates, default_handler, indent)\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0miso_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miso_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mdefault_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         )\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Could not reserve memory block"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(el_bin, test_size = 0.2, random_state = 42)\n",
    "train_json = train_df.to_json(orient = 'records')\n",
    "train_json_result = json.loads(train_json)\n",
    "with open('elec_bin_train.json', 'w') as f:\n",
    "    for entry in train_json_result:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(el_bin, test_size = 0.2, random_state = 42)\n",
    "train_df.to_csv('el_bin_train.csv')\n",
    "test_df.to_csv('el_bin_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bin.to_csv('electronics_pn_binary_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Could not reserve memory block",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8d5babe67cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_json_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'elec_bin_test.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_json_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m   2303\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2304\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2305\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2306\u001b[0m         )\n\u001b[0;32m   2307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdefault_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     ).write()\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iso\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         )\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, obj, orient, double_precision, ensure_ascii, date_unit, iso_dates, default_handler, indent)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0miso_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, obj, orient, double_precision, ensure_ascii, date_unit, iso_dates, default_handler, indent)\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0miso_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miso_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mdefault_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         )\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Could not reserve memory block"
     ]
    }
   ],
   "source": [
    "test_json = test_df.to_json(orient = 'records')\n",
    "test_json_result = json.loads(test_json)\n",
    "with open('elec_bin_test.json', 'w') as f:\n",
    "    for entry in test_json_result:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "TOKENS = data.Field(tokenize = nltk.word_tokenize,\n",
    "                      include_lengths = True, batch_first = True)\n",
    "SCORE = data.LabelField(dtype = torch.float)\n",
    "\n",
    "fields = {'reviewText': ('tokens', TOKENS), 'pos_neg': ('score', SCORE)}\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "    path = '',\n",
    "    train = 'el_bin_train.json',\n",
    "    test = 'el_bin_test.json',\n",
    "    format = 'json',\n",
    "    fields = fields\n",
    ")\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-dbea7cef1ee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mskip_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m---> 78\u001b[1;33m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[0;32m     79\u001b[0m         val_data = None if validation is None else cls(\n\u001b[0;32m     80\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, format, fields, skip_header, csv_reader_params, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\utils.py\u001b[0m in \u001b[0;36municode_csv_reader\u001b[1;34m(unicode_csv_data, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mmaxInt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxInt\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfield_size_limit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "TEXT = data.Field(tokenize = nltk.word_tokenize, include_lengths = True, batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "fields = [('reviewText', TEXT), ('pos_neg'), LABEL]\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "    path = '',\n",
    "    train = 'el_bin_train.csv',\n",
    "    test = 'el_bin_test.csv',\n",
    "    format = 'csv',\n",
    "    skip_header = False,\n",
    "    fields = fields\n",
    ")\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9f419ba94bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def dynamic_pad(batch, vocab):\n",
    "    pad_idx = vocab.stoi['<pad>']\n",
    "        for idx, ex in enumerate(batch):\n",
    "            if len(ex) < min_length:\n",
    "                batch[idx] = ex + [pad_idx] * (min_length - len(ex))\n",
    "        return batch'''\n",
    "    \n",
    "def dynamic_pad(batch):\n",
    "    size = len(batch[0])\n",
    "    #get the lengths of the token lists in the batch\n",
    "    lens = []\n",
    "    for item in batch['':\n",
    "        \n",
    "    # Just to make the function more robust, we allow it to handle data that hasn't been separated from the label\n",
    "    if size == 3:\n",
    "        texts, lens, y = zip(*batch)\n",
    "    else:\n",
    "        texts, lens = zip(*batch)\n",
    "    lens = np.array(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_dataset(dataset):\n",
    "    TEXT = data.Field(tokenize = nltk.word_tokenize,\n",
    "                      include_lengths = True, batch_first = True)\n",
    "    LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "    fields = {'reviewText': ('text', TEXT), 'pos_neg': ('label', LABEL)}\n",
    "    train_data, test_data = data.TabularDataset.splits(\n",
    "        path = '',\n",
    "        train = 'el_bin_train.json',\n",
    "        test = 'el_bin_test.json',\n",
    "        format = 'json',\n",
    "        fields = fields\n",
    "    )\n",
    "    \n",
    "    #dataset = dataset.to_numpy()\n",
    "    \n",
    "    #train_data, test_data = train_test_split(dataset, test_size = 0.2, random_state =42)\n",
    "    \n",
    "\n",
    "    TEXT.build_vocab(train_data, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "    LABEL.build_vocab(train_data)\n",
    "\n",
    "    #train_data, valid_data = train_data.split(split_ratio=0.8, random_state = random.seed(seed))\n",
    "    train_data, valid_data = train_test_split(train_data, test_size = 0.2)\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                                                                   batch_size=batch_size, sort_key=lambda x: len(x.text),\n",
    "                                                                   repeat=False, shuffle=True)\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-a917edb805b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-176-f2badca6ea34>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"glove.6B.100d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munk_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mLABEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[0;32m    308\u001b[0m             if tok is not None))\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# sort by frequency, then alphabetically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mwords_and_frequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mwords_and_frequencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "TEXT, vocab_size, train_iter, valid_iter, test_iter = load_dataset(el_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_dict(arr, dictionary):\n",
    "  text = []\n",
    "  for element in arr:\n",
    "    text.append(dictionary[element])\n",
    "  return text\n",
    "\n",
    "for idx, batch in enumerate(train_iter):\n",
    "    text = batch.text[0]\n",
    "    target = batch.label\n",
    "\n",
    "    for itr in range(25,30):\n",
    "      print('Review: ', ' '.join(text_from_dict(text[itr], TEXT.vocab.itos)))\n",
    "      print('Label: ', int(target[itr].item()), '\\n')\n",
    "   \n",
    "    print('[0: Negative Review, 1: Positive Review]')\n",
    "    if idx==0:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (word_embeddings): Embedding(1000, 300)\n",
      "  (rnn): RNN(300, 50, num_layers=2)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "  def __init__(self, output_size, hidden_size, vocab_size, embed_size):\n",
    "    super(VanillaRNN, self).__init__()\n",
    "\n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.word_embeddings = nn.Embedding(vocab_size, embed_size)\n",
    "    self.rnn = nn.RNN(embed_size, hidden_size, num_layers=2)\n",
    "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    input = self.word_embeddings(inputs)\n",
    "    input = input.permute(1, 0, 2)\n",
    "    h_0 =  Variable(torch.zeros(2, input.size()[1], self.hidden_size).to(device)) \n",
    "    output, h_n = self.rnn(input, h_0)\n",
    "    h_n = h_n.permute(1, 0, 2) \n",
    "    h_n = h_n.contiguous().view(h_n.size()[0], h_n.size()[1]*h_n.size()[2])\n",
    "    logits = self.fc(h_n)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "# Uncomment to test\n",
    "sampleRNN = VanillaRNN(10, 50, 1000, 300)\n",
    "print(sampleRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "  def __init__(self, output_size, hidden_size, vocab_size, embed_size):\n",
    "    super(VanillaRNN, self).__init__()\n",
    "\n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.word_embeddings = nn.Embedding(vocab_size, embed_size)\n",
    "    self.rnn = nn.GRU(embed_size, hidden_size, num_layers=2)\n",
    "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    input = self.word_embeddings(inputs)\n",
    "    input = input.permute(1, 0, 2)\n",
    "    h_0 =  Variable(torch.zeros(2, input.size()[1], self.hidden_size).to(device)) \n",
    "    output, h_n = self.rnn(input, h_0)\n",
    "    h_n = h_n.permute(1, 0, 2) \n",
    "    h_n = h_n.contiguous().view(h_n.size()[0], h_n.size()[1]*h_n.size()[2])\n",
    "    logits = self.fc(h_n)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "# Uncomment to test\n",
    "sampleRNN = VanillaRNN(10, 50, 1000, 300)\n",
    "print(sampleRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparamters\n",
    "learning_rate = 0.0002\n",
    "output_size = 2\n",
    "hidden_size = 100 \n",
    "embedding_length = 100\n",
    "epochs = 10\n",
    "\n",
    "# Initialize model, training and testing\n",
    "vanilla_rnn_model = VanillaRNN(output_size, hidden_size, vocab_size, embedding_length)\n",
    "vanilla_rnn_model.to(device)\n",
    "vanilla_rnn_start_time = time.time()\n",
    "vanilla_train_loss, vanilla_train_acc, vanilla_validation_loss, vanilla_validation_acc = train(vanilla_rnn_model, device, train_iter, valid_iter, epochs, learning_rate)\n",
    "print(\"--- Time taken to train = %s seconds ---\" % (time.time() - vanilla_rnn_start_time))\n",
    "test_accuracy = test(vanilla_rnn_model, device, test_iter)\n",
    "print('Test Accuracy: ',  test_accuracy, '%')\n",
    "\n",
    "# Plot accuracy curves\n",
    "plot_train_val(np.arange(0,epochs), vanilla_train_acc, vanilla_validation_acc,\n",
    "               'training_accuracy', 'validation_accuracy', 'Vanilla RNN on IMDB text classification')\n",
    "\n",
    "# Number of model parameters\n",
    "paramters = count_parameters(vanilla_rnn_model)\n",
    "print('\\n\\nNumber of parameters = ',  paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Set `bidirectional` to True to get a bidirectional recurrent neural\n",
    "        # network\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers,\n",
    "                               bidirectional=True)\n",
    "        self.decoder = nn.Linear(4 * num_hiddens, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The shape of `inputs` is (batch size, no. of words). Because LSTM\n",
    "        # needs to use sequence as the first dimension, the input is\n",
    "        # transformed and the word feature is then extracted. The output shape\n",
    "        # is (no. of words, batch size, word vector dimension).\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        # Since the input (embeddings) is the only argument passed into\n",
    "        # nn.LSTM, both h_0 and c_0 default to zero.\n",
    "        # we only use the hidden states of the last hidden layer\n",
    "        # at different time step (outputs). The shape of `outputs` is\n",
    "        # (no. of words, batch size, 2 * no. of hidden units).\n",
    "        self.encoder.flatten_parameters()\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        # Concatenate the hidden states of the initial time step and final\n",
    "        # time step to use as the input of the fully connected layer. Its\n",
    "        # shape is (batch size, 4 * no. of hidden units)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, devices = 100, 100, 2, d2l.try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "net.apply(init_weights);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
