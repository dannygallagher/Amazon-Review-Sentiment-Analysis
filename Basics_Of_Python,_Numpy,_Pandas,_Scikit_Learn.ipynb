{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics Of Python, Numpy, Pandas, Scikit-Learn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wtmBPJKe5Rhu",
        "bxfiAvCO5Rhv",
        "KOgvCRsQ5Rhw",
        "sy_7zIdh5Rhx",
        "P-5PaQUH5Rhy",
        "TTK1JCR_5Rhy",
        "Ruo9xRq75Rhz",
        "z6ZtNRHO5Rh0",
        "vDAIm0Um5Rh1",
        "JCJYG1h55Rh2",
        "s7MNALHP5Rh4",
        "S7F6krwQ5Rh5",
        "0kUKV9HP5Rh6",
        "0FiAL5If3Wtx",
        "uQUIxvJb3Wty",
        "wUU-zkPu3Wuk",
        "y6B6PGPK3WvD",
        "OLEPQnnC3WvJ",
        "Fh7Flpcx3WvU",
        "r8Hutjj33Wv7",
        "DJQGn_eV3WwA",
        "rHZN9Wj63WwJ",
        "CFo0Wrqm3WwJ",
        "WpyIS_Bn3Wwb",
        "fTEpNhD13Wwt",
        "8lxbwUHH3WxX",
        "HiQmv6HV3Wx0",
        "pCaIJQ6R3Wyc",
        "TzhoCk0C3Wyk",
        "UdRyKR44dcNI"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sUjXNQy5Rho"
      },
      "source": [
        "# **CIS 419/519 Fall 2021, Week 1**\n",
        "## Worksheet - Introduction to Python (and useful packages), and Colab\n",
        "---\n",
        "In this first section, we cover the following:\n",
        "\n",
        "*   Python/Jupyter Installation Instructions (if not using in Colab)\n",
        "*   Basics of Python/Jupyter notebooks\n",
        "*   Useful packages like `random`, `numpy` and `sklearn`, along with exercises\n",
        "\n",
        "In the second section, we introduce Google Colab.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYAuhATVqz8y"
      },
      "source": [
        "### Python/Jupyter Installation Instructions\n",
        "First, make sure you have python3 (version 3.7 is the latest) installed on your local machine.\n",
        "We recommend managing your python installation with Anaconda.\n",
        "The Anaconda website has instructions for how to install python based on your operating system:\n",
        "- https://www.anaconda.com/download/\n",
        "\n",
        "Second, make sure that you have Jupyter notebooks installed.\n",
        "It may have already come with your Anaconda installation.\n",
        "If not, the Jupyter website has installation instructions:\n",
        "- http://jupyter.org/install\n",
        "\n",
        "If you have never used python or Jupyter notebooks before, we recommend bookmarking these resources:\n",
        "- Python: https://developers.google.com/edu/python/\n",
        "- Jupyter: https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\n",
        "\n",
        "Be aware that the Google tutorial uses python2, so some of their example code may not directly work in python3:\n",
        "- Print statements now require parentheses: `print x` now becomes `print(x)`\n",
        "- No longer need to specify file encoding: `open('file.txt', 'r')` works\n",
        "- The division operator `/` no longer does integer divison: `5 / 2` is `2.5`\n",
        "- The `xrange` operator is now only `range`\n",
        "\n",
        "Other differences can be found on the web: https://www.geeksforgeeks.org/important-differences-between-python-2-x-and-python-3-x-with-examples/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H9Ufiyi5Rhs"
      },
      "source": [
        "## About Python\n",
        "Python is a programming language that is very popular among the machine learning research community.\n",
        "It is a higher-level programming language than Java, and has an extensive collection of libraries that can be easily installed.\n",
        "We require that you use python for this class, so it is important to be familiar with it.\n",
        "\n",
        "### Python vs Java\n",
        "- Java is compiled, but Python is not: you directly run the Python file\n",
        "- Java is statically typed (the types of the variables cannot change), and you do not declare types in Python\n",
        "```\n",
        "# This works in python\n",
        "x = 3\n",
        "x = \"python\"\n",
        "```\n",
        "- Instantiating a class in Python does not use `new`\n",
        "```\n",
        "# Assume there is a class called `Person`\n",
        "p = Person('Emily', 25)\n",
        "```\n",
        "- Python does not use parentheses, like Java. Instead, it uses whitespace to infer the scope of methods, for loops, etc.\n",
        "```\n",
        "for i in range(10):\n",
        "      print(i * 2)      # Indent by 4 spaces\n",
        "      print(i * 4)\n",
        "print('Done')       # No indent, runs after for loop\n",
        "```\n",
        "- Functions cannot be overloaded, instead use optional arguments\n",
        "```\n",
        "def f(x, y=0.0):\n",
        "      ....\n",
        "f(8)\n",
        "f(8, 2)\n",
        "```\n",
        "- Boolean values are now `True` and `False`\n",
        "\n",
        "### Python vs Matlab\n",
        "- Python uses hard brackets `[]` for indexing arrays and matrices instead of `()` in Matlab\n",
        "- Python is 0-indexed, so the first item in a list is at index 0, not 1\n",
        "- Python doesn't come by default with a full development tool, like Matlab\n",
        "- The `numpy` library in Python implements many of the same matrix functionality that Matlab has\n",
        "\n",
        "### Development Environments\n",
        "- In this class we will use Jupyter Notebooks, which is one of many ways you can write python code. We feel that Jupyter Notebooks are a simple, but effective tool.\n",
        "- Other options include:\n",
        "  - Text editors: Atom, Sublime\n",
        "  - PyCharm: https://www.jetbrains.com/pycharm/\n",
        "  - Google Collaboratory: https://colab.research.google.com/ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFCHtVH35Rht"
      },
      "source": [
        "## Jupyter Notebooks\n",
        "When you start a Jupyter Notebook, you are starting a server on your local machine that hosts the notebooks.\n",
        "```\n",
        "> jupyter notebook\n",
        "```\n",
        "Once the server has started, open up a web browser and go to http://localhost:8888.\n",
        "You should see a file tree, which you can use to navigate to where you want to save your Jupyter Notebook.\n",
        "\n",
        "Jupyter Notebooks allow you to interactively develop python code.\n",
        "Cells have types, either markdown (https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) or python code.\n",
        "You can write as much code in a cell as you need.\n",
        "When you want to execute it, enter shift+enter.\n",
        "Anything displayed by your program will be written below the cell.\n",
        "Variables that are defined within an executed cell are saved in memory and can be used later (similar behavior in Matlab).\n",
        "It's similar to if you could pause the program execution.\n",
        "Code within other cells can reference any cell _which has already been executed_.\n",
        "If you have already run a cell and you edit its code, the cell needs to be rerun in order for your changes to take effect.\n",
        "\n",
        "If you close the Jupyter Notebook, you will need to rerun all of the cells from scratch so the variables and methods will be redefined. **Make sure you save before you close the notebook!**\n",
        "\n",
        "### Submitting assignments\n",
        "Your Jupyter Notebook can be downloaded as a python file that can be run under File -> Download -> Python .py.\n",
        "You should turn in this python file and **not** the `.ipynb` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtmBPJKe5Rhu"
      },
      "source": [
        "### Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_9b2Lq5Rhu"
      },
      "source": [
        "# Assigning variables\n",
        "x = 4.2\n",
        "y = 8\n",
        "s = 'hello'\n",
        "\n",
        "# The types of variables can change without a problem\n",
        "y = 'abc'\n",
        "\n",
        "# To display variables, use the print function\n",
        "print(y)\n",
        "\n",
        "# The \"null\" type is called `None`\n",
        "z = None\n",
        "print(z)\n",
        "\n",
        "print(z == None)\n",
        "\n",
        "# Casting\n",
        "s = '140'\n",
        "print(int(s))\n",
        "s = '140.243'\n",
        "print(float(s))\n",
        "x = 123\n",
        "print(str(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxfiAvCO5Rhv"
      },
      "source": [
        "### String Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPlNYAhk5Rhv"
      },
      "source": [
        "s = \"ABCdef\"\n",
        "s = 'ABCdef'\n",
        "\n",
        "# Length\n",
        "print(len(s))  # 6\n",
        "\n",
        "# Standard Indexing: Notice hard brackets and 0-indexing\n",
        "print(s[0])      # 'A'\n",
        "print(s[1])      # 'B'\n",
        "print(s[5])      # 'f'\n",
        "# print(s[100])  # Error\n",
        "\n",
        "# Range Indexing\n",
        "print(s[1:4])    # 'BCd'\n",
        "print(s[2:])     # 'Cdef'\n",
        "print(s[:2])     # 'AB'\n",
        "print(s[1:100])  # 'BCdef'\n",
        "\n",
        "# Negative Indexing\n",
        "print(s[-1])    # 'f'\n",
        "print(s[-2])    # 'e'\n",
        "print(s[:-1])   # 'ABCde'\n",
        "print(s[:-3])   # 'ABC'\n",
        "print(s[::-1])  # 'fedCBA'\n",
        "\n",
        "# Concatenation\n",
        "print(s + 'xyz')     # 'ABCdefxyz'\n",
        "# print(s + 123)     # Error\n",
        "print(s + str(123))  # 'ABCdef123'\n",
        "\n",
        "# Splitting\n",
        "print(s.split('C'))  # ['AB', 'def']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOgvCRsQ5Rhw"
      },
      "source": [
        "### Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbvPeBcJ5Rhw"
      },
      "source": [
        "a = [0, 4, 2, 8, 9]  # Create a list with initial items\n",
        "b = []  # Create an empty list\n",
        "\n",
        "# Length\n",
        "print(len(a))  # 5\n",
        "\n",
        "# The same indexing operations on strings work for lists\n",
        "print(a[1])    # 4\n",
        "print(a[2:4])  # [2, 8]\n",
        "print(a[-2])   # 8\n",
        "\n",
        "# Sort the list\n",
        "print(sorted(a))                # [0, 2, 4, 8, 9] Creates a copy, does not modify the original list\n",
        "print(sorted(a, reverse=True))  # [9, 8, 4, 2, 0] Also a copy\n",
        "\n",
        "# Add items to the end of the list\n",
        "a.append(10)  # Returns nothing\n",
        "print(a)      # [0, 4, 2, 8, 9, 10] \n",
        "a += [1, 12]  # Returns nothing\n",
        "print(a)      # [0, 4, 2, 8, 9, 10, 1, 12]\n",
        "\n",
        "# Lists don't have to be the same type in python\n",
        "a.append('machine learning')\n",
        "print(a)            # [0, 4, 2, 8, 9, 10, 1, 12, 'machine learning']\n",
        "# print(sorted(a))  # Causes an error\n",
        "\n",
        "# Searching\n",
        "print(8 in a)    # True\n",
        "print(100 in a)  # False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy_7zIdh5Rhx"
      },
      "source": [
        "## Dictionaries\n",
        "https://developers.google.com/edu/python/dict-files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuIaOXtz5Rhx"
      },
      "source": [
        "d = {}       # Create an empty dictionary, which is a key-value map\n",
        "d['a'] = 97  # Add an item to the dictionary\n",
        "print(d)     # {'a': 97}\n",
        "print(d['a'])\n",
        "\n",
        "d['c'] = 99\n",
        "d[0] = [0, 1, 2]  # Keys and values don't need to be the same type\n",
        "print(d)          # {'a': 97, 'c': 99, 0: [0, 1, 2]}\n",
        "\n",
        "# Retrieve the keys and values of the dictionary.\n",
        "# These are not actually lists, but look like it. Call list(d.keys()) to actually convert it to a list\n",
        "keys = d.keys()      # Retrieve a list of the keys of the dictionary, not necessarily in any order\n",
        "values = d.values()  # Retrieve a list of the values of the dictionary, not necessarily in any order\n",
        "print(keys)          # ['a', 'c', 0]\n",
        "print(values)        # [97, 99, [0, 1, 2]]\n",
        "\n",
        "# Check to see if items are in the dictionary (checks keys)\n",
        "print('a' in d)  # True\n",
        "print('x' in d)  # False\n",
        "\n",
        "# Remove an item from the list\n",
        "del d['a']    # Returns nothing, modifies inplace\n",
        "# del d['y']  # Error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-5PaQUH5Rhy"
      },
      "source": [
        "## If Statements\n",
        "Covered in the strings section: https://developers.google.com/edu/python/strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4rD_9D5Rhy"
      },
      "source": [
        "# Python doesn't require parenthese\n",
        "a, b = 7, 10\n",
        "\n",
        "# equality\n",
        "if a == 7:\n",
        "    print('yes')\n",
        "else:\n",
        "    print('no')\n",
        "    \n",
        "# not equal\n",
        "if a != 8:\n",
        "    print('neq')\n",
        "    \n",
        "# and\n",
        "if a > 5 and b <= 10:\n",
        "    print('1')\n",
        "elif a > 10:\n",
        "    print('2')\n",
        "else:\n",
        "    print('3')\n",
        "\n",
        "# or\n",
        "if a < 10 or b > 100:\n",
        "    print('yes')\n",
        "    \n",
        "# Strings also use '=='\n",
        "s = 'abc'\n",
        "if s == 'abc':\n",
        "    print('here')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTK1JCR_5Rhy"
      },
      "source": [
        "## For Loops\n",
        "Covered under lists: https://developers.google.com/edu/python/lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bmH3pQm5Rhz"
      },
      "source": [
        "a = [0, 8, 3, 5, 1]\n",
        "\n",
        "range(5)     # Dynamically generates 0, 1, 2, 3, 4\n",
        "range(1, 5)  # 1, 2, 3, 4\n",
        "\n",
        "# \"Standard\" for loop from Java\n",
        "for i in range(len(a)):\n",
        "    print(a[i])\n",
        "\n",
        "# Iterate over each element in the list\n",
        "for x in a:\n",
        "    print(x)\n",
        "    \n",
        "# Iterating through dictionaries\n",
        "d = {0: 'a', 1: 'b', 2: 'c'}\n",
        "for key, value in d.items():\n",
        "    print(str(key) + ' -> ' + value)\n",
        "    \n",
        "    \n",
        "# Loop over items in an array and get the index at the same time\n",
        "for index, item in enumerate(a):\n",
        "  print(index, item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruo9xRq75Rhz"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVr7wLj5Rhz"
      },
      "source": [
        "# No return type specification necessary\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "\n",
        "def concat(list_1, list_2):\n",
        "    list_1 += list_2\n",
        "\n",
        "print(add(3, 4))        # 7\n",
        "# print(add(4, 8, 10))  # Error\n",
        "\n",
        "# Arguments can be passed by name\n",
        "print(add(y=8, x=2))  # 10\n",
        "\n",
        "a1 = [0, 1]\n",
        "a2 = [3, 5]\n",
        "concat(a1, a2)  # Returns nothing\n",
        "print(a1)       # [0, 1, 3, 5]\n",
        "\n",
        "# Methods can return more than one thing\n",
        "def two(a):\n",
        "  return a + 1, a + 2\n",
        "\n",
        "a3, a4 = two(1)\n",
        "print(a3)  # 2\n",
        "print(a4)  # 3\n",
        "\n",
        "t = two(1)\n",
        "print(t[0])\n",
        "print(t[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6ZtNRHO5Rh0"
      },
      "source": [
        "## List and Dictionary Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RadNS7m75Rh0"
      },
      "source": [
        "# Sometimes code can be simplified using list/dictionary comprehensions\n",
        "def add_one(x):\n",
        "  return x + 1\n",
        "\n",
        "# The standard way to apply a function to every element and save in y\n",
        "x = [0, 1, 2, 3]\n",
        "y = []\n",
        "for i in range(len(x)):\n",
        "  y.append(add_one(x[i]))\n",
        "\n",
        "# This is equivalent to the above\n",
        "y = [add_one(x_i) for x_i in x]\n",
        "\n",
        "# Add conditionals\n",
        "y2 = [add_one(x_i) for x_i in x if x_i > 1]\n",
        "\n",
        "# Dictionary comprehensions can be used to create dictionaries easily.\n",
        "# This creates a mapping from x_i -> x_i * 4\n",
        "d = {x_i : x_i * 4 for x_i in x}\n",
        "print(d)\n",
        "print(d[2])  # 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDAIm0Um5Rh1"
      },
      "source": [
        "## Files\n",
        "https://developers.google.com/edu/python/dict-files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1n8ilU5Rh1"
      },
      "source": [
        "# Reading from a file\n",
        "# In the same directory as the Jupyter notebook is a file called 'input.txt'.\n",
        "# You can use this for loop template to iteratively read a file line by line. Generally, you will\n",
        "# include some parsing logic to extract data from each line\n",
        "lines = []\n",
        "with open('input.txt', 'r') as f:   # This is the line which opens the file. `f` is the file handler\n",
        "                                    # The `with open` will automatically close the file are you are done reading.\n",
        "                                    # 'r' means you want to read from the file\n",
        "    for line in f:\n",
        "        line = line.strip()         # `strip()` removes any  whitespace from the beginning and end of the string\n",
        "                                    # By default, each line will have '\\n' at the end. \n",
        "        upper = line.upper()        # Here is where you would add your custom parsing logic\n",
        "        lines.append(upper)\n",
        "\n",
        "print(lines)  # ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
        "\n",
        "# Writing to a file\n",
        "# This will write each of the apital letters to a line in an output file\n",
        "out = open('out.txt', 'w')\n",
        "out.write('hi')\n",
        "out.close()\n",
        "\n",
        "with open('output.txt', 'w') as out:  # 'w' means you want to write to the file. This will overwite the file if it exists\n",
        "    for item in lines:\n",
        "        out.write(str(item) + '\\n')   # the `write` method only accepts strings and you have to\n",
        "                                      # manually take care of the '\\n' yourself"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCJYG1h55Rh2"
      },
      "source": [
        "### Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXnDgtWq5Rh2"
      },
      "source": [
        "class Person(object):\n",
        "    # This is the constructor. All instance methods of a class\n",
        "    # must accept `self` as the first parameter\n",
        "    # The self parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class\n",
        "    # You use `self` to access data members and methods of the class,\n",
        "    # similar to `this` in Java\n",
        "    def __init__(self, name, age):\n",
        "        # This will call the super class's constructor; Optional if you inherit from `object`\n",
        "        super().__init__()\n",
        "        \n",
        "        # Assign data members\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        \n",
        "    def is_adult(self):\n",
        "        return self.age >= 18\n",
        "    \n",
        "    def is_child(self):\n",
        "        # Other instance methods are called with the `self` keyword.\n",
        "        return not self.is_adult()\n",
        "    \n",
        "    def increment_age(self, amount):\n",
        "        self.age += amount\n",
        "        \n",
        "    # Test to see if two `Person` objects are equal\n",
        "    def __eq__(self, other):\n",
        "        return self.name == other.name and self.age == other.age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyov6YVZ5Rh3"
      },
      "source": [
        "p = Person('Bob', 19)\n",
        "\n",
        "# Data members can be accessed directly\n",
        "print(p.name)  # 'Bob'\n",
        "print(p.age)   # 19\n",
        "\n",
        "# Even though all of the methods require a `self` argument, you ignore that argument\n",
        "# when calling the method\n",
        "print(p.is_adult())  # True \n",
        "\n",
        "p.increment_age(1)  # Returns nothing\n",
        "print(p.age)        # 20\n",
        "\n",
        "p2 = Person('Mary', 30)\n",
        "print(p == p2)  # False\n",
        "\n",
        "p3 = Person('Mary', 30)\n",
        "print(p2 == p3)  # True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf7jlRTn5Rh4"
      },
      "source": [
        "# Useful Packages\n",
        "There are many packages that come with your python installation as well as many which can be downloaded easily for free.\n",
        "Importing a package requires the `import` command.\n",
        "Most packages can be installed using the `pip` command (which is run on the command line, not within a python environment), that is included with the python installation.\n",
        "\n",
        "```\n",
        "> pip install numpy\n",
        "> pip install scikit-learn\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7MNALHP5Rh4"
      },
      "source": [
        "### **random**\n",
        "The `random` package provides tools for generating random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sxiY5a75Rh4"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(4)\n",
        "\n",
        "print(random.randint(1, 5))  # A random integer in (1, 5)\n",
        "\n",
        "print(random.random())  # A random number in (0, 1.0]\n",
        "\n",
        "# Randomly shuffle a list\n",
        "a = [0, 1, 2, 3, 4, 5]\n",
        "random.shuffle(a)  # Shuffles in place - does not return a copy\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7F6krwQ5Rh5"
      },
      "source": [
        "### **numpy**\n",
        "`numpy` is a very useful matrix library for Python.\n",
        "It is used very frequently in machine learning, so it is good to be familiar with it.\n",
        "If your program crashes with an import error when you import numpy, you need to install it with\n",
        "```\n",
        "> pip install numpy\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paud9WX_5Rh5"
      },
      "source": [
        "# Imports can be aliased to simplify code\n",
        "import numpy as np  # The numpy library is now referenced with np\n",
        "\n",
        "# Create a vector of length 5 of all 0s\n",
        "v = np.zeros(5)\n",
        "print(v)\n",
        "\n",
        "print(v.shape)     # Returns a tuple of the dimensions: (5,)\n",
        "print(v.shape[0])  # Returns the size of the 0th dimension, 5\n",
        "\n",
        "# You can assign specific entries by their index into the vector\n",
        "v[0] = 1\n",
        "v[1] = 4\n",
        "\n",
        "# You can assign ranges of values\n",
        "v[2:5] = [5, 3, 6]\n",
        "print(v)\n",
        "\n",
        "# Create a random vector of values between 0 and 1\n",
        "np.random.seed(1)\n",
        "v1 = np.random.rand(5)\n",
        "print(v1)\n",
        "\n",
        "# Compute the dot product\n",
        "print(np.dot(v, v1))\n",
        "\n",
        "# Element-wise multiplication\n",
        "print(v * v1)\n",
        "print(np.multiply(v, v1))  # equivalent\n",
        "\n",
        "# Multiply the whole vector by a scalar, add a constant\n",
        "print(v * 5)\n",
        "print(v + 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNprz_H85Rh5"
      },
      "source": [
        "# Matrices work much the same way (vectors are just matrices with 1 dimension)\n",
        "# `np.ones` creates a matrix of the given input size\n",
        "t = (3, 4)\n",
        "X = np.ones(t)\n",
        "print(X)\n",
        "print(X.shape)     # (3, 4)\n",
        "print(X.shape[0])  # 3\n",
        "print(X.shape[1])  # 4\n",
        "\n",
        "# Assigning specific entries requires 2 indices\n",
        "# The first is the row index, the second is the column index\n",
        "X[1, 3] = 8\n",
        "print(X)\n",
        "\n",
        "# The `:` selects the entire row or column\n",
        "row1 = X[1, :]\n",
        "print(row1)\n",
        "print(X[:, 2])\n",
        "\n",
        "# It can also be used to assign values\n",
        "X[1, :] = [1, 2, 3, 4]\n",
        "print(X)\n",
        "\n",
        "# Matrix multiplication\n",
        "Y = np.random.rand(4, 5)\n",
        "print(np.matmul(X, Y))  # A matrix of size (3, 5)\n",
        "\n",
        "# Transpose\n",
        "print(X.transpose())\n",
        "print(X.T)  # equivalent\n",
        "\n",
        "# You can create a matrix from a list (of lists)\n",
        "Z = np.asarray(\n",
        "    [\n",
        "        [0, 1, 2], \n",
        "        [3, 4, 5]\n",
        "    ])\n",
        "print(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JrcDJlL5Rh5"
      },
      "source": [
        "# Useful ways to initialize matrices\n",
        "A = np.zeros((5, 3))  # A 5x5 matrix of all 0s\n",
        "print(A)\n",
        "\n",
        "A = np.ones((5, 3))  # A 5x3 matrix of all 1s\n",
        "print(A)\n",
        "\n",
        "A = np.eye(5)  # I matrix of size 5x5\n",
        "print(A)\n",
        "\n",
        "A = np.random.rand(5, 3)  # A random matrix of size 5x3 with numbers between 0 and 1\n",
        "print(A)\n",
        "\n",
        "A = np.random.randint(1, 4, (5, 3)) # A random matrix of integers in (0, 4] of size 5x3\n",
        "print(A)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAsDeSC6RIZ"
      },
      "source": [
        "### More information on `numpy`\n",
        "To know more about the methods and functions in `numpy`, visit the `numpy` User Guide: https://numpy.org/doc/stable/user/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kUKV9HP5Rh6"
      },
      "source": [
        "### **sklearn**\n",
        "`sklearn` is a useful machine learning library. It can be installed with\n",
        "```\n",
        "> pip install scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O3tfzwT5Rh6"
      },
      "source": [
        "# An example learning problem. You may use this as a template for homework\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# This is the feature matrix. There are 7 rows (7 training examples) with\n",
        "# 4 columns (4 features).\n",
        "X = np.asarray(\n",
        "[\n",
        "    [0, 0, 1, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 1, 1],\n",
        "    [1, 0, 0, 1],\n",
        "    [0, 1, 1, 0],\n",
        "    [1, 1, 0, 0],\n",
        "    [0, 1, 0, 1]\n",
        "])\n",
        "\n",
        "# These are the binary class labels for all 7 instances\n",
        "y = np.asarray([0, 0, 1, 1, 0, 0, 0])\n",
        "\n",
        "# Create the classifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
        "\n",
        "# Train the classifier on our labeled data\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Use our trained classifier to predict labels for new input data\n",
        "X_test = np.asarray(\n",
        "[\n",
        "    [1, 0, 0, 0],\n",
        "    [0, 1, 1, 1],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Let's assume we know the actual labels of `X_test` are this\n",
        "y_test = np.asarray([0, 1, 1])\n",
        "\n",
        "# We can compute the total number of correct classifications:\n",
        "num_correct = sum(y_pred == y_test)\n",
        "total = y_pred.shape[0]\n",
        "print('Accuracy: ' + str(num_correct / total * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvcrBsoBbak-"
      },
      "source": [
        "A key function of sklearn is the ability to split datasets. For supervised machine learning, we need to split our data into sets on which we train our models, validate how well different iterations of our models perform (which we can use to tune and improve the model), and finally evaluate how the final model performs. Sklearn allows us to split the data easily using the train_test_split function. The function is quite well documented, so we encourage you to check out how it works for the specifics, but will run an example here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f2iC21jcG5H"
      },
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Let's practice using a random array with ints ranging from 0-3\n",
        "X = np.random.randint(4, size= (6,5))\n",
        "\n",
        "#Let's view the transpose of each array to make the labels line up more clearly on the screen\n",
        "print(f'X:\\n {X}')\n",
        "\n",
        "# We'll also say we have a corresponding array of class labels. \n",
        "# Often, this will be in the same dataset, and you will have to split it into its own array\n",
        "y = np.random.randint(2, size = (6, 1))\n",
        "print(f'y:\\n {y}')\n",
        "\n",
        "# Now we can split the data using train_test_split. Note that the class labels stay with their corresponding rows.\n",
        "# We are setting a test size of .3, meaning 30% of our data will be used as a test set, and the rest for training.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)\n",
        "print(f'X_train:\\n {X_train}')\n",
        "print(f'y_train:\\n {y_train}')\n",
        "print(f'X_test:\\n {X_test}')\n",
        "print(f'y_test:\\n {y_test}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYv4GFT2crPQ"
      },
      "source": [
        "Sklearn also contains other ways to split data other than just randomly, such as a stratified sample which tries to retain the same proportions of classes in each split. We encourage you to look through the documentation to learn about other sampling methods!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnydi9lg6yyO"
      },
      "source": [
        "### More information on `sklearn`\n",
        "To know more about the methods and functions supported in `sklearn`, visit `sklearn` user guide: https://scikit-learn.org/stable/user_guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FiAL5If3Wtx"
      },
      "source": [
        "### **pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdCUq_st5Rh7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# !pip install jupyter_contib_nbextensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQUIxvJb3Wty"
      },
      "source": [
        "#### Series & DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSm28tZ03Wty"
      },
      "source": [
        "sports = pd.Series(['football', 'basketball',' volleyball','tennis'])\n",
        "\n",
        "population = pd.Series({'Germany': 81.3, 'Belgium': 11.3, 'France': 64.3, \n",
        "                        'United Kingdom': 64.9, 'Netherlands': 16.9})\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMUmGqKg3Wt1"
      },
      "source": [
        "sports"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5gvsCGH3Wt5"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50d4u6So3Wt8"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feapzLyS3Wt_"
      },
      "source": [
        "type(population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHp3RKmv3WuD"
      },
      "source": [
        "sports.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD3-CxRF3WuG"
      },
      "source": [
        "population.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrz-rSxe3WuJ"
      },
      "source": [
        "population['Belgium']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaUPxsis3WuL"
      },
      "source": [
        "population.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSo2vGIX3WuO"
      },
      "source": [
        "population/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxDliCc73WuR"
      },
      "source": [
        "type(population.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv3mfF6j3Wub"
      },
      "source": [
        "Accessing dataframe variables using the '.' operator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ddwUeq3Wuc"
      },
      "source": [
        "type(countries.area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weQFlPmm3Wue"
      },
      "source": [
        "countries.area.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYnI9rSX3Wug"
      },
      "source": [
        "type(countries.capital.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUU-zkPu3Wuk"
      },
      "source": [
        "#### Basic Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Y5pQ5J3Wul"
      },
      "source": [
        "countries.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGGfvAgu3Wun"
      },
      "source": [
        "countries.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyV8QA-O3Wuq"
      },
      "source": [
        "countries.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejcGv2n63Wus"
      },
      "source": [
        "countries.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVPAG1LI3Wuu"
      },
      "source": [
        "countries.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnsatRQE3Wuw"
      },
      "source": [
        "countries.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXfYKm2h3Wu0"
      },
      "source": [
        "countries.capital.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cyRKUsw3Wu3"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOHFtPdB3Wu5"
      },
      "source": [
        "population.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBxDA9M43Wu9"
      },
      "source": [
        "type(population.reset_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvHc1RIU3WvA"
      },
      "source": [
        "countries.capital.value_counts().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6B6PGPK3WvD"
      },
      "source": [
        "#### Selecting and Filtering Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNh4awSB3WvD"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "<b>ATTENTION!</b>: <br><br>\n",
        "\n",
        "One of pandas' basic features is the labeling of rows and columns, but this makes indexing also a bit more complex compared to numpy. <br><br> We now have to distuinguish between:\n",
        "\n",
        " <ul>\n",
        "  <li>selection by **label**</li>\n",
        "  <li>selection by **position**</li>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2wtkhQv3WvE"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur7YYnvj3WvH"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLEPQnnC3WvJ"
      },
      "source": [
        "##### `data[]` provides some convenience shortcuts "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdJVL8N33WvK"
      },
      "source": [
        "Selecting a single column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er7PHioh3WvK",
        "scrolled": true
      },
      "source": [
        "df['Pclass']  # Can also use df.Pclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpw283_s3WvM"
      },
      "source": [
        "Selecting multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl-8W-5k3WvO",
        "scrolled": true
      },
      "source": [
        "df[  ['Pclass','Sex']   ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02qDfxdx3WvQ"
      },
      "source": [
        "Keep in mind that when we select more than one column, the output is DataFrame and not a series. Hence the difference in formatting of the two outputs above\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We can also use this syntax to select specific rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nINwoPkU3WvS"
      },
      "source": [
        "df[3:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh7Flpcx3WvU"
      },
      "source": [
        "#### Systematic indexing with `loc` and `iloc`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "059P_5z63WvV"
      },
      "source": [
        "When using `[]` like above, you can only select from one axis at once (rows or columns, not both). For more advanced indexing, you have some extra attributes:\n",
        "    \n",
        "* `loc`: selection by label\n",
        "* `iloc`: selection by position\n",
        "\n",
        "These methods index the different dimensions of the frame:\n",
        "\n",
        "* `df.loc[row_indexer, column_indexer]`\n",
        "* `df.iloc[row_indexer, column_indexer]`\n",
        "\n",
        "**As long as the dataframe has no defined indices, loc can do the job of iloc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQdXtta-3WvW"
      },
      "source": [
        "df.loc[4,'Fare']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htvmMpsi3WvY"
      },
      "source": [
        "df.loc[df.Sex=='female']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND0E_1qG3Wvc",
        "scrolled": true
      },
      "source": [
        "df.loc[df.Sex=='female','Fare']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3dvUMgU3Wvf",
        "scrolled": true
      },
      "source": [
        "df.loc[df.Sex=='female',['Fare','Name','Sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eG_FdqP3Wvj"
      },
      "source": [
        "df.loc[df.Sex=='female'][['Fare','Name','Sex']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_H6xsS23Wvl"
      },
      "source": [
        "iloc is based on the position of the elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSCKKG03Wvl"
      },
      "source": [
        "df.iloc[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soLRbg2O3Wvp"
      },
      "source": [
        "df.iloc[5:7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qiv2XoOk3Wvu",
        "scrolled": true
      },
      "source": [
        "df.iloc[5:7,'Fare']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbklMIL53Wvw"
      },
      "source": [
        "df.iloc[5:7]['Fare']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5I87UDz3Wvy"
      },
      "source": [
        "df.iloc[[1,2,3,8]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx59kaUz5RiG"
      },
      "source": [
        "df.loc[[1,2,3,8]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpgjYWcA5RiG"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQQnoavG5RiG"
      },
      "source": [
        "population.loc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPmh7P0U3Wv0"
      },
      "source": [
        "The different indexing methods can also be used to assign data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdZEXCWa3Wv2"
      },
      "source": [
        "df2 = df.copy()\n",
        "\n",
        "df2.loc[0,'Fare'] = -100.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD32H7E33Wv3"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Hutjj33Wv7"
      },
      "source": [
        "#### Creating New Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLX0JKmh3Wv8"
      },
      "source": [
        "countries['newVar'] = [1,2,3,4,5]                   #Basic assignment\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bSg2OEw3Wv-"
      },
      "source": [
        "countries['newVar'] = countries.population * 2  + countries.area**0.5   #Using existing columns\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJQGn_eV3WwA"
      },
      "source": [
        "##### Using apply\n",
        "\n",
        "Apply is a very powerful method which can be used for making major data manipulation tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlU1Z6_D3WwA"
      },
      "source": [
        "countries['capital_upper'] = countries['capital'].apply(lambda x : x.upper())\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdsJygi3WwC"
      },
      "source": [
        "def ageBucket(x):\n",
        "    if x<18:\n",
        "        return \"A. <18\"\n",
        "    elif x<25:\n",
        "        return \"B. 18-25\"\n",
        "    elif x<45:\n",
        "        return \"C. 25-45\"\n",
        "    else:\n",
        "        return \"D. >45\"\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7N8t6Au3WwD"
      },
      "source": [
        "Apply can be used on a single column (Series object)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPubA06U3WwD"
      },
      "source": [
        "df['AgeBucket'] = df['Age'].apply(lambda x : ageBucket(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stcvjvwf3WwG"
      },
      "source": [
        "It can also be used on an entire dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5xHhod3WwH"
      },
      "source": [
        "df['AgeBucket2'] = df.apply(lambda x : ageBucket(x['Age']),axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgR92Mms3WwI"
      },
      "source": [
        "Other derivative methods that you can look into : `map` and `applymap`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHZN9Wj63WwJ"
      },
      "source": [
        "#### Groupby Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFo0Wrqm3WwJ"
      },
      "source": [
        "##### Some 'theory': the groupby operation (split-apply-combine)\n",
        "\n",
        "The \"group by\" concept: we want to **apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets**\n",
        "\n",
        "This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps:\n",
        "\n",
        "* **Splitting** the data into groups based on some criteria\n",
        "* **Applying** a function to each group independently\n",
        "* **Combining** the results into a data structure\n",
        "\n",
        "<img src=\"https://github.com/CIS-519/primer-dev/blob/master/pandas-tutorial-master/img/splitApplyCombine.png?raw=1\">\n",
        "\n",
        "Similar to SQL `GROUP BY`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAj20Vve3WwK"
      },
      "source": [
        "df.groupby('Sex')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ELuau23WwL"
      },
      "source": [
        "df.groupby(\"Sex\").mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBFxiNJ3WwN"
      },
      "source": [
        "df.groupby('Sex').max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pwARtVh3WwO"
      },
      "source": [
        "def getRange(x):\n",
        "    \n",
        "    minVal = np.min(x.Fare)\n",
        "    maxVal = np.max(x.Fare)\n",
        "    \n",
        "    return maxVal - minVal\n",
        "\n",
        "\n",
        "df.groupby('Pclass').apply(lambda x : getRange(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGu1111T3WwQ"
      },
      "source": [
        "Grouping on multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHpnkv9d3WwQ"
      },
      "source": [
        "df.groupby(['Sex','Pclass']).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE8wmhMq3WwS"
      },
      "source": [
        "df.groupby(['Sex','Pclass'])['Age'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yapH_edp3WwY"
      },
      "source": [
        "df.groupby('Sex').agg({'PassengerId':'min', 'Age':'max','Fare':'sum'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpyIS_Bn3Wwb"
      },
      "source": [
        "#### Merge Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPGG_g1H3Wwb"
      },
      "source": [
        "Merging with Pandas works pretty much the same as SQL. There are four merge methods:\n",
        "1. Left\n",
        "2. Right\n",
        "3. Inner \n",
        "4. Outer\n",
        "\n",
        "Basic syntax : pd.merge(left_dataframe, right_dataframe, left_on=\"some_column\", right_on=\"some_column\", how=\"left|right|inner|outer)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzFKDI6I3Wwb"
      },
      "source": [
        "population = pd.DataFrame({'country': ['Germany', 'Belgium', 'France', \n",
        "                        'United Kingdom', 'United States'],'population': [81.3, 11.3, 64.3, 64.9, 65.9]})\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbRi4xh3Wwd"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec1g-uJw3Wwf"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaU4-kzk3Wwi"
      },
      "source": [
        "In a Left Merge we are mostly concerned with data on the LEFT side but we would like to add data from \n",
        "the RIGHT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffn5Rf3V3Wwj"
      },
      "source": [
        "pd.merge(left=population, right=countries, on=\"country\", how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHV_k3Q3Wwl"
      },
      "source": [
        "In a Right Merge we are mostly concerned with data on the RIGHT side but we would like to add data from \n",
        "the LEFT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEAd4weA3Wwn"
      },
      "source": [
        "pd.merge(left=population, right=countries, on=\"country\", how=\"right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGVgL1O73Wwp"
      },
      "source": [
        "With an Inner Merge, we chop up both dataframes and only glue the stuff that matches. If a country isn't in both \n",
        "dataframes, we don't keep it and we don't add NaN's. If no type of join is mentioned, then inner join is the \n",
        "default join. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cumuNz1-3Wwp"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwK5dcNV3Wwq"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country', how = \"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbnDLQwd3Wws"
      },
      "source": [
        "With an Outer Merge, we chop up both dataframes and keep everything from both sides. Then we toss in NaN's to fill\n",
        "any blanks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwv0vZka3Wws"
      },
      "source": [
        "pd.merge(left=population, right=countries,on ='country', how = \"outer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "fTEpNhD13Wwt"
      },
      "source": [
        "#### Reading Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "V88hkF283Wwu"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "YpSCbc2r3Wwu"
      },
      "source": [
        "sales_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "IYXmyTue3Www"
      },
      "source": [
        "# header = 0 denotes the first line of data. If nothing is mentioned about header, then header = 0 is default.\n",
        "sales_data2 = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv', header = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "JfhKhkSQ3Www"
      },
      "source": [
        "sales_data2.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "2lpgq01a3Wwy"
      },
      "source": [
        "sales_data3 = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv', header = None)\n",
        "sales_data3.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ZwkwAs2s3Wwz"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv', usecols=['name', 'birthday'])\n",
        "sales_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "wKKTODqd3Ww3"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv', header= None, skiprows=2)\n",
        "sales_data.columns= ['name', 'birthday','customer','orderadate','product','units','unitprice']\n",
        "sales_data.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "mu60xXuG3Ww5"
      },
      "source": [
        "# The date parse is US datew friendly! MM/DD/YYYY\n",
        "\n",
        "\n",
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv',parse_dates=['birthday', 'orderdate'])\n",
        "sales_data.head(2)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "5VFeUlcT3Ww_"
      },
      "source": [
        "# To use the more common international format for sure, add 'dayfirst=True'\n",
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv',parse_dates=['birthday', 'orderdate'], dayfirst=True)\n",
        "sales_data.head(2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "aNNmEloL3WxD"
      },
      "source": [
        "sales_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "UpocT9mQ3WxE"
      },
      "source": [
        "sales_data['modified_orderdate'] = sales_data['orderdate'].apply(lambda x: \"%d/%d/%d\" % (x.day, x.month, x.year))\n",
        "sales_data.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "9vRxeCBg3WxG"
      },
      "source": [
        "sales_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6hnXPGkM3WxK"
      },
      "source": [
        "sales_data['Hour'] = sales_data['orderdate'].apply(lambda x: \"%d\" % (x.hour))\n",
        "sales_data.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "VN-p4LTg3WxL"
      },
      "source": [
        "sales_data[\"modified_orderdate\"]= pd.to_datetime(sales_data[\"modified_orderdate\"])\n",
        "sales_data.head(4)\n",
        "sales_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "vk_Mm7x63WxP"
      },
      "source": [
        "sales_data['birth_month'] = sales_data['birthday'].dt.month\n",
        "sales_data.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "SOcFohvD3WxV"
      },
      "source": [
        "sales_data_json = pd.read_json('pandas-tutorial-master/data/blooth_sales_data.json')\n",
        "sales_data_json.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "8lxbwUHH3WxX"
      },
      "source": [
        "#### Missing Data\n",
        "How to handle missing data (NaN's)? Most common commands used are fillna and dropna. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Z4sbjPoR3WxX"
      },
      "source": [
        "missing_df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],columns=['one', 'two', 'three'])\n",
        "missing_df['four'] = 'bar'\n",
        "missing_df['five'] = missing_df['one'] > 0\n",
        "missing_df.loc[['a','c','h'],['one','four']] = np.nan\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "cOAic3gb3WxZ"
      },
      "source": [
        "# fillna replaces NA/NAN values with the given value in the command.\n",
        "missing_df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "UcJud3dn3Wxf"
      },
      "source": [
        "missing_df['one'].fillna('missing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "L4dr81_h3Wxh"
      },
      "source": [
        "Dropna is used to drop the rows or columns with NA/NAN values.\n",
        "<br>\n",
        "'axis' argument determines if rows or columns which contain missing values are removed.\n",
        "<br>\n",
        "'axis =0': Drop rows which contain missing values. \n",
        "<br>\n",
        "'axis =1': Drop columns which contain missing value.\n",
        "<br>\n",
        "\n",
        "\n",
        "'how' argument determines if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
        "<br>\n",
        "how = any : If any NA values are present, drop that row or column. (default)\n",
        "<br>\n",
        "how = all : If all values are NA, drop that row or column.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "LDrcfuDH3Wxi"
      },
      "source": [
        "missing_df.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "eRLSnqGz3Wxk"
      },
      "source": [
        "missing_df.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "t875iBcc3Wxo"
      },
      "source": [
        "missing_df['six'] = np.nan\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OG27aNrA3Wxq"
      },
      "source": [
        "missing_df.dropna(axis=1, how = 'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "v-MB5Pl73Wxr"
      },
      "source": [
        "#dropping rows only where some columns are missing\n",
        "missing_df.dropna(subset = ['one', 'two', 'four'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "u4WwTo6S3Wxx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghfu4Sbc9zeB"
      },
      "source": [
        "### More information on `pandas`\n",
        "To know more about the methods and functions in `pandas`, visit the `pandas` User Guide: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "tT4ZKgxm3Wx0"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "HiQmv6HV3Wx0"
      },
      "source": [
        "## Titanic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "BE99grfO3Wx1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "6XBMUadX3Wx5"
      },
      "source": [
        "Calculate the number of passengers with Pclass = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "rXr_SK_c3Wx7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "GFA7Yn-H3Wx8"
      },
      "source": [
        "Compute the percentage of passengers that survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "IRkoto_v3Wx8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Ej80X4cl3Wx9"
      },
      "source": [
        "How many children below the age of 18?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "C1ezst8B3Wx-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "SvEOxQ9a3Wx_"
      },
      "source": [
        "Whats the ratio of male and female passengers?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "y1L20dpS3WyA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "G4vqjRwT3WyE"
      },
      "source": [
        "Between the two genders, whats the ratio of passengers that survived?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "JR1WrisY3WyE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "q6JcJaQN3WyF"
      },
      "source": [
        "Create a new variable which has 0 for male and 1 for female. Name this variable **LabelEncode_Sex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "nyfw6dyY3WyG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "2sIdQgEw3WyH"
      },
      "source": [
        "Create a variable that takes the value of 1 when Pclass is 1 and 0 otherwise. Create similar variables for when Pclass has a value of 2 and 3.\n",
        "\n",
        "Name these variables **OHE_PClass1, OHE_PClass2, OHE_PClass3** respectively "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "J9BFY3Ja3WyI"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "hM3jPG4s3WyK"
      },
      "source": [
        "Calculate the mean fare for all samples with an odd index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "xqia6PYr3WyM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "OUT8jkNh3WyO"
      },
      "source": [
        "Create a new variable which stores the last name of passengers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "3DpxXxMR3WyO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Atr4PLVj3WyR"
      },
      "source": [
        "Calculate the number of unique families ( based on last names)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ntu_MpxC3WyR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ev08MwE13WyW"
      },
      "source": [
        "Create a variable that indicates the **size of the family** for each passenger. *Family size is the number of passengers with the same family name*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ZmxAUjkq3WyZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "pCaIJQ6R3Wyc"
      },
      "source": [
        "#### Fare by Cabin Index\n",
        "\n",
        "All cabin numbers begin with a letter. We hypothesize that this first letter actually has a significance. So create a new variable that stores the first letter of the cabin variable. Call this **CabinIndex**.\n",
        "\n",
        "NOTE : The cabin variable has missing values. Also check for the data type of the Cabin variable.\n",
        "\n",
        "Once you have created the CabinIndex variable, calculate the mean value of fare for different levels of CabinIndex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "qxo2LVAx3Wyd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "TzhoCk0C3Wyk"
      },
      "source": [
        "## Sales Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "wUpkw4X53Wyk"
      },
      "source": [
        "For sales_data, create a variable named mean_units which is the average of all units when the birth month lies between Feb and August."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "2xfFNH-g3Wyl"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv')\n",
        "sales_data.dtypes\n",
        "sales_data[\"birthday\"]= pd.to_datetime(sales_data[\"birthday\"])\n",
        "sales_data_mid = sales_data[((sales_data['birthday'].dt.month > 2) & (sales_data['birthday'].dt.month <8 ))]\n",
        "mean_units =sales_data_mid[\"units\"].mean()\n",
        "mean_units"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "HXqX7Tjm3Wyp"
      },
      "source": [
        "Create a new column in sales_data titled 'order_minutes' and for each row, store the minutes from orderdate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "133EUqqG3Wyp"
      },
      "source": [
        "sales_data[\"orderdate\"]= pd.to_datetime(sales_data[\"orderdate\"])\n",
        "sales_data['order_minutes'] = sales_data['orderdate'].dt.minute\n",
        "sales_data.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "HJ6RitkV3Wyr"
      },
      "source": [
        "For sales_data dataframe, create a dataframe called 'sd_df' to store only those rows where product is 'Harry Potter book'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "smjYl3F13Wyr"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv')\n",
        "sd_df = sales_data[sales_data[\"product\"] == 'Harry Potter book' ]\n",
        "sd_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "BPPK6tgy3Wys"
      },
      "source": [
        "For sales_data, find the data of people who were born before 1980"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "HpZnKBkB3Wys"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv')\n",
        "sales_data[\"birthday\"]= pd.to_datetime(sales_data[\"birthday\"])\n",
        "sales_data= sales_data[sales_data['birthday'].dt.year < 1980]\n",
        "sales_data.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "SoLB3wSM3Wyv"
      },
      "source": [
        "For sales_data, find the average unitprice for products that were ordered in first week of a month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zBYtf5a43Wyw"
      },
      "source": [
        "sales_data = pd.read_csv('pandas-tutorial-master/data/blooth_sales_data.csv')\n",
        "sales_data[\"orderdate\"]= pd.to_datetime(sales_data[\"orderdate\"])\n",
        "sales_data= sales_data[sales_data['orderdate'].dt.day > 8]\n",
        "sales_data.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "hLuJVWP23Wyy"
      },
      "source": [
        "For sales data, display number of units sold for each product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "NUanKuUL3Wy0"
      },
      "source": [
        "sales_data.groupby('product')['units'].sum().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_KEJO5Ep3Wy1"
      },
      "source": [
        "Create a new column in sales_data and store orderdate in the format mm/dd/yyyy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6zYmcOKv3Wy1"
      },
      "source": [
        "sales_data['new_date'] = sales_data['orderdate'].apply(lambda x: \"%d/%d/%d\" % (x.month, x.day,x.year))\n",
        "sales_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "MVdzrRVE3Wy4"
      },
      "source": [
        "## Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ZH-70CeB3Wy5"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "SZBSysRj3WzI"
      },
      "source": [
        "data.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zUyOE2KH3WzJ"
      },
      "source": [
        "data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "KcnI3iE_3WzL"
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "TWx6wsU-3WzO"
      },
      "source": [
        "data.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "JyjbJwKl3WzP"
      },
      "source": [
        "### Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Yt7Dii2O3WzP"
      },
      "source": [
        "Put together all the components of the data variable into a Pandas DataFrame. *This means putting together the feature and target variables, and adding their names as column names*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "QMrYo5U63WzP"
      },
      "source": [
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "df['target'] = data.target\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5vkzjRZA3WzR"
      },
      "source": [
        "Find number of observations in the dataset which belong to class setosa and have a petal length > 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "BEHGFSQu3WzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Oj1DDSyl3WzV"
      },
      "source": [
        "Find the maximum and minimum values of each of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "drH9aURJ3WzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "sJpCfA3M3WzW"
      },
      "source": [
        "Find the range of value for each of the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANLkRajjum9y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7GK3MHcL3WzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "myT3HQQF3WzY"
      },
      "source": [
        "For each of the target classes, find the mean value of each of the independent variables. The mean values should be represented in a table.\n",
        "\n",
        "**Do not** use for loops. This should be doable in a single line of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "kY7xLTWi3WzZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "# **Section 2 - Google Colab**\n",
        "This section covers an introduction to Colab.\n",
        "\n",
        "---\n",
        "\n",
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>What is Colaboratory?</h1>\n",
        "\n",
        "Colaboratory, or 'Colab' for short, allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPUs\n",
        "- Easy sharing\n",
        "\n",
        "Whether you're a <strong>student</strong>, a <strong>data scientist</strong> or an <strong>AI researcher</strong>, Colab can make your work easier. Watch <a href=\"https://www.youtube.com/watch?v=inN8seMm7UI\">Introduction to Colab</a> to find out more, or just get started below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## <strong>Getting started</strong>\n",
        "\n",
        "The document that you are reading is not a static web page, but an interactive environment called a <strong>Colab notebook</strong> that lets you write and execute code.\n",
        "\n",
        "For example, here is a <strong>code cell</strong> with a short Python script that computes a value, stores it in a variable and prints the result.  Note that you can import many common packages, including some packages that would otherwise have to be pip-installed, directly into Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "xs = range(10)\n",
        "std_val = np.std(xs)\n",
        "std_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut 'Command/Ctrl+Enter'. To edit the code, just click the cell and start editing.\n",
        "\n",
        "Variables that you define in one cell can later be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "Colab notebooks allow you to combine <strong>executable code</strong> and <strong>rich text</strong> in a single document, along with <strong>images</strong>, <strong>HTML</strong>, <strong>LaTeX</strong> and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them. To find out more, see <a href=\"/notebooks/basic_features_overview.ipynb\">Overview of Colab</a>. To create a new Colab notebook you can use the File menu above, or use the following link: <a href=\"http://colab.research.google.com#create=true\">Create a new Colab notebook</a>.\n",
        "\n",
        "Colab notebooks are Jupyter notebooks that are hosted by Colab. To find out more about the Jupyter project, see <a href=\"https://www.jupyter.org\">jupyter.org</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "## Data science\n",
        "\n",
        "With Colab you can harness the full power of popular Python libraries to analyse and visualise data. The code cell below uses <strong>numpy</strong> to generate some random data, and uses <strong>matplotlib</strong> to visualise it. To edit the code, just click the cell and start editing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4HZx7Gndbrh"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ys = 200 + np.random.randn(100)\n",
        "x = [x for x in range(len(ys))]\n",
        "\n",
        "plt.plot(x, ys, '-')\n",
        "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
        "\n",
        "plt.title(\"Sample Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kCnsPUqS6o"
      },
      "source": [
        "You can import your own data into Colab notebooks from your Google Drive account, including from spreadsheets, as well as from GitHub and many other sources. To find out more about importing data, and how Colab can be used for data science, see the links below under <a href=\"#working-with-data\">Working with data</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuxHmxllTwN"
      },
      "source": [
        "## Machine learning\n",
        "\n",
        "With Colab you can import an image dataset, train an image classifier on it, and evaluate the model, all in just <a href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\">a few lines of code</a>. Colab notebooks execute code on Google's cloud servers, meaning you can leverage the power of Google hardware, including <a href=\"#using-accelerated-hardware\">GPUs and TPUs</a>, regardless of the power of your machine. All you need is a browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufxBm1yRnruN"
      },
      "source": [
        "Colab is used extensively in the machine learning community with applications including:\n",
        "- Getting started with TensorFlow\n",
        "- Developing and training neural networks\n",
        "- Experimenting with TPUs\n",
        "- Disseminating AI research\n",
        "- Creating tutorials\n",
        "\n",
        "To see sample Colab notebooks that demonstrate machine learning applications, see the <a href=\"#machine-learning-examples\">machine learning examples</a> below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More resources\n",
        "\n",
        "### Primary resources\n",
        "Resources that are particularly useful are:\n",
        "\n",
        "*   [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "*   [Guide to markdown](/notebooks/markdown_guide.ipynb)\n",
        "*   [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "*   [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "*   [Loading data: Drive, Sheets and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "\n",
        "### Other resources\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb) \n",
        "- [Charts: visualising data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine learning crash course\n",
        "These are a few of the notebooks from Google's online machine learning course. See the <a href=\"https://developers.google.com/machine-learning/crash-course/\">full course website</a> for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [TensorFlow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using accelerated hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine learning examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine-learning analyses that Colaboratory makes possible, take a look at these tutorials using models from <a href=\"https://tfhub.dev\">TensorFlow Hub</a>.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">Retraining an Image Classifier</a>: Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">Text Classification</a>: Classify IMDB film reviews as either <em>positive</em> or <em>negative</em>.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">Style Transfer</a>: Use deep learning to transfer style between images.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">Multilingual Universal Sentence Encoder Q&amp;A</a>: Use a machine-learning model to answer questions from the SQuAD dataset.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">Video Interpolation</a>: Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ]
}