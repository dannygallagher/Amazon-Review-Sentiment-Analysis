{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnwork_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cofmYleBK7l-"
      },
      "source": [
        "#CNN Training and Evaluation\n",
        "This notebook contains code for importing and calibrating data, training, and testing for our CNN sentiment analysis model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4yJB3WLOca"
      },
      "source": [
        "# Importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHXfPL3cEZUB"
      },
      "source": [
        "%pip install autocorrect\n",
        "%pip install madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYtb4z0LzVl"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvv0jmiuLUiV"
      },
      "source": [
        "#Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjOajYcXsl_N"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT7RGgEZLXm3"
      },
      "source": [
        "#Data processing code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq9RAO1p7Usz"
      },
      "source": [
        "'''\n",
        "Takes preprocessed code and puts it into a format that will be used by the CNN model\n",
        "\n",
        "If @binary is True, transforms the data from five class into a simple 1/0 positve/negative\n",
        "'''\n",
        "\n",
        "def cleanup(df, binary):\n",
        "    df = df[['title_plus_review', 'overall']]\n",
        "    df['overall'] = df['overall'].apply(lambda x: x if isinstance(x, float) else None)\n",
        "    if binary:\n",
        "        df['overall_adj'] = df['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
        "        df = df[['overall_adj', 'title_plus_review']]\n",
        "        df = df.rename(columns = {'overall_adj': 'overall', 'title_plus_review': 'reviewText'})\n",
        "    df = df.dropna()\n",
        "    df = df.rename(columns = {'title_plus_review': 'reviewText'})\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1jt03k-c9_-"
      },
      "source": [
        "'''\n",
        "Tokenizes the data and removes stopwords\n",
        "'''\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "def tokenize(sentence):\n",
        "  tokens = token.tokenize(sentence)\n",
        "  filtered = [x for x in tokens if not x in stop_words]\n",
        "  return filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VcuT5xJ9Lj"
      },
      "source": [
        "'''\n",
        "Outputs the processed dataframes into json format, which will ultimately be read\n",
        "by the Torch Dataset\n",
        "'''\n",
        "def output_to_json(train_df, test_df):\n",
        "    train_json = train_df.to_json(orient = 'records')\n",
        "    train_json_result = json.loads(train_json)\n",
        "    with open('sample_data/train.json', 'w') as f:\n",
        "      for entry in train_json_result:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')\n",
        "\n",
        "    test_json = test_df.to_json(orient = 'records')\n",
        "    test_json_result = json.loads(test_json)\n",
        "    with open('sample_data/test.json', 'w') as f:\n",
        "      for entry in test_json_result:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psAvAvJuMz4-"
      },
      "source": [
        "'''\n",
        "Constructs the torch datasets and imports pre-trained word embeddings\n",
        "\n",
        "Changes the classificaiton method if binary vs. five class\n",
        "'''\n",
        "def get_data_tokens_score(binary):\n",
        "    TOKENS = data.Field(lower = True, batch_first = True)\n",
        "    if binary:\n",
        "        SCORE = data.LabelField(dtype = torch.float)\n",
        "    else:\n",
        "        SCORE = data.LabelField(dtype = torch.long)\n",
        "\n",
        "    fields = {'tokenized': ('tokens', TOKENS), 'overall': ('score', SCORE)}\n",
        "    train_data, test_data = data.TabularDataset.splits(\n",
        "        path = 'sample_data',\n",
        "        train = 'train.json',\n",
        "        test = 'test.json',\n",
        "        format = 'json',\n",
        "        fields = fields\n",
        "    )\n",
        "\n",
        "    TOKENS.build_vocab(train_data, \n",
        "                      max_size = 10000,\n",
        "                      vectors = \"glove.6B.100d\", \n",
        "                      unk_init = torch.Tensor.normal_)\n",
        "    SCORE.build_vocab(train_data)\n",
        "\n",
        "    return train_data, test_data, TOKENS, SCORE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64V9jCNeMIGt"
      },
      "source": [
        "'''\n",
        "Builds Torch iterators for the loaded data\n",
        "'''\n",
        "\n",
        "import torch\n",
        "\n",
        "def get_iters(train_data, test_data):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    train_iterator = data.BucketIterator(train_data, sort_key = lambda x: x.tokens, \n",
        "                                        sort = False, sort_within_batch = True, batch_size= 64, device = device)\n",
        "    test_iterator = data.BucketIterator(test_data, sort_key = lambda x: x.tokens, \n",
        "                                        sort = False, sort_within_batch = True, batch_size= 64, device = device)\n",
        "    return train_iterator, test_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDousd4g3cl"
      },
      "source": [
        "'''\n",
        "Method that combines all of the above into a single method and provides the \n",
        "relevant inputs that will be fed to the CNN \n",
        "'''\n",
        "def get_iters_tokens(dataset, binary):\n",
        "    path = '/content/drive/Shareddrives/519 Project/Data/preprocessed/Final Data/'\n",
        "    if dataset == 'electronics':\n",
        "        electronics_train_path = os.path.join(path, 'electronics_train.csv')\n",
        "        electronics_test_path = os.path.join(path, 'electronics_test.csv')\n",
        "\n",
        "        train_df = pd.read_csv(electronics_train_path)\n",
        "        test_df = pd.read_csv(electronics_test_path)\n",
        "    else:\n",
        "        allcats_train_path = os.path.join(path, 'all_train.csv')\n",
        "        allcats_test_path = os.path.join(path, 'all_test.csv')\n",
        "\n",
        "        train_df = pd.read_csv(allcats_train_path)\n",
        "        test_df = pd.read_csv(allcats_test_path)\n",
        "    \n",
        "    train_df = cleanup(train_df, binary)\n",
        "    test_df = cleanup(test_df, binary)\n",
        "\n",
        "    train_df['tokenized'] = train_df['reviewText'].apply(tokenize)\n",
        "    train_df = train_df[['tokenized', 'overall']]\n",
        "\n",
        "    test_df['tokenized'] = test_df['reviewText'].apply(tokenize)\n",
        "    test_df = test_df[['tokenized', 'overall']]\n",
        "\n",
        "    output_to_json(train_df, test_df)\n",
        "\n",
        "    train_data, test_data, TOKENS, SCORE = get_data_tokens_score(binary)\n",
        "    train_iterator, test_iterator = get_iters(train_data, test_data)\n",
        "\n",
        "    return train_iterator, test_iterator, TOKENS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx-jdoldBEDw"
      },
      "source": [
        "## CNN's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdWzbgXZTqZi"
      },
      "source": [
        "'''\n",
        "Outlines the structure for our CNN model\n",
        "\n",
        "model architecture from: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
        "used as a starting point\n",
        "'''\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self, vocab_size, \n",
        "                 vector_size, n_filters, \n",
        "                 filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vector_size, \n",
        "                                      padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, vector_size)) \n",
        "                                    for fs in filter_sizes])\n",
        "        \n",
        "        self.linear = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text).unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        return self.linear(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPLw0QxmVoWc"
      },
      "source": [
        "'''\n",
        "Returns a new base CNN model\n",
        "@num_classes how many classes\n",
        "@TOKENS contains the pre-trained embeddings\n",
        "'''\n",
        "def get_cnn_model(num_classes, TOKENS):\n",
        "  input_dim = len(TOKENS.vocab)\n",
        "  embedding_dim = 100\n",
        "  n_filters = 100\n",
        "  filter_sizes = [1,2,3,4]\n",
        "  output_dim = num_classes\n",
        "  dropout = .3\n",
        "  pad_idx = TOKENS.vocab.stoi[TOKENS.pad_token]\n",
        "\n",
        "  model = CNN_Text(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)\n",
        "  pretrained_embeddings = TOKENS.vocab.vectors\n",
        "  model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "  unk_idx = TOKENS.vocab.stoi[TOKENS.unk_token]\n",
        "\n",
        "  model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "  model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BILiVNtRMn_g"
      },
      "source": [
        "Below methods used for calculating relevant metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEpTN2bS_m8y"
      },
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "\n",
        "def get_f1_score(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    score = f1_score(y.cpu().detach().numpy(), rounded_preds.cpu().detach().numpy(), average = 'macro')\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onqx0O_z-DV6"
      },
      "source": [
        "def get_precision_recall(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    p_score = precision_score(y.cpu().detach().numpy(), rounded_preds.cpu().detach().numpy(), average = 'macro')\n",
        "    r_score = recall_score(y.cpu().detach().numpy(), rounded_preds.cpu().detach().numpy(), average = 'macro')\n",
        "    return p_score, r_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17G86lZFbEBc"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tQdt2U1VSBF"
      },
      "source": [
        "def five_f1_score(preds, y):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    score = f1_score(y.cpu().detach().numpy(), predicted.cpu().detach().numpy(), average = 'macro')\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q98dGIwC-hJg"
      },
      "source": [
        "def five_precision_recall(preds, y):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    p_score = precision_score(y.cpu().detach().numpy(), predicted.cpu().detach().numpy(), average = 'macro')\n",
        "    r_score = recall_score(y.cpu().detach().numpy(), predicted.cpu().detach().numpy(), average = 'macro')\n",
        "    return p_score, r_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJD_he06UemC"
      },
      "source": [
        "def five_accuracy(preds, y):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct / len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCzbsXRDK7iM"
      },
      "source": [
        "\"\"\"\n",
        "Basic train loop for cnn\n",
        "\n",
        "Returns final accuracy, loss, f1 score, precision, and recall \n",
        "\"\"\"\n",
        "def train_cnn(model, iterator, optimizer, criterion, epochs=10, print_intermediate = False, five_class = False):\n",
        "    for child in model.children():\n",
        "      if hasattr(child, 'reset_parameters'):\n",
        "        child.reset_parameters()\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    f1_list = []\n",
        "    precision_list = []\n",
        "    recall_list= []\n",
        "    print('Starting Training\\n')\n",
        "    for epoch in range(epochs):\n",
        "      epoch_acc = 0\n",
        "      epoch_loss = 0\n",
        "      epoch_f1 = 0\n",
        "      epoch_precision = 0\n",
        "      epoch_recall = 0\n",
        "      i = 0\n",
        "      seen_since_last_print = 0\n",
        "      for batch in iterator:\n",
        "        i += 1\n",
        "        seen_since_last_print += 1\n",
        "\n",
        "        inputs = batch.tokens\n",
        "        labels = batch.score\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        if five_class:\n",
        "            epoch_f1 += five_f1_score(outputs, labels)\n",
        "            epoch_acc += five_accuracy(outputs, labels)\n",
        "            precision, recall = five_precision_recall(outputs, labels)\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "        else:\n",
        "            epoch_f1 += get_f1_score(outputs, labels)\n",
        "            epoch_acc += binary_accuracy(outputs, labels).item()\n",
        "            precision, recall = get_precision_recall(outputs, labels)\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "\n",
        "        \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "        if print_intermediate:\n",
        "          if (seen_since_last_print / len(iterator)) > .1:\n",
        "            percent = 100 * i / len(iterator)\n",
        "            print('Epoch %d is %d%% done' % (epoch + 1, percent))\n",
        "            seen_since_last_print = 0\n",
        "\n",
        "      epoch_acc = epoch_acc / len(iterator)\n",
        "      epoch_loss = epoch_loss / len(iterator)\n",
        "      epoch_f1 = epoch_f1 / len(iterator)\n",
        "      epoch_recall = epoch_recall / len(iterator)\n",
        "      epoch_precision = epoch_precision / len(iterator)\n",
        "\n",
        "      accuracy_list.append(epoch_acc)\n",
        "      loss_list.append(epoch_loss)\n",
        "      f1_list.append(epoch_f1)\n",
        "      recall_list.append(epoch_recall)\n",
        "      precision_list.append(epoch_precision)\n",
        "      print('\\nEpoch Num: %d, Accuracy: %.4f, Loss: %.4f, F1: %.4f, Precision: %.4f, Recall: %.4f\\n' % (epoch + 1, epoch_acc, epoch_loss, epoch_f1, epoch_precision, epoch_recall))\n",
        "\n",
        "    final_training_accuracy = accuracy_list[-1]     \n",
        "    final_training_loss = loss_list[-1]\n",
        "    final_training_f1 = f1_list[-1]\n",
        "    final_training_precision = precision_list[-1]\n",
        "    final_training_recall = recall_list[-1]\n",
        "    print('Done training\\n')\n",
        "    return final_training_accuracy, final_training_loss, final_training_f1, final_training_precision, final_training_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5AF4hxLZ9I7"
      },
      "source": [
        "'''\n",
        "Test loop for CNN that outputs the same metrics as the train loop\n",
        "'''\n",
        "def test_cnn_model(model, iterator, criterion, five_class = False):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    test_f1 = 0 \n",
        "    test_precision = 0\n",
        "    test_recall = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in iterator:\n",
        "        outputs = model(batch.tokens).squeeze(1)\n",
        "        loss = criterion(outputs, batch.score)\n",
        "        test_loss += loss.item()\n",
        "        if five_class:\n",
        "            test_acc += five_accuracy(outputs, batch.score)\n",
        "            test_f1 += five_f1_score(outputs, batch.score)\n",
        "            precision, recall = five_precision_recall(outputs, batch.score)\n",
        "            test_precision += precision\n",
        "            test_recall += recall\n",
        "        else:\n",
        "            test_acc += binary_accuracy(outputs, batch.score)\n",
        "            test_f1 += get_f1_score(outputs, batch.score)\n",
        "            precision, recall = get_precision_recall(outputs, batch.score)\n",
        "            test_precision += precision\n",
        "            test_recall += recall\n",
        "    \n",
        "    testing_accuracy = test_acc / len(iterator)   \n",
        "    testing_loss = test_loss / len(iterator)\n",
        "    testing_f1 = test_f1 / len(iterator)\n",
        "    testing_precision = test_precision / len(iterator)\n",
        "    testing_recall = test_recall / len(iterator) \n",
        "    return testing_accuracy, testing_loss, testing_f1, testing_precision, testing_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqOw67D0M8o7"
      },
      "source": [
        "#Testing / Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBE9HyM_d7K1"
      },
      "source": [
        "'''\n",
        "executes a single train/test loop based on the parameters\n",
        "'''\n",
        "def single_train_test_loop(summary_df, dataset_name, num_classes, optim_name, train_iter, test_iter, tokens):\n",
        "    model = get_cnn_model(num_classes = num_classes, TOKENS = tokens)\n",
        "    if optim_name == 'madgrad':\n",
        "        optimizer = madgrad.MADGRAD(model.parameters(), lr = .001)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = .001)\n",
        "    \n",
        "    if num_classes == 1:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    five_classes = (num_classes == 5)\n",
        "\n",
        "    train_acc, train_loss, train_f1, train_precision, train_recall = train_cnn(model, train_iter, optimizer, criterion, print_intermediate=False, five_class=five_classes)\n",
        "    test_acc, test_loss, test_f1, test_precision, test_recall = test_cnn_model(model, train_iter, criterion, five_class = five_classes)\n",
        "\n",
        "    print('-----------------------------------')\n",
        "    print('Test Statistics: ')\n",
        "    print(test_acc, test_loss, test_f1, test_precision, test_recall)\n",
        "    print('-----------------------------------')\n",
        "\n",
        "    prediction_type = 'five class' if num_classes == 5 else 'binary'\n",
        "    #new_row = {'dataset': dataset_name, 'predicton_type': prediction_type, 'optimizer': optim_name,\n",
        "    #          'lr': .001, 'train_acc': train_acc, 'train_loss': train_loss, 'train_f1': train_f1,\n",
        "    #          'test_acc': test_acc, 'test_loss': test_loss, 'test_f1': test_f1}\n",
        "    #summary_df.append(new_row, ignore_index = True)\n",
        "    return model, summary_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b-pnie7ZpdC"
      },
      "source": [
        "\"\"\"\n",
        "Comparing different algorithms\n",
        "\"\"\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cols = ['dataset', 'prediction_type', 'optimizer', 'lr', 'train_acc', 'train_loss', \\\n",
        "        'train_f1', 'train_precision', 'train_recall', 'test_acc', 'test_loss', 'test_f1'\\\n",
        "        'test_precision', 'test_recall']\n",
        "\n",
        "summary_df = pd.DataFrame(columns = cols)\n",
        "\n",
        "#compare binary electronics vs. binary allcats\n",
        "bin_elec_train_iter, bin_elec_test_iter, bin_elec_tokens = get_iters_tokens(dataset = 'electronics', binary = True)\n",
        "bin_elec_model, summary_df = single_train_test_loop(summary_df, 'electronics', 1, 'madgrad', \\\n",
        "                                        bin_elec_train_iter, bin_elec_test_iter,\n",
        "                                        bin_elec_tokens)\n",
        "\n",
        "print(summary_df)\n",
        "\n",
        "bin_all_train_iter, bin_all_test_iter, bin_all_tokens = get_iters_tokens(dataset = 'all', binary = True)\n",
        "bin_all_madgrad_model, summary_df = single_train_test_loop(summary_df, 'allcats', 1, 'madgrad', \\\n",
        "                                        bin_all_train_iter, bin_all_test_iter,\n",
        "                                        bin_all_tokens)\n",
        "\n",
        "\n",
        "#compare binary allcats vs. five allcats\n",
        "five_all_train, five_all_test, five_all_tokens = get_iters_tokens(dataset = 'all', binary = False)\n",
        "five_all_madgrad_model, summary_df = single_train_test_loop(summary_df, 'allcats', 5, 'madgrad', \\\n",
        "                                        five_all_train, five_all_test,\n",
        "                                        five_all_tokens)\n",
        "\n",
        "#compare adam to madgrad\n",
        "bin_all_adam_model, summary_df = single_train_test_loop(summary_df, 'allcats', 1, 'adam', \\\n",
        "                                        bin_all_train_iter, bin_all_test_iter,\n",
        "                                        bin_all_tokens)\n",
        "\n",
        "\n",
        "five_all_adam_model, summary_df = single_train_test_loop(summary_df, 'allcats', 5, 'adam', \\\n",
        "                                        five_all_train, five_all_test, \n",
        "                                        five_all_tokens)\n",
        "\n",
        "#summary_df.to_csv('/content/drive/Shareddrives/519 Project/Data/Final Results/CNN_comparison_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}